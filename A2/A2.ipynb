{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 - Human Value Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f812147f55c0220",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:22.961453700Z",
     "start_time": "2023-12-10T16:15:10.114241800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !pip install lightning\n",
    "# !pip install torchmetrics\n",
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b3cd2c7bd257608",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.149703Z",
     "start_time": "2023-12-10T16:15:22.963513600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# file management\n",
    "import urllib.request\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# torchmetrics\n",
    "from torchmetrics import PrecisionRecallCurve\n",
    "from torchmetrics.classification import MultilabelConfusionMatrix\n",
    "\n",
    "# pytorch lightning\n",
    "from lightning import LightningModule\n",
    "from lightning.pytorch import Trainer, seed_everything\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from torchmetrics.classification import MultilabelF1Score\n",
    "from torchmetrics import Metric\n",
    "from torchmetrics import ConfusionMatrix\n",
    "\n",
    "# transformers\n",
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1: Corpus\n",
    "\n",
    "* **Download** the specificed training, validation, and test files.\n",
    "* **Encode** split files into a pandas.DataFrame object.\n",
    "* For each split, **merge** the arguments and labels dataframes into a single dataframe.\n",
    "* **Merge** level 2 annotations to level 3 categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4516ac9d641c89e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.166590900Z",
     "start_time": "2023-12-10T16:15:24.150726800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File arguments-training.tsv already exists. Skipping download...\n",
      "File arguments-test.tsv already exists. Skipping download...\n",
      "File arguments-validation.tsv already exists. Skipping download...\n",
      "File labels-training.tsv already exists. Skipping download...\n",
      "File labels-test.tsv already exists. Skipping download...\n",
      "File labels-validation.tsv already exists. Skipping download...\n"
     ]
    }
   ],
   "source": [
    "# download data from url and save it to the data folder\n",
    "\n",
    "file_names = [\n",
    "    \"arguments-training.tsv\",\n",
    "    \"arguments-test.tsv\",\n",
    "    \"arguments-validation.tsv\",\n",
    "    \"labels-training.tsv\",\n",
    "    \"labels-test.tsv\",\n",
    "    \"labels-validation.tsv\"\n",
    "]\n",
    "\n",
    "# Create the data folder\n",
    "if not os.path.exists(\"./data\"):\n",
    "    os.makedirs(\"./data\")\n",
    "\n",
    "url = \"https://zenodo.org/records/8248658/files/{file_name}?download=1\"\n",
    "for file_name in file_names:\n",
    "    if os.path.exists(f\"./data/{file_name}\"):\n",
    "        print(f\"File {file_name} already exists. Skipping download...\")\n",
    "        continue\n",
    "\n",
    "    file_url = url.format(file_name=file_name)\n",
    "    print(f\"Downloading {file_name} from {file_url}...\")        \n",
    "    urllib.request.urlretrieve(url.format(file_name=file_name), f\"./data/{file_name}\")\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.212916600Z",
     "start_time": "2023-12-10T16:15:24.166590900Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Argument ID</th>\n",
       "      <th>Self-direction: thought</th>\n",
       "      <th>Self-direction: action</th>\n",
       "      <th>Stimulation</th>\n",
       "      <th>Hedonism</th>\n",
       "      <th>Achievement</th>\n",
       "      <th>Power: dominance</th>\n",
       "      <th>Power: resources</th>\n",
       "      <th>Face</th>\n",
       "      <th>Security: personal</th>\n",
       "      <th>...</th>\n",
       "      <th>Tradition</th>\n",
       "      <th>Conformity: rules</th>\n",
       "      <th>Conformity: interpersonal</th>\n",
       "      <th>Humility</th>\n",
       "      <th>Benevolence: caring</th>\n",
       "      <th>Benevolence: dependability</th>\n",
       "      <th>Universalism: concern</th>\n",
       "      <th>Universalism: nature</th>\n",
       "      <th>Universalism: tolerance</th>\n",
       "      <th>Universalism: objectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A26004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A26010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A26016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A26024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A26026</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Argument ID  Self-direction: thought  Self-direction: action  Stimulation  \\\n",
       "0      A26004                        0                       0            0   \n",
       "1      A26010                        0                       0            0   \n",
       "2      A26016                        0                       0            0   \n",
       "3      A26024                        0                       0            0   \n",
       "4      A26026                        0                       0            0   \n",
       "\n",
       "   Hedonism  Achievement  Power: dominance  Power: resources  Face  \\\n",
       "0         0            1                 0                 0     0   \n",
       "1         0            1                 0                 0     0   \n",
       "2         0            1                 0                 0     0   \n",
       "3         0            1                 0                 0     0   \n",
       "4         0            1                 0                 0     0   \n",
       "\n",
       "   Security: personal  ...  Tradition  Conformity: rules  \\\n",
       "0                   1  ...          0                  0   \n",
       "1                   0  ...          0                  0   \n",
       "2                   1  ...          0                  0   \n",
       "3                   0  ...          0                  0   \n",
       "4                   1  ...          0                  0   \n",
       "\n",
       "   Conformity: interpersonal  Humility  Benevolence: caring  \\\n",
       "0                          0         0                    0   \n",
       "1                          0         0                    0   \n",
       "2                          0         0                    0   \n",
       "3                          0         0                    0   \n",
       "4                          0         0                    1   \n",
       "\n",
       "   Benevolence: dependability  Universalism: concern  Universalism: nature  \\\n",
       "0                           0                      1                     0   \n",
       "1                           0                      1                     0   \n",
       "2                           1                      1                     0   \n",
       "3                           0                      0                     0   \n",
       "4                           1                      0                     0   \n",
       "\n",
       "   Universalism: tolerance  Universalism: objectivity  \n",
       "0                        1                          0  \n",
       "1                        1                          1  \n",
       "2                        0                          0  \n",
       "3                        0                          0  \n",
       "4                        0                          0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the dataframes\n",
    "df_arg_train = pd.read_csv('./data/arguments-training.tsv', sep='\\t')\n",
    "df_arg_test = pd.read_csv('./data/arguments-test.tsv', sep='\\t')\n",
    "df_arg_val = pd.read_csv('./data/arguments-validation.tsv', sep='\\t')\n",
    "\n",
    "df_labels_train = pd.read_csv('./data/labels-training.tsv', sep='\\t')\n",
    "df_labels_test = pd.read_csv('./data/labels-test.tsv', sep='\\t')\n",
    "df_labels_val = pd.read_csv('./data/labels-validation.tsv', sep='\\t')\n",
    "\n",
    "df_labels_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotations\n",
    "Since the task requires only to take in account *level 3 categories* a mapping between *level 2* and *level 3* is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e2b4fe2c6cb107d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.255091700Z",
     "start_time": "2023-12-10T16:15:24.214959700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Argument ID</th>\n",
       "      <th>Openness to change</th>\n",
       "      <th>Self-enhancement</th>\n",
       "      <th>Conservation</th>\n",
       "      <th>Self-transcendence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A26004</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A26010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A26016</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A26024</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A26026</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Argument ID  Openness to change  Self-enhancement  Conservation  \\\n",
       "0      A26004                   0                 1             1   \n",
       "1      A26010                   0                 1             0   \n",
       "2      A26016                   0                 1             1   \n",
       "3      A26024                   0                 1             0   \n",
       "4      A26026                   0                 1             1   \n",
       "\n",
       "   Self-transcendence  \n",
       "0                   1  \n",
       "1                   1  \n",
       "2                   1  \n",
       "3                   0  \n",
       "4                   1  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_3_categories = [\"Openness to change\", \"Self-enhancement\", \"Conservation\", \"Self-transcendence\"]\n",
    "\n",
    "level_3_to_2_mapping = {\n",
    "    \"Openness to change\": [\n",
    "        \"Self-direction: thought\",\n",
    "        \"Self-direction: action\",\n",
    "        \"Stimulation\",\n",
    "        \"Hedonism\",\n",
    "    ],\n",
    "    \"Self-enhancement\": [\n",
    "        \"Hedonism\",\n",
    "        \"Achievement\",\n",
    "        \"Power: dominance\",\n",
    "        \"Power: resources\",\n",
    "        \"Face\",\n",
    "    ],\n",
    "    \"Conservation\": [\n",
    "        \"Security: personal\",\n",
    "        \"Security: societal\",\n",
    "        \"Conformity: rules\",\n",
    "        \"Conformity: interpersonal\",\n",
    "        \"Tradition\",\n",
    "        \"Face\",\n",
    "        \"Humility\",\n",
    "    ],\n",
    "    \"Self-transcendence\": [\n",
    "        \"Benevolence: caring\",\n",
    "        \"Benevolence: dependability\",\n",
    "        \"Universalism: concern\",\n",
    "        \"Universalism: nature\",\n",
    "        \"Universalism: tolerance\",\n",
    "        \"Universalism: objectivity\",\n",
    "        \"Humility\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "column_to_drop = [level_2 for level_3 in level_3_to_2_mapping.values() for level_2 in level_3]\n",
    "\n",
    "for category in level_3_categories:\n",
    "    # make a logical OR of all the level 2 categories\n",
    "    df_labels_test[category] = df_labels_test[level_3_to_2_mapping[category]].any(axis=1).map({True: 1, False: 0})\n",
    "    df_labels_val[category] = df_labels_val[level_3_to_2_mapping[category]].any(axis=1).map({True: 1, False: 0})\n",
    "    df_labels_train[category] = df_labels_train[level_3_to_2_mapping[category]].any(axis=1).map({True: 1, False: 0})\n",
    "\n",
    "df_labels_test = df_labels_test.drop(columns=column_to_drop)\n",
    "df_labels_val = df_labels_val.drop(columns=column_to_drop)\n",
    "df_labels_train = df_labels_train.drop(columns=column_to_drop)\n",
    "\n",
    "df_labels_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8316839c9de44b89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.274578600Z",
     "start_time": "2023-12-10T16:15:24.244896500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Argument ID</th>\n",
       "      <th>Conclusion</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Premise</th>\n",
       "      <th>Openness to change</th>\n",
       "      <th>Self-enhancement</th>\n",
       "      <th>Conservation</th>\n",
       "      <th>Self-transcendence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A01002</td>\n",
       "      <td>We should ban human cloning</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>we should ban human cloning as it will only ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A01005</td>\n",
       "      <td>We should ban fast food</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>fast food should be banned because it is reall...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A01006</td>\n",
       "      <td>We should end the use of economic sanctions</td>\n",
       "      <td>against</td>\n",
       "      <td>sometimes economic sanctions are the only thin...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A01007</td>\n",
       "      <td>We should abolish capital punishment</td>\n",
       "      <td>against</td>\n",
       "      <td>capital punishment is sometimes the only optio...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A01008</td>\n",
       "      <td>We should ban factory farming</td>\n",
       "      <td>against</td>\n",
       "      <td>factory farming allows for the production of c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Argument ID                                   Conclusion       Stance  \\\n",
       "0      A01002                  We should ban human cloning  in favor of   \n",
       "1      A01005                      We should ban fast food  in favor of   \n",
       "2      A01006  We should end the use of economic sanctions      against   \n",
       "3      A01007         We should abolish capital punishment      against   \n",
       "4      A01008                We should ban factory farming      against   \n",
       "\n",
       "                                             Premise  Openness to change  \\\n",
       "0  we should ban human cloning as it will only ca...                   0   \n",
       "1  fast food should be banned because it is reall...                   0   \n",
       "2  sometimes economic sanctions are the only thin...                   0   \n",
       "3  capital punishment is sometimes the only optio...                   0   \n",
       "4  factory farming allows for the production of c...                   0   \n",
       "\n",
       "   Self-enhancement  Conservation  Self-transcendence  \n",
       "0                 0             1                   0  \n",
       "1                 0             1                   0  \n",
       "2                 1             1                   0  \n",
       "3                 0             1                   1  \n",
       "4                 0             1                   1  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.merge(df_arg_train, df_labels_train, on='Argument ID')\n",
    "df_test = pd.merge(df_arg_test, df_labels_test, on='Argument ID')\n",
    "df_val = pd.merge(df_arg_val, df_labels_val, on='Argument ID')\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cdfe3378972543",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Task 1.5 - stance encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "232f6776a1ee9a80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.290104800Z",
     "start_time": "2023-12-10T16:15:24.260231300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Argument ID</th>\n",
       "      <th>Conclusion</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Premise</th>\n",
       "      <th>Openness to change</th>\n",
       "      <th>Self-enhancement</th>\n",
       "      <th>Conservation</th>\n",
       "      <th>Self-transcendence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A01002</td>\n",
       "      <td>We should ban human cloning</td>\n",
       "      <td>1</td>\n",
       "      <td>we should ban human cloning as it will only ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A01005</td>\n",
       "      <td>We should ban fast food</td>\n",
       "      <td>1</td>\n",
       "      <td>fast food should be banned because it is reall...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A01006</td>\n",
       "      <td>We should end the use of economic sanctions</td>\n",
       "      <td>0</td>\n",
       "      <td>sometimes economic sanctions are the only thin...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A01007</td>\n",
       "      <td>We should abolish capital punishment</td>\n",
       "      <td>0</td>\n",
       "      <td>capital punishment is sometimes the only optio...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A01008</td>\n",
       "      <td>We should ban factory farming</td>\n",
       "      <td>0</td>\n",
       "      <td>factory farming allows for the production of c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Argument ID                                   Conclusion  Stance  \\\n",
       "0      A01002                  We should ban human cloning       1   \n",
       "1      A01005                      We should ban fast food       1   \n",
       "2      A01006  We should end the use of economic sanctions       0   \n",
       "3      A01007         We should abolish capital punishment       0   \n",
       "4      A01008                We should ban factory farming       0   \n",
       "\n",
       "                                             Premise  Openness to change  \\\n",
       "0  we should ban human cloning as it will only ca...                   0   \n",
       "1  fast food should be banned because it is reall...                   0   \n",
       "2  sometimes economic sanctions are the only thin...                   0   \n",
       "3  capital punishment is sometimes the only optio...                   0   \n",
       "4  factory farming allows for the production of c...                   0   \n",
       "\n",
       "   Self-enhancement  Conservation  Self-transcendence  \n",
       "0                 0             1                   0  \n",
       "1                 0             1                   0  \n",
       "2                 1             1                   0  \n",
       "3                 0             1                   1  \n",
       "4                 0             1                   1  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode stance into 0, 1 \n",
    "df_train[\"Stance\"] = df_train[\"Stance\"].map({\"in favor of\": 1, \"against\": 0})\n",
    "df_test[\"Stance\"] = df_test[\"Stance\"].map({\"in favor of\": 1, \"against\": 0})\n",
    "df_val[\"Stance\"] = df_val[\"Stance\"].map({\"in favor of\": 1, \"against\": 0})\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77076cfdcc028fa7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Dataset definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ecad75b6100c0040",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.359095Z",
     "start_time": "2023-12-10T16:15:24.275596200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ArgumentDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        return {\n",
    "            \"Premise\": row[\"Premise\"],\n",
    "            \"Conclusion\": row[\"Conclusion\"],\n",
    "            \"labels\": torch.tensor(row[level_3_categories].values.tolist(), dtype=torch.float32),\n",
    "            \"Stance\": torch.tensor(row[\"Stance\"], dtype=torch.float32)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "94fe31d775254160",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.377556300Z",
     "start_time": "2023-12-10T16:15:24.290104800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Premise': 'we should ban human cloning as it will only cause huge issues when you have a bunch of the same humans running around all acting the same.', 'Conclusion': 'We should ban human cloning', 'labels': tensor([0., 0., 1., 0.]), 'Stance': tensor(1.)}\n",
      "{'Premise': 'fast food should be banned because it is really bad for your health and is costly.', 'Conclusion': 'We should ban fast food', 'labels': tensor([0., 0., 1., 0.]), 'Stance': tensor(1.)}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = ArgumentDataset(df_train)\n",
    "test_dataset = ArgumentDataset(df_test)\n",
    "val_dataset = ArgumentDataset(df_val)\n",
    "\n",
    "# Create the dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(train_dataset[0])\n",
    "print(train_dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 3: Metrics\n",
    "\n",
    "### Instructions\n",
    "\n",
    "* Evaluate your models using per-category binary F1-score.\n",
    "* Compute the average binary F1-score over all categories (macro F1-score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1ScoreCumulative(Metric):\n",
    "    def __init__(self, num_classes: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.add_state(\"true_positive\", default=torch.zeros([num_classes]), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"false_negative\", default=torch.zeros([num_classes]), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"false_positive\", default=torch.zeros([num_classes]), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, y_hat: torch.Tensor, y: torch.Tensor):\n",
    "        \n",
    "        for i in range(self.num_classes):\n",
    "            true_positive = torch.sum((y_hat[:, i] == 1) & (y[:, i] == 1))\n",
    "            false_negative = torch.sum((y_hat[:, i] == 0) & (y[:, i] == 1))\n",
    "            false_positive = torch.sum((y_hat[:, i] == 1) & (y[:, i] == 0))\n",
    "\n",
    "            self.true_positive[i] += true_positive\n",
    "            self.false_negative[i] += false_negative\n",
    "            self.false_positive[i] += false_positive\n",
    "\n",
    "    def compute(self):\n",
    "        precision = self.true_positive / (self.true_positive + self.false_positive)\n",
    "        recall = self.true_positive / (self.true_positive + self.false_negative)\n",
    "\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        \n",
    "        # If there are not enough data to compute the f1 score, set it to 0\n",
    "        if f1.isnan().any():\n",
    "            f1[f1.isnan()] = 0\n",
    "\n",
    "        return f1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ffa5c2876fecbf",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## TASK 2: Model definition\n",
    "\n",
    "* **Baseline**: implement a random uniform classifier (an individual classifier per category).\n",
    "* **Baseline**: implement a majority classifier (an individual classifier per category).\n",
    "\n",
    "<br/>\n",
    "\n",
    "* **BERT w/ C**: define a BERT-based classifier that receives an argument **conclusion** as input.\n",
    "* **BERT w/ CP**: add argument **premise** as an additional input.\n",
    "* **BERT w/ CPS**: add argument premise-to-conclusion **stance** as an additional input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbd8b41505ded6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Baselines: random uniform classifier and majority classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "331380fdc13c462f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.395023600Z",
     "start_time": "2023-12-10T16:15:24.308674Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RandomUniformClassifier(LightningModule):\n",
    "    def __init__(self):\n",
    "        self._random_state = np.random.RandomState()\n",
    "\n",
    "    def predict(self, X):\n",
    "        batch_size = X.shape[0]\n",
    "        logits = self._random_state.uniform(size=(batch_size, 4))\n",
    "        logits = logits > 0.5\n",
    "        return torch.tensor(logits, dtype=torch.float32)\n",
    "\n",
    "\n",
    "class MajorityClassifier(LightningModule):\n",
    "    def __init__(self, n_random_classifiers=10):\n",
    "        self.n_random_classifiers = n_random_classifiers\n",
    "        self.random_classifiers = [RandomUniformClassifier() for _ in range(n_random_classifiers)]\n",
    "\n",
    "    def predict(self, X):\n",
    "        batch_size = X.shape[0]\n",
    "        votes = torch.zeros((batch_size, 4))\n",
    "        for clf in self.random_classifiers:\n",
    "            votes += clf.predict(X)\n",
    "        votes = votes / self.n_random_classifiers\n",
    "        votes = votes > 0.5\n",
    "        return torch.tensor(votes, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab6e80eded57efb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Bert models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eef0d525e8b3e87e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.441482700Z",
     "start_time": "2023-12-10T16:15:24.326135400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BertConclusion(LightningModule):\n",
    "    def __init__(self, bert_model_name, backbone, tokenizer, num_classes, clf_input_size=None):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=['backbone'])\n",
    "        self.tokenizer = tokenizer\n",
    "        self.backbone = backbone\n",
    "        self.clf_input_size = clf_input_size\n",
    "        if clf_input_size is None:\n",
    "            clf_input_size = self.backbone.config.hidden_size\n",
    "\n",
    "        # freeze bert layers\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.classifier = nn.Linear(self.clf_input_size, num_classes)\n",
    "        \n",
    "        self._f1_train = F1ScoreCumulative(num_classes=num_classes)\n",
    "        self._f1_val = F1ScoreCumulative(num_classes=num_classes)\n",
    "        self._f1_test = F1ScoreCumulative(num_classes=num_classes)\n",
    "\n",
    "        self.f1_metrics = {\n",
    "            \"train\": self._f1_train,\n",
    "            \"val\": self._f1_val,\n",
    "            \"test\": self._f1_test\n",
    "        }\n",
    "\n",
    "    def forward(self, X_data):\n",
    "        X = X_data[\"Conclusion\"]\n",
    "\n",
    "        encoded = self.tokenizer(X, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "        outputs = self.backbone(**encoded)\n",
    "\n",
    "        # last_hidden_state contains the hidden representations for each token in each sequence of the batch:\n",
    "        # shape is (batch_size, seq_len, hidden_size)\n",
    "        # we only need the representation of the first token (the [CLS] token)\n",
    "        logits = self.classifier(outputs.last_hidden_state[:, 0, :])\n",
    "        return logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        data = batch\n",
    "        X_data = {key:value for key, value in data.items() if key != \"labels\"}\n",
    "        y = data[\"labels\"]\n",
    "\n",
    "        logits = self(X_data)\n",
    "\n",
    "        loss = nn.BCEWithLogitsLoss()(logits, y)\n",
    "        self.log(\"train_loss\", loss, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        # Get predictions\n",
    "        y_hat = torch.zeros_like(y)\n",
    "        y_hat[torch.nn.functional.sigmoid(logits) > 0.5] = 1\n",
    "        self.f1_metrics[\"train\"].update(y_hat, y)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        data = batch\n",
    "        X = {key:value for key, value in data.items() if key != \"labels\"}\n",
    "        y = data[\"labels\"]\n",
    "\n",
    "        logits = self(X)\n",
    "\n",
    "        loss = nn.BCEWithLogitsLoss()(logits, y)\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        y_hat = torch.zeros_like(y)\n",
    "        y_hat[torch.nn.functional.sigmoid(logits) > 0.5] = 1\n",
    "        self.f1_metrics[\"val\"].update(y_hat, y)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        data = batch\n",
    "        X = {key:value for key, value in data.items() if key != \"labels\"}\n",
    "        y = data[\"labels\"]\n",
    "\n",
    "        logits = self(X)\n",
    "\n",
    "        loss = nn.BCEWithLogitsLoss()(logits, y)\n",
    "        self.log(\"test_loss\", loss, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        y_hat = torch.zeros_like(y)\n",
    "        y_hat[torch.nn.functional.sigmoid(logits) > 0.5] = 1\n",
    "        self.f1_metrics[\"test\"].update(y_hat, y)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-5)\n",
    "\n",
    "    def on_epoch_type_end(self, epoch_type) -> None:\n",
    "        f1_score_per_class = self.f1_metrics[epoch_type].compute()\n",
    "        f1_score_macro = f1_score_per_class.mean()\n",
    "\n",
    "        self.log(f\"{epoch_type}_f1_score\", f1_score_macro, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        for i, category in enumerate(level_3_categories):\n",
    "            self.log(f\"{epoch_type}_f1_score_{category}\", f1_score_per_class[i], on_epoch=True, prog_bar=True, logger=True)\n",
    "    \n",
    "        self.f1_metrics[epoch_type].reset()\n",
    "\n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        self.on_epoch_type_end(\"train\")\n",
    "\n",
    "    def on_validation_epoch_end(self) -> None:\n",
    "        self.on_epoch_type_end(\"val\")\n",
    "\n",
    "    def on_test_epoch_end(self) -> None:\n",
    "        self.on_epoch_type_end(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "31dbbe5fe8eb3195",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.443528100Z",
     "start_time": "2023-12-10T16:15:24.357066200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BertPremiseConclusion(BertConclusion):\n",
    "    def __init__(self, bert_model_name, backbone, tokenizer, num_classes, clf_input_size):\n",
    "        super().__init__(bert_model_name, num_classes, clf_input_size*2)\n",
    "\n",
    "    def forward(self, X_data):\n",
    "        X_1 = X_data[\"Premise\"]\n",
    "        X_2 = X_data[\"Conclusion\"]\n",
    "\n",
    "        encoded_1 = self.tokenizer(X_1, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "        encoded_2 = self.tokenizer(X_2, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        # last_hidden_state contains the hidden representations for each token in each sequence of the batch:\n",
    "        # shape is (batch_size, seq_len, hidden_size)\n",
    "        # we only need the representation of the first token (the [CLS] token)\n",
    "        output_1 = self.bert(**encoded_1).last_hidden_state[:, 0, :]\n",
    "        output_2 = self.bert(**encoded_2).last_hidden_state[:, 0, :]\n",
    "\n",
    "        output = torch.cat((output_1, output_2), dim=1)\n",
    "\n",
    "        logits = self.classifier(output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b11eb0f4965923dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.444544200Z",
     "start_time": "2023-12-10T16:15:24.372404800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BertPremiseConclusionStance(BertConclusion):\n",
    "    def __init__(self, bert_model_name, backbone, tokenizer, num_classes, clf_input_size):\n",
    "        super().__init__(bert_model_name, num_classes, clf_input_size=clf_input_size*2+1)\n",
    "                         \n",
    "\n",
    "    def forward(self, X_data):\n",
    "        X_1, X_2, stance = X_data[\"Premise\"], X_data[\"Conclusion\"], X_data[\"Stance\"]\n",
    "        \n",
    "        encoded_1 = self.tokenizer(X_1, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "        encoded_2 = self.tokenizer(X_2, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        # last_hidden_state contains the hidden representations for each token in each sequence of the batch:\n",
    "        # shape is (batch_size, seq_len, hidden_size)\n",
    "        # we only need the representation of the first token (the [CLS] token)\n",
    "        output_1 = self.bert(**encoded_1).last_hidden_state[:, 0, :]\n",
    "        output_2 = self.bert(**encoded_2).last_hidden_state[:, 0, :]\n",
    "        \n",
    "        stance = stance.unsqueeze(1)\n",
    "        output = torch.cat((output_1, output_2, stance), dim=1)\n",
    "        logits = self.classifier(output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e4d886bff0ede4b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.444544200Z",
     "start_time": "2023-12-10T16:15:24.387844600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fix all possible sources of randomness\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e755d7ef",
   "metadata": {},
   "source": [
    "## Task 4 Training and Evaluation\n",
    "\n",
    "You are now tasked to train and evaluate **all** defined models.\n",
    "* Train **all** models on the train set.\n",
    "* Evaluate **all** models on the validation set.\n",
    "* Pick **at least** three seeds for robust estimation.\n",
    "* Compute metrics on the validation set.\n",
    "* Report **per-category** and **macro** F1-score for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "499c93fc7632db8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.463035600Z",
     "start_time": "2023-12-10T16:15:24.406432500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bb57eb3cf3e4966a6aa9835fc2e0063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [48], line 11\u001b[0m\n\u001b[1;32m      6\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m15\u001b[39m\n\u001b[1;32m      7\u001b[0m output_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(level_3_categories)\n\u001b[1;32m      9\u001b[0m backbones \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m: BertModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroberta-base\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mBertModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mroberta-base\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     12\u001b[0m }\n\u001b[1;32m     14\u001b[0m tokenizers \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m: BertTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroberta-base\u001b[39m\u001b[38;5;124m\"\u001b[39m: BertTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroberta-base\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     17\u001b[0m }\n\u001b[1;32m     19\u001b[0m backbone_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/modeling_utils.py:2519\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2504\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2505\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m   2506\u001b[0m     cached_file_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   2507\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m: cache_dir,\n\u001b[1;32m   2508\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforce_download\u001b[39m\u001b[38;5;124m\"\u001b[39m: force_download,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2517\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m: commit_hash,\n\u001b[1;32m   2518\u001b[0m     }\n\u001b[0;32m-> 2519\u001b[0m     resolved_archive_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcached_file_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2521\u001b[0m     \u001b[38;5;66;03m# Since we set _raise_exceptions_for_missing_entries=False, we don't get an exception but a None\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m     \u001b[38;5;66;03m# result when internet is up, the repo and revision exist, but the file does not.\u001b[39;00m\n\u001b[1;32m   2523\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_archive_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m filename \u001b[38;5;241m==\u001b[39m _add_variant(SAFE_WEIGHTS_NAME, variant):\n\u001b[1;32m   2524\u001b[0m         \u001b[38;5;66;03m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/hub.py:417\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    414\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 417\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError:\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    434\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    435\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    436\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpass a token having permission to this repo with `use_auth_token` or log in with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`huggingface-cli login` and pass `use_auth_token=True`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    438\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:120\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    118\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1364\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1361\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m temp_file_manager() \u001b[38;5;28;01mas\u001b[39;00m temp_file:\n\u001b[1;32m   1362\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdownloading \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, temp_file\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m-> 1364\u001b[0m     \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1365\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemp_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1367\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1371\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m local_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStoring \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in cache at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mblob_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:541\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, timeout, max_retries, expected_size)\u001b[0m\n\u001b[1;32m    531\u001b[0m     displayed_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(…)\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisplayed_name[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m20\u001b[39m:]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m progress \u001b[38;5;241m=\u001b[39m tqdm(\n\u001b[1;32m    534\u001b[0m     unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    535\u001b[0m     unit_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    539\u001b[0m     disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m(logger\u001b[38;5;241m.\u001b[39mgetEffectiveLevel() \u001b[38;5;241m==\u001b[39m logging\u001b[38;5;241m.\u001b[39mNOTSET),\n\u001b[1;32m    540\u001b[0m )\n\u001b[0;32m--> 541\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m r\u001b[38;5;241m.\u001b[39miter_content(chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m):\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunk:  \u001b[38;5;66;03m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[1;32m    543\u001b[0m         progress\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(chunk))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/response.py:576\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp):\n\u001b[0;32m--> 576\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    578\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m    579\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/response.py:519\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    518\u001b[0m     cache_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    521\u001b[0m         amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data\n\u001b[1;32m    522\u001b[0m     ):  \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[1;32m    529\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[1;32m    530\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:466\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 466\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1303\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1300\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1301\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1302\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1305\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1159\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1159\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1161\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "logs_path = Path.cwd() / \"logs\" / \"lightning_logs\"\n",
    "train = True\n",
    "\n",
    "seeds = [6, 90, 157]\n",
    "\n",
    "epochs = 15\n",
    "output_dim = len(level_3_categories)\n",
    "\n",
    "backbones = {\n",
    "    \"bert-base-uncased\": BertModel.from_pretrained(\"bert-base-uncased\"),\n",
    "    \"roberta-base\": BertModel.from_pretrained(\"roberta-base\"),\n",
    "}\n",
    "\n",
    "tokenizers = {\n",
    "    \"bert-base-uncased\": BertTokenizer.from_pretrained(\"bert-base-uncased\"),\n",
    "    \"roberta-base\": BertTokenizer.from_pretrained(\"roberta-base\"),\n",
    "}\n",
    "\n",
    "backbone_name = \"bert-base-uncased\"\n",
    "backbone = backbones[backbone_name]\n",
    "tokenizer = tokenizers[backbone_name]\n",
    "clf_input_size = backbone.config.hidden_size\n",
    "\n",
    "model_classes = [BertConclusion, BertPremiseConclusion, BertPremiseConclusionStance]\n",
    "model_names = [\"bert_w_c\", \"bert_w_cp\", \"bert_w_cps\"]\n",
    "hyperparameters = [\n",
    "    {'bert_model_name': 'bert-base-uncased', 'num_classes': output_dim, \"backbone\": backbone, \"tokenizer\": tokenizer, \"clf_input_size\": clf_input_size},\n",
    "    {'bert_model_name': 'bert-base-uncased', 'num_classes': output_dim, \"backbone\": backbone, \"tokenizer\": tokenizer, \"clf_input_size\": clf_input_size},\n",
    "    {'bert_model_name': 'bert-base-uncased', 'num_classes': output_dim, \"backbone\": backbone, \"tokenizer\": tokenizer, \"clf_input_size\": clf_input_size}\n",
    "]\n",
    "\n",
    "if train:\n",
    "    for model_class, model_name, hyperparameter in zip(model_classes, model_names, hyperparameters):\n",
    "        for seed in seeds:\n",
    "            print(f\"Training model {model_name} with seed {seed}...\")\n",
    "            seed_everything(seed, workers=True)\n",
    "\n",
    "            model = model_class(**hyperparameter)\n",
    "\n",
    "            logger = TensorBoardLogger(logs_path, name=f\"{model_name}_seed{seed}\")\n",
    "            checkpoint_callback = ModelCheckpoint(\n",
    "                monitor='val_loss',\n",
    "                dirpath=None,\n",
    "                filename=f'{model_name}-seed={seed}-backbone={backbone_name}' + '-{epoch:02d}-{val_loss:.2f}-{val_f1:.2f}',\n",
    "                save_top_k=1,\n",
    "            )\n",
    "            early_stop_callback = EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=3,\n",
    "                verbose=True,\n",
    "                mode='min'\n",
    "            )\n",
    "\n",
    "            trainer = Trainer(\n",
    "                max_epochs=epochs,\n",
    "                logger=logger,\n",
    "                log_every_n_steps=1,\n",
    "                callbacks=[checkpoint_callback, early_stop_callback],\n",
    "                deterministic=True\n",
    "            )\n",
    "\n",
    "            trainer.fit(model, train_dataloader, val_dataloader)\n",
    "else:\n",
    "    print(\"Skipping training...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0839fab615304c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:48:04.171446700Z",
     "start_time": "2023-12-10T16:48:04.167175500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Definition of some utility functions\n",
    "\n",
    "def model_predict(model, dataloader):\n",
    "    model.eval()  \n",
    "\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            X = {key:value for key, value in batch.items() if key != \"labels\"}\n",
    "\n",
    "            batch_predictions = model(X)\n",
    "\n",
    "            predictions.append(batch_predictions)\n",
    "\n",
    "    all_predictions = torch.cat(predictions)\n",
    "\n",
    "    return all_predictions\n",
    "\n",
    "def evaluate_model(model, loader):    \n",
    "    prediction = model_predict(model, loader)\n",
    "\n",
    "    f1_metric = MultilabelF1Score(num_labels=4, average=None, multidim_average='global')    # TODO: shouldn't we be using binary F1 Score here?\n",
    "    \n",
    "    #Take the target from the loader\n",
    "    target = torch.cat([data[\"labels\"] for data in loader], dim=0)\n",
    "\n",
    "    results = f1_metric(prediction, target)\n",
    "    average = sum(results) / 4\n",
    "\n",
    "    return results, average\n",
    "\n",
    "def load_model(model_name, model_path):\n",
    "    if model_name == \"bert_w_c\":\n",
    "        cls = BertConclusion\n",
    "    elif model_name == \"bert_w_cp\":\n",
    "        cls = BertPremiseConclusion\n",
    "    elif model_name == \"bert_w_cps\":\n",
    "        cls = BertPremiseConclusionStance\n",
    "    else:\n",
    "        raise ValueError(f\"Model name {model_name} not recognized.\")\n",
    "    hparams_path = Path(model_path).parent.parent / \"hparams.yaml\"\n",
    "    \n",
    "    model = cls.load_from_checkpoint(model_path, hparams_file=hparams_path)\n",
    "    model.freeze()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a05ea9d9aa6539",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:48:00.980078700Z",
     "start_time": "2023-12-10T16:47:36.753386800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=[\"Model\", \"Seed\", \"F1 Score\"] + level_3_categories)\n",
    "\n",
    "for model_name in model_names:\n",
    "    print(f\"Evaluating model {model_name}...\")\n",
    "    for seed in seeds:\n",
    "        model_folder = logs_path / f\"{model_name}_seed{seed}\"\n",
    "        \n",
    "        version_folders = os.listdir(model_folder)\n",
    "        versions = [int(x.split(\"_\")[1]) for x in version_folders]\n",
    "        latest_version = max(versions)  \n",
    "        version_folder = model_folder / f\"version_{latest_version}\"\n",
    "        \n",
    "        checkpoint_folder = version_folder / \"checkpoints\"\n",
    "        checkpoint_path = list(checkpoint_folder.glob(\"*.ckpt\"))[0]\n",
    "        \n",
    "        model = load_model(model_name, checkpoint_path)\n",
    "        results, average = evaluate_model(model, test_dataloader)\n",
    "        \n",
    "        temp = pd.DataFrame({\n",
    "            \"Model\": model_name,\n",
    "            \"Seed\": seed,\n",
    "            \"F1 Score\": average.item(),\n",
    "            **{category: f1.item() for category, f1 in zip(level_3_categories, results)},\n",
    "            \"Checkpoint path\": checkpoint_path \n",
    "        }, index=[0])\n",
    "        \n",
    "        results_df = pd.concat([results_df, temp], ignore_index=True)\n",
    "        \n",
    "        print(f\"Seed {seed}:\")\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9937ee",
   "metadata": {},
   "source": [
    "## Task 5: Error analysis\n",
    "You are tasked to discuss your results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aeb6704",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "* **Compare** classification performance of BERT-based models with respect to baselines.\n",
    "* Discuss **difference in prediction** between the best performing BERT-based model and its variants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43da156",
   "metadata": {},
   "source": [
    "### Best model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4f764a455f16dc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_model_row = None\n",
    "\n",
    "for row in results_df.itertuples():\n",
    "    if best_model_row is None or row[\"F1 Score\"] > best_model_row[\"F1 Score\"]:\n",
    "        best_model_row = row\n",
    "        \n",
    "best_model = load_model(best_model_row[\"Model\"], best_model_row[\"Checkpoint path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220cfc0f90823351",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:49:21.969441700Z",
     "start_time": "2023-12-10T16:49:20.329955700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_model = load_model(\"bert_w_c\", \"./logs/lightning_logs/bert_w_c_seed6/version_0/checkpoints/bert_w_c-seed=6-epoch=00-val_loss=0.64-val_f1=0.00.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9646e0c",
   "metadata": {},
   "source": [
    "#### Precision/Recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c596864e44c68068",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:59:26.915219500Z",
     "start_time": "2023-12-10T16:59:25.202145100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "small_test_dataset = ArgumentDataset(df_test[:50])\n",
    "loader = DataLoader(small_test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "precision_curve = PrecisionRecallCurve(task=\"multilabel\", num_labels=4)\n",
    "\n",
    "y_pred = model_predict(best_model, loader)\n",
    "\n",
    "y_true = torch.cat([data[\"labels\"] for data in loader], dim=0)\n",
    "y_true = y_true.type(torch.LongTensor)\n",
    "\n",
    "curve = precision_curve(y_pred, y_true)\n",
    "precision, recall, _ = curve\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.grid()\n",
    "\n",
    "label_to_auc = {}\n",
    "for i in range(len(level_3_categories)):\n",
    "    label = level_3_categories[i]\n",
    "    auc = -1 * torch.trapz(precision[i], recall[i])\n",
    "    \n",
    "    label_to_auc[label] = auc.item()\n",
    "    \n",
    "    plt.plot(recall[i], precision[i], label=f\"{label}: {auc:.2f}\")\n",
    "\n",
    "plt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e157f7a7",
   "metadata": {},
   "source": [
    "#### Confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9054e8b02b426438",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T17:13:41.924346200Z",
     "start_time": "2023-12-10T17:13:41.738516Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confusion_matrix_metric = MultilabelConfusionMatrix(num_labels=len(level_3_categories))\n",
    "\n",
    "confusion_matrix = confusion_matrix_metric(y_pred, y_true)\n",
    "\n",
    "# Craete a subplot for each category\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axs = axs.flatten()\n",
    "\n",
    "\n",
    "for i, category in enumerate(level_3_categories):\n",
    "    axs[i].imshow(confusion_matrix[i].numpy(), cmap=\"Blues\")\n",
    "    axs[i].set_title(category)\n",
    "    axs[i].set_xlabel(\"Predicted label\")\n",
    "    axs[i].set_ylabel(\"True label\")\n",
    "    axs[i].set_xticks([0, 1])\n",
    "    axs[i].set_yticks([0, 1])\n",
    "    axs[i].set_xticklabels([\"Positive\", \"Negative\"])\n",
    "    axs[i].set_yticklabels([\"Positive\", \"Negative\"])\n",
    "    axs[i].grid(False)\n",
    "    \n",
    "    # add the values to the plot\n",
    "    for k in range(2):\n",
    "        for j in range(2):\n",
    "            axs[i].text(k, j, confusion_matrix[i][k, j].item(), ha=\"center\", va=\"center\", color=\"Red\", fontsize=20)\n",
    "    \n",
    "#\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dd7bd9",
   "metadata": {},
   "source": [
    "### Best model vs baselines"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
