{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 - Human Value Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f812147f55c0220",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:22.961453700Z",
     "start_time": "2023-12-10T16:15:10.114241800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !pip install lightning\n",
    "# !pip install torchmetrics\n",
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b3cd2c7bd257608",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.149703Z",
     "start_time": "2023-12-10T16:15:22.963513600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# file management\n",
    "import urllib.request\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# torchmetrics\n",
    "from torchmetrics import PrecisionRecallCurve\n",
    "from torchmetrics.classification import MultilabelConfusionMatrix\n",
    "\n",
    "# pytorch lightning\n",
    "from lightning import LightningModule\n",
    "from lightning.pytorch import Trainer, seed_everything\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from torchmetrics.classification import MultilabelF1Score\n",
    "from torchmetrics import Metric\n",
    "from torchmetrics import ConfusionMatrix\n",
    "\n",
    "# transformers\n",
    "from transformers import BertModel, BertTokenizer, RobertaModel, RobertaTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1: Corpus\n",
    "\n",
    "* **Download** the specificed training, validation, and test files.\n",
    "* **Encode** split files into a pandas.DataFrame object.\n",
    "* For each split, **merge** the arguments and labels dataframes into a single dataframe.\n",
    "* **Merge** level 2 annotations to level 3 categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4516ac9d641c89e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.166590900Z",
     "start_time": "2023-12-10T16:15:24.150726800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File arguments-training.tsv already exists. Skipping download...\n",
      "File arguments-test.tsv already exists. Skipping download...\n",
      "File arguments-validation.tsv already exists. Skipping download...\n",
      "File labels-training.tsv already exists. Skipping download...\n",
      "File labels-test.tsv already exists. Skipping download...\n",
      "File labels-validation.tsv already exists. Skipping download...\n"
     ]
    }
   ],
   "source": [
    "# download data from url and save it to the data folder\n",
    "\n",
    "file_names = [\n",
    "    \"arguments-training.tsv\",\n",
    "    \"arguments-test.tsv\",\n",
    "    \"arguments-validation.tsv\",\n",
    "    \"labels-training.tsv\",\n",
    "    \"labels-test.tsv\",\n",
    "    \"labels-validation.tsv\"\n",
    "]\n",
    "\n",
    "# Create the data folder\n",
    "if not os.path.exists(\"./data\"):\n",
    "    os.makedirs(\"./data\")\n",
    "\n",
    "url = \"https://zenodo.org/records/8248658/files/{file_name}?download=1\"\n",
    "for file_name in file_names:\n",
    "    if os.path.exists(f\"./data/{file_name}\"):\n",
    "        print(f\"File {file_name} already exists. Skipping download...\")\n",
    "        continue\n",
    "\n",
    "    file_url = url.format(file_name=file_name)\n",
    "    print(f\"Downloading {file_name} from {file_url}...\")        \n",
    "    urllib.request.urlretrieve(url.format(file_name=file_name), f\"./data/{file_name}\")\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.212916600Z",
     "start_time": "2023-12-10T16:15:24.166590900Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Argument ID</th>\n",
       "      <th>Self-direction: thought</th>\n",
       "      <th>Self-direction: action</th>\n",
       "      <th>Stimulation</th>\n",
       "      <th>Hedonism</th>\n",
       "      <th>Achievement</th>\n",
       "      <th>Power: dominance</th>\n",
       "      <th>Power: resources</th>\n",
       "      <th>Face</th>\n",
       "      <th>Security: personal</th>\n",
       "      <th>...</th>\n",
       "      <th>Tradition</th>\n",
       "      <th>Conformity: rules</th>\n",
       "      <th>Conformity: interpersonal</th>\n",
       "      <th>Humility</th>\n",
       "      <th>Benevolence: caring</th>\n",
       "      <th>Benevolence: dependability</th>\n",
       "      <th>Universalism: concern</th>\n",
       "      <th>Universalism: nature</th>\n",
       "      <th>Universalism: tolerance</th>\n",
       "      <th>Universalism: objectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A26004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A26010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A26016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A26024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A26026</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Argument ID  Self-direction: thought  Self-direction: action  Stimulation  \\\n",
       "0      A26004                        0                       0            0   \n",
       "1      A26010                        0                       0            0   \n",
       "2      A26016                        0                       0            0   \n",
       "3      A26024                        0                       0            0   \n",
       "4      A26026                        0                       0            0   \n",
       "\n",
       "   Hedonism  Achievement  Power: dominance  Power: resources  Face  \\\n",
       "0         0            1                 0                 0     0   \n",
       "1         0            1                 0                 0     0   \n",
       "2         0            1                 0                 0     0   \n",
       "3         0            1                 0                 0     0   \n",
       "4         0            1                 0                 0     0   \n",
       "\n",
       "   Security: personal  ...  Tradition  Conformity: rules  \\\n",
       "0                   1  ...          0                  0   \n",
       "1                   0  ...          0                  0   \n",
       "2                   1  ...          0                  0   \n",
       "3                   0  ...          0                  0   \n",
       "4                   1  ...          0                  0   \n",
       "\n",
       "   Conformity: interpersonal  Humility  Benevolence: caring  \\\n",
       "0                          0         0                    0   \n",
       "1                          0         0                    0   \n",
       "2                          0         0                    0   \n",
       "3                          0         0                    0   \n",
       "4                          0         0                    1   \n",
       "\n",
       "   Benevolence: dependability  Universalism: concern  Universalism: nature  \\\n",
       "0                           0                      1                     0   \n",
       "1                           0                      1                     0   \n",
       "2                           1                      1                     0   \n",
       "3                           0                      0                     0   \n",
       "4                           1                      0                     0   \n",
       "\n",
       "   Universalism: tolerance  Universalism: objectivity  \n",
       "0                        1                          0  \n",
       "1                        1                          1  \n",
       "2                        0                          0  \n",
       "3                        0                          0  \n",
       "4                        0                          0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the dataframes\n",
    "df_arg_train = pd.read_csv('./data/arguments-training.tsv', sep='\\t')\n",
    "df_arg_test = pd.read_csv('./data/arguments-test.tsv', sep='\\t')\n",
    "df_arg_val = pd.read_csv('./data/arguments-validation.tsv', sep='\\t')\n",
    "\n",
    "df_labels_train = pd.read_csv('./data/labels-training.tsv', sep='\\t')\n",
    "df_labels_test = pd.read_csv('./data/labels-test.tsv', sep='\\t')\n",
    "df_labels_val = pd.read_csv('./data/labels-validation.tsv', sep='\\t')\n",
    "\n",
    "df_labels_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotations\n",
    "Since the task requires only to take in account *level 3 categories* a mapping between *level 2* and *level 3* is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2b4fe2c6cb107d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.255091700Z",
     "start_time": "2023-12-10T16:15:24.214959700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Argument ID</th>\n",
       "      <th>Openness to change</th>\n",
       "      <th>Self-enhancement</th>\n",
       "      <th>Conservation</th>\n",
       "      <th>Self-transcendence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A26004</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A26010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A26016</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A26024</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A26026</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Argument ID  Openness to change  Self-enhancement  Conservation  \\\n",
       "0      A26004                   0                 1             1   \n",
       "1      A26010                   0                 1             0   \n",
       "2      A26016                   0                 1             1   \n",
       "3      A26024                   0                 1             0   \n",
       "4      A26026                   0                 1             1   \n",
       "\n",
       "   Self-transcendence  \n",
       "0                   1  \n",
       "1                   1  \n",
       "2                   1  \n",
       "3                   0  \n",
       "4                   1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_3_categories = [\"Openness to change\", \"Self-enhancement\", \"Conservation\", \"Self-transcendence\"]\n",
    "\n",
    "level_3_to_2_mapping = {\n",
    "    \"Openness to change\": [\n",
    "        \"Self-direction: thought\",\n",
    "        \"Self-direction: action\",\n",
    "        \"Stimulation\",\n",
    "        \"Hedonism\",\n",
    "    ],\n",
    "    \"Self-enhancement\": [\n",
    "        \"Hedonism\",\n",
    "        \"Achievement\",\n",
    "        \"Power: dominance\",\n",
    "        \"Power: resources\",\n",
    "        \"Face\",\n",
    "    ],\n",
    "    \"Conservation\": [\n",
    "        \"Security: personal\",\n",
    "        \"Security: societal\",\n",
    "        \"Conformity: rules\",\n",
    "        \"Conformity: interpersonal\",\n",
    "        \"Tradition\",\n",
    "        \"Face\",\n",
    "        \"Humility\",\n",
    "    ],\n",
    "    \"Self-transcendence\": [\n",
    "        \"Benevolence: caring\",\n",
    "        \"Benevolence: dependability\",\n",
    "        \"Universalism: concern\",\n",
    "        \"Universalism: nature\",\n",
    "        \"Universalism: tolerance\",\n",
    "        \"Universalism: objectivity\",\n",
    "        \"Humility\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "column_to_drop = [level_2 for level_3 in level_3_to_2_mapping.values() for level_2 in level_3]\n",
    "\n",
    "for category in level_3_categories:\n",
    "    # make a logical OR of all the level 2 categories\n",
    "    df_labels_test[category] = df_labels_test[level_3_to_2_mapping[category]].any(axis=1).map({True: 1, False: 0})\n",
    "    df_labels_val[category] = df_labels_val[level_3_to_2_mapping[category]].any(axis=1).map({True: 1, False: 0})\n",
    "    df_labels_train[category] = df_labels_train[level_3_to_2_mapping[category]].any(axis=1).map({True: 1, False: 0})\n",
    "\n",
    "df_labels_test = df_labels_test.drop(columns=column_to_drop)\n",
    "df_labels_val = df_labels_val.drop(columns=column_to_drop)\n",
    "df_labels_train = df_labels_train.drop(columns=column_to_drop)\n",
    "\n",
    "df_labels_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8316839c9de44b89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.274578600Z",
     "start_time": "2023-12-10T16:15:24.244896500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Argument ID</th>\n",
       "      <th>Conclusion</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Premise</th>\n",
       "      <th>Openness to change</th>\n",
       "      <th>Self-enhancement</th>\n",
       "      <th>Conservation</th>\n",
       "      <th>Self-transcendence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A01002</td>\n",
       "      <td>We should ban human cloning</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>we should ban human cloning as it will only ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A01005</td>\n",
       "      <td>We should ban fast food</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>fast food should be banned because it is reall...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A01006</td>\n",
       "      <td>We should end the use of economic sanctions</td>\n",
       "      <td>against</td>\n",
       "      <td>sometimes economic sanctions are the only thin...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A01007</td>\n",
       "      <td>We should abolish capital punishment</td>\n",
       "      <td>against</td>\n",
       "      <td>capital punishment is sometimes the only optio...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A01008</td>\n",
       "      <td>We should ban factory farming</td>\n",
       "      <td>against</td>\n",
       "      <td>factory farming allows for the production of c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Argument ID                                   Conclusion       Stance  \\\n",
       "0      A01002                  We should ban human cloning  in favor of   \n",
       "1      A01005                      We should ban fast food  in favor of   \n",
       "2      A01006  We should end the use of economic sanctions      against   \n",
       "3      A01007         We should abolish capital punishment      against   \n",
       "4      A01008                We should ban factory farming      against   \n",
       "\n",
       "                                             Premise  Openness to change  \\\n",
       "0  we should ban human cloning as it will only ca...                   0   \n",
       "1  fast food should be banned because it is reall...                   0   \n",
       "2  sometimes economic sanctions are the only thin...                   0   \n",
       "3  capital punishment is sometimes the only optio...                   0   \n",
       "4  factory farming allows for the production of c...                   0   \n",
       "\n",
       "   Self-enhancement  Conservation  Self-transcendence  \n",
       "0                 0             1                   0  \n",
       "1                 0             1                   0  \n",
       "2                 1             1                   0  \n",
       "3                 0             1                   1  \n",
       "4                 0             1                   1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.merge(df_arg_train, df_labels_train, on='Argument ID')\n",
    "df_test = pd.merge(df_arg_test, df_labels_test, on='Argument ID')\n",
    "df_val = pd.merge(df_arg_val, df_labels_val, on='Argument ID')\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cdfe3378972543",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Task 1.5 - stance encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "232f6776a1ee9a80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.290104800Z",
     "start_time": "2023-12-10T16:15:24.260231300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Argument ID</th>\n",
       "      <th>Conclusion</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Premise</th>\n",
       "      <th>Openness to change</th>\n",
       "      <th>Self-enhancement</th>\n",
       "      <th>Conservation</th>\n",
       "      <th>Self-transcendence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A01002</td>\n",
       "      <td>We should ban human cloning</td>\n",
       "      <td>1</td>\n",
       "      <td>we should ban human cloning as it will only ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A01005</td>\n",
       "      <td>We should ban fast food</td>\n",
       "      <td>1</td>\n",
       "      <td>fast food should be banned because it is reall...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A01006</td>\n",
       "      <td>We should end the use of economic sanctions</td>\n",
       "      <td>0</td>\n",
       "      <td>sometimes economic sanctions are the only thin...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A01007</td>\n",
       "      <td>We should abolish capital punishment</td>\n",
       "      <td>0</td>\n",
       "      <td>capital punishment is sometimes the only optio...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A01008</td>\n",
       "      <td>We should ban factory farming</td>\n",
       "      <td>0</td>\n",
       "      <td>factory farming allows for the production of c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Argument ID                                   Conclusion  Stance  \\\n",
       "0      A01002                  We should ban human cloning       1   \n",
       "1      A01005                      We should ban fast food       1   \n",
       "2      A01006  We should end the use of economic sanctions       0   \n",
       "3      A01007         We should abolish capital punishment       0   \n",
       "4      A01008                We should ban factory farming       0   \n",
       "\n",
       "                                             Premise  Openness to change  \\\n",
       "0  we should ban human cloning as it will only ca...                   0   \n",
       "1  fast food should be banned because it is reall...                   0   \n",
       "2  sometimes economic sanctions are the only thin...                   0   \n",
       "3  capital punishment is sometimes the only optio...                   0   \n",
       "4  factory farming allows for the production of c...                   0   \n",
       "\n",
       "   Self-enhancement  Conservation  Self-transcendence  \n",
       "0                 0             1                   0  \n",
       "1                 0             1                   0  \n",
       "2                 1             1                   0  \n",
       "3                 0             1                   1  \n",
       "4                 0             1                   1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode stance into 0, 1 \n",
    "df_train[\"Stance\"] = df_train[\"Stance\"].map({\"in favor of\": 1, \"against\": 0})\n",
    "df_test[\"Stance\"] = df_test[\"Stance\"].map({\"in favor of\": 1, \"against\": 0})\n",
    "df_val[\"Stance\"] = df_val[\"Stance\"].map({\"in favor of\": 1, \"against\": 0})\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77076cfdcc028fa7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Dataset definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecad75b6100c0040",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.359095Z",
     "start_time": "2023-12-10T16:15:24.275596200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ArgumentDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        return {\n",
    "            \"Premise\": row[\"Premise\"],\n",
    "            \"Conclusion\": row[\"Conclusion\"],\n",
    "            \"labels\": torch.tensor(row[level_3_categories].values.tolist(), dtype=torch.float32),\n",
    "            \"Stance\": torch.tensor(row[\"Stance\"], dtype=torch.float32)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94fe31d775254160",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.377556300Z",
     "start_time": "2023-12-10T16:15:24.290104800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Premise': 'we should ban human cloning as it will only cause huge issues when you have a bunch of the same humans running around all acting the same.', 'Conclusion': 'We should ban human cloning', 'labels': tensor([0., 0., 1., 0.]), 'Stance': tensor(1.)}\n",
      "{'Premise': 'fast food should be banned because it is really bad for your health and is costly.', 'Conclusion': 'We should ban fast food', 'labels': tensor([0., 0., 1., 0.]), 'Stance': tensor(1.)}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = ArgumentDataset(df_train)\n",
    "test_dataset = ArgumentDataset(df_test)\n",
    "val_dataset = ArgumentDataset(df_val)\n",
    "\n",
    "# Create the dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(train_dataset[0])\n",
    "print(train_dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 3: Metrics\n",
    "\n",
    "### Instructions\n",
    "\n",
    "* Evaluate your models using per-category binary F1-score.\n",
    "* Compute the average binary F1-score over all categories (macro F1-score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1ScoreCumulative(Metric):\n",
    "    def __init__(self, num_classes: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.add_state(\"true_positive\", default=torch.zeros([num_classes]), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"false_negative\", default=torch.zeros([num_classes]), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"false_positive\", default=torch.zeros([num_classes]), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, y_hat: torch.Tensor, y: torch.Tensor):\n",
    "        \n",
    "        for i in range(self.num_classes):\n",
    "            true_positive = torch.sum((y_hat[:, i] == 1) & (y[:, i] == 1))\n",
    "            false_negative = torch.sum((y_hat[:, i] == 0) & (y[:, i] == 1))\n",
    "            false_positive = torch.sum((y_hat[:, i] == 1) & (y[:, i] == 0))\n",
    "\n",
    "            self.true_positive[i] += true_positive\n",
    "            self.false_negative[i] += false_negative\n",
    "            self.false_positive[i] += false_positive\n",
    "\n",
    "    def compute(self):\n",
    "        precision = self.true_positive / (self.true_positive + self.false_positive)\n",
    "        recall = self.true_positive / (self.true_positive + self.false_negative)\n",
    "\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        \n",
    "        # If there are not enough data to compute the f1 score, set it to 0\n",
    "        if f1.isnan().any():\n",
    "            f1[f1.isnan()] = 0\n",
    "\n",
    "        return f1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ffa5c2876fecbf",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## TASK 2: Model definition\n",
    "\n",
    "* **Baseline**: implement a random uniform classifier (an individual classifier per category).\n",
    "* **Baseline**: implement a majority classifier (an individual classifier per category).\n",
    "\n",
    "<br/>\n",
    "\n",
    "* **BERT w/ C**: define a BERT-based classifier that receives an argument **conclusion** as input.\n",
    "* **BERT w/ CP**: add argument **premise** as an additional input.\n",
    "* **BERT w/ CPS**: add argument premise-to-conclusion **stance** as an additional input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbd8b41505ded6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Baselines: random uniform classifier and majority classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "331380fdc13c462f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.395023600Z",
     "start_time": "2023-12-10T16:15:24.308674Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO - check if this is correct or we need to define 4 different models\n",
    "class RandomUniformClassifier(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._random_state = np.random.RandomState()\n",
    "\n",
    "    def predict(self, X):\n",
    "        batch_size = len(X[\"Conclusion\"])\n",
    "        logits = self._random_state.uniform(size=(batch_size, 4))\n",
    "        logits = logits > 0.5\n",
    "        return torch.tensor(logits, dtype=torch.float32)\n",
    "\n",
    "\n",
    "class MajorityClassifier(LightningModule):\n",
    "    def __init__(self, n_random_classifiers=10):\n",
    "        super().__init__()\n",
    "        self.n_random_classifiers = n_random_classifiers\n",
    "        self.random_classifiers = [RandomUniformClassifier() for _ in range(n_random_classifiers)]\n",
    "\n",
    "    def predict(self, X):\n",
    "        batch_size = len(X[\"Conclusion\"])\n",
    "        votes = torch.zeros((batch_size, 4))\n",
    "        for clf in self.random_classifiers:\n",
    "            votes += clf.predict(X)\n",
    "        \n",
    "        votes = votes / self.n_random_classifiers\n",
    "        predictions = torch.zeros((batch_size, 4))\n",
    "        predictions[votes > 0.5] = 1\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85576b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for loading the backbon given the name\n",
    "def load_backbone(backbone_name):\n",
    "    if backbone_name == \"bert-base-uncased\":\n",
    "        backbone = BertModel.from_pretrained(backbone_name)\n",
    "        tokenizer = BertTokenizer.from_pretrained(backbone_name)\n",
    "    elif backbone_name == \"roberta-base\":\n",
    "        backbone = RobertaModel.from_pretrained(backbone_name)\n",
    "        tokenizer = RobertaTokenizer.from_pretrained(backbone_name)\n",
    "    else:\n",
    "        raise ValueError(f\"Backbone {backbone_name} not supported\")\n",
    "\n",
    "    return backbone, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab6e80eded57efb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Bert models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc849dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationHead(LightningModule):\n",
    "    def __init__(self, in_size, hidden_size, n_classes):\n",
    "        super().__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self.activation = nn.Sigmoid()\n",
    "        self.l1 = nn.Linear(in_size, hidden_size)\n",
    "        self.l2 = nn.Linear(hidden_size, n_classes)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.l2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eef0d525e8b3e87e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.441482700Z",
     "start_time": "2023-12-10T16:15:24.326135400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BertConclusion(LightningModule):\n",
    "    def __init__(self, bert_model_name, hidden_size, num_classes, lr, model_type=\"Conclusion\"):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=['backbone', 'tokenizer'])\n",
    "        self.backbone, self.tokenizer = load_backbone(bert_model_name)\n",
    "\n",
    "        self.lr = lr\n",
    "        \n",
    "        # Define the input size of the classification head\n",
    "        if model_type == \"Conclusion\":\n",
    "            self.clf_input_size = self.backbone.config.hidden_size\n",
    "        elif model_type == \"Premise\":\n",
    "            self.clf_input_size = self.backbone.config.hidden_size*2\n",
    "        elif model_type == \"Stance\":\n",
    "            self.clf_input_size = self.backbone.config.hidden_size*2 + 1\n",
    "        else:\n",
    "            raise ValueError(f\"Model type {model_type} not supported. Supported model types: ['Conclusion', 'Premise', 'Stance']\")\n",
    "\n",
    "        # freeze bert layers\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.classifier = ClassificationHead(self.clf_input_size, hidden_size, num_classes)\n",
    "        \n",
    "        self._f1_train = F1ScoreCumulative(num_classes=num_classes)\n",
    "        self._f1_val = F1ScoreCumulative(num_classes=num_classes)\n",
    "        self._f1_test = F1ScoreCumulative(num_classes=num_classes)\n",
    "\n",
    "        self.f1_metrics = {\n",
    "            \"train\": self._f1_train,\n",
    "            \"val\": self._f1_val,\n",
    "            \"test\": self._f1_test\n",
    "        }\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "    \n",
    "    def on_save_checkpoint(checkpoint):\n",
    "        # pop the backbone here using custom logic\n",
    "        del checkpoint['state_dict']['backbone']\n",
    "\n",
    "    def encode(self, X):\n",
    "        encoded = self.tokenizer(X, padding=True, return_tensors=\"pt\").to(device)\n",
    "        model_output = self.backbone(**encoded)['last_hidden_state']\n",
    "\n",
    "        return model_output[:, 0, :].to(device)\n",
    "\n",
    "    def forward(self, X_data):\n",
    "        X = X_data[\"Conclusion\"]\n",
    "\n",
    "        encoded = self.encode(X)\n",
    "\n",
    "        # last_hidden_state contains the hidden representations for each token in each sequence of the batch:\n",
    "        # shape is (batch_size, seq_len, hidden_size)\n",
    "        # we only need the representation of the first token (the [CLS] token)\n",
    "        logits = self.classifier(encoded)\n",
    "        return logits\n",
    "    \n",
    "    def predict(self, X):\n",
    "        logits = self(X)\n",
    "        y_hat = torch.zeros_like(logits)\n",
    "        y_hat[torch.nn.functional.sigmoid(logits) > 0.5] = 1\n",
    "        return y_hat\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        data = batch\n",
    "        X_data = {key:value for key, value in data.items() if key != \"labels\"}\n",
    "        y = data[\"labels\"]\n",
    "\n",
    "        logits = self(X_data)\n",
    "\n",
    "        loss = nn.BCEWithLogitsLoss()(logits, y)\n",
    "        \n",
    "        self.log(\"train_loss\", loss, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        # Get predictions\n",
    "        y_hat = torch.zeros_like(y)\n",
    "        y_hat[torch.nn.functional.sigmoid(logits) > 0.5] = 1\n",
    "        self.f1_metrics[\"train\"].update(y_hat, y)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        data = batch\n",
    "        X = {key:value for key, value in data.items() if key != \"labels\"}\n",
    "        y = data[\"labels\"]\n",
    "\n",
    "        logits = self(X)\n",
    "\n",
    "        loss = nn.BCEWithLogitsLoss()(logits, y)\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        y_hat = torch.zeros_like(y)\n",
    "        y_hat[torch.nn.functional.sigmoid(logits) > 0.5] = 1\n",
    "        self.f1_metrics[\"val\"].update(y_hat, y)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        data = batch\n",
    "        X = {key:value for key, value in data.items() if key != \"labels\"}\n",
    "        y = data[\"labels\"]\n",
    "\n",
    "        logits = self(X)\n",
    "\n",
    "        loss = nn.BCEWithLogitsLoss()(logits, y)\n",
    "\n",
    "        self.log(\"test_loss\", loss, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        y_hat = torch.zeros_like(y)\n",
    "        y_hat[torch.nn.functional.sigmoid(logits) > 0.5] = 1\n",
    "        self.f1_metrics[\"test\"].update(y_hat, y)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def on_epoch_type_end(self, epoch_type) -> None:\n",
    "        f1_score_per_class = self.f1_metrics[epoch_type].compute()\n",
    "        f1_score_macro = f1_score_per_class.mean()\n",
    "\n",
    "        self.log(f\"{epoch_type}_f1_score\", f1_score_macro, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        for i, category in enumerate(level_3_categories):\n",
    "            self.log(f\"{epoch_type}_f1_score_{category}\", f1_score_per_class[i], on_epoch=True, prog_bar=True, logger=True)\n",
    "    \n",
    "        self.f1_metrics[epoch_type].reset()\n",
    "\n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        self.on_epoch_type_end(\"train\")\n",
    "\n",
    "    def on_validation_epoch_end(self) -> None:\n",
    "        self.on_epoch_type_end(\"val\")\n",
    "\n",
    "    def on_test_epoch_end(self) -> None:\n",
    "        self.on_epoch_type_end(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31dbbe5fe8eb3195",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.443528100Z",
     "start_time": "2023-12-10T16:15:24.357066200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BertPremiseConclusion(BertConclusion):\n",
    "    def __init__(self, bert_model_name, hidden_size, num_classes, lr, model_type=\"Premise\"):\n",
    "        super().__init__(bert_model_name, hidden_size, num_classes, lr, model_type)\n",
    "\n",
    "    def forward(self, X_data):\n",
    "        X_1 = X_data[\"Premise\"]\n",
    "        X_2 = X_data[\"Conclusion\"]\n",
    "\n",
    "        encoded_1 = self.encode(X_1)\n",
    "        encoded_2 = self.encode(X_2)\n",
    "\n",
    "        output = torch.cat((encoded_1, encoded_2), dim=1)\n",
    "\n",
    "        logits = self.classifier(output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b11eb0f4965923dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.444544200Z",
     "start_time": "2023-12-10T16:15:24.372404800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BertPremiseConclusionStance(BertConclusion):\n",
    "    def __init__(self, bert_model_name, hidden_size, num_classes, lr, model_type=\"Stance\"):\n",
    "        super().__init__(bert_model_name, hidden_size, num_classes, lr, model_type)\n",
    "                         \n",
    "\n",
    "    def forward(self, X_data):\n",
    "        X_1, X_2, stance = X_data[\"Premise\"], X_data[\"Conclusion\"], X_data[\"Stance\"]\n",
    "        \n",
    "        encoded_1 = self.encode(X_1)\n",
    "        encoded_2 = self.encode(X_2)\n",
    "        \n",
    "        stance = stance.unsqueeze(1)\n",
    "        output = torch.cat((encoded_1, encoded_2, stance), dim=1)\n",
    "        logits = self.classifier(output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4d886bff0ede4b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.444544200Z",
     "start_time": "2023-12-10T16:15:24.387844600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fix all possible sources of randomness\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87af0dff",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e755d7ef",
   "metadata": {},
   "source": [
    "## Task 4 Training and Evaluation\n",
    "\n",
    "You are now tasked to train and evaluate **all** defined models.\n",
    "* Train **all** models on the train set.\n",
    "* Evaluate **all** models on the validation set.\n",
    "* Pick **at least** three seeds for robust estimation.\n",
    "* Compute metrics on the validation set.\n",
    "* Report **per-category** and **macro** F1-score for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "499c93fc7632db8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.463035600Z",
     "start_time": "2023-12-10T16:15:24.406432500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping training...\n"
     ]
    }
   ],
   "source": [
    "logs_path = Path.cwd() / \"logs\" / \"lightning_logs\"\n",
    "train = False\n",
    "\n",
    "seeds = [6, 90, 157]\n",
    "\n",
    "epochs = 15\n",
    "output_dim = len(level_3_categories)\n",
    "\n",
    "\n",
    "\n",
    "bert_model_name = \"roberta-base\"\n",
    "hidden_size = 128\n",
    "lr = 0.01\n",
    "\n",
    "model_classes = [BertPremiseConclusion, BertPremiseConclusion, BertConclusion]\n",
    "model_names = [\"bert_w_cps\", \"bert_w_cp\", \"bert_w_s\"]\n",
    "hyperparameters = [\n",
    "    {'bert_model_name': bert_model_name, 'num_classes': output_dim, \"hidden_size\": hidden_size, \"lr\":lr},\n",
    "    {'bert_model_name': bert_model_name, 'num_classes': output_dim, \"hidden_size\": hidden_size, \"lr\":lr},\n",
    "    {'bert_model_name': bert_model_name, 'num_classes': output_dim, \"hidden_size\": hidden_size, \"lr\":lr}\n",
    "]\n",
    "\n",
    "if train:\n",
    "    for model_class, model_name, hyperparameter in zip(model_classes, model_names, hyperparameters):\n",
    "        for seed in seeds:\n",
    "            print(f\"Training model {model_name} with seed {seed}...\")\n",
    "            seed_everything(seed, workers=True)\n",
    "\n",
    "            model = model_class(**hyperparameter)\n",
    "\n",
    "            logger = TensorBoardLogger(logs_path, name=f\"{model_name}_seed{seed}\")\n",
    "            checkpoint_callback = ModelCheckpoint(\n",
    "                monitor='val_loss',\n",
    "                dirpath=None,\n",
    "                filename=f'{model_name}-seed={seed}-backbone={bert_model_name}' + '-{epoch:02d}-{val_loss:.2f}-{val_f1_score:.2f}',\n",
    "                save_top_k=1,\n",
    "            )\n",
    "            early_stop_callback = EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=3,\n",
    "                verbose=True,\n",
    "                mode='min'\n",
    "            )\n",
    "\n",
    "            trainer = Trainer(\n",
    "                max_epochs=epochs,\n",
    "                logger=logger,\n",
    "                log_every_n_steps=1,\n",
    "                callbacks=[checkpoint_callback, early_stop_callback],\n",
    "                deterministic=True\n",
    "            )\n",
    "\n",
    "            trainer.fit(model, train_dataloader, val_dataloader)\n",
    "else:\n",
    "    print(\"Skipping training...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c0839fab615304c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:48:04.171446700Z",
     "start_time": "2023-12-10T16:48:04.167175500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Definition of some utility functions\n",
    "\n",
    "def model_predict(model, dataloader):\n",
    "    model.eval()  \n",
    "\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            X = {key:value for key, value in batch.items() if key != \"labels\"}\n",
    "\n",
    "            batch_predictions = model.predict(X)\n",
    "\n",
    "            predictions.append(batch_predictions)\n",
    "\n",
    "    all_predictions = torch.cat(predictions)\n",
    "\n",
    "    return all_predictions\n",
    "\n",
    "def evaluate_model(model, loader):    \n",
    "    prediction = model_predict(model, loader)\n",
    "\n",
    "    f1_metric = MultilabelF1Score(num_labels=4, average=None, multidim_average='global')    # TODO: EDO shouldn't we be using binary F1 Score here?\n",
    "    \n",
    "    #Take the target from the loader\n",
    "    target = torch.cat([data[\"labels\"] for data in loader], dim=0)\n",
    "    print(\"Begore f1_metric\")\n",
    "    results = f1_metric(prediction, target)\n",
    "    average = sum(results) / 4\n",
    "\n",
    "    return results, average\n",
    "\n",
    "def load_model(model_name, model_path):\n",
    "    if model_name == \"bert_w_c\":\n",
    "        cls = BertConclusion\n",
    "    elif model_name == \"bert_w_cp\":\n",
    "        cls = BertPremiseConclusion\n",
    "    elif model_name == \"bert_w_cps\":\n",
    "        cls = BertPremiseConclusionStance\n",
    "    else:\n",
    "        raise ValueError(f\"Model name {model_name} not recognized.\")\n",
    "    hparams_path = Path(model_path).parent.parent / \"hparams.yaml\"\n",
    "    \n",
    "    model = cls.load_from_checkpoint(model_path, hparams_file=hparams_path, strict=False)\n",
    "    model.freeze()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17a05ea9d9aa6539",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:48:00.980078700Z",
     "start_time": "2023-12-10T16:47:36.753386800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model bert_w_cps...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [20], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m version_folder \u001b[38;5;241m=\u001b[39m model_folder \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlatest_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m checkpoint_folder \u001b[38;5;241m=\u001b[39m version_folder \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoints\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 14\u001b[0m checkpoint_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_folder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*.ckpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     16\u001b[0m model \u001b[38;5;241m=\u001b[39m load_model(model_name, checkpoint_path)\n\u001b[1;32m     17\u001b[0m results, average \u001b[38;5;241m=\u001b[39m evaluate_model(model, test_dataloader)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(columns=[\"Model\", \"Seed\", \"F1 Score\"] + level_3_categories)\n",
    "\n",
    "for model_name in model_names:\n",
    "    print(f\"Evaluating model {model_name}...\")\n",
    "    for seed in seeds:\n",
    "        model_folder = logs_path / f\"{model_name}_seed{seed}\"\n",
    "        \n",
    "        version_folders = os.listdir(model_folder)\n",
    "        versions = [int(x.split(\"_\")[1]) for x in version_folders]\n",
    "        latest_version = max(versions)  \n",
    "        version_folder = model_folder / f\"version_{latest_version}\"\n",
    "        \n",
    "        checkpoint_folder = version_folder / \"checkpoints\"\n",
    "        checkpoint_path = list(checkpoint_folder.glob(\"*.ckpt\"))[0]\n",
    "        \n",
    "        model = load_model(model_name, checkpoint_path)\n",
    "        results, average = evaluate_model(model, test_dataloader)\n",
    "        \n",
    "        temp = pd.DataFrame({\n",
    "            \"Model\": model_name,\n",
    "            \"Seed\": seed,\n",
    "            \"F1 Score\": average.item(),\n",
    "            **{category: f1.item() for category, f1 in zip(level_3_categories, results)},\n",
    "            \"Checkpoint path\": checkpoint_path \n",
    "        }, index=[0])\n",
    "        \n",
    "        results_df = pd.concat([results_df, temp], ignore_index=True)\n",
    "        \n",
    "        print(f\"Seed {seed}:\")\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9937ee",
   "metadata": {},
   "source": [
    "## Task 5: Error analysis\n",
    "You are tasked to discuss your results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aeb6704",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "* **Compare** classification performance of BERT-based models with respect to baselines.\n",
    "* Discuss **difference in prediction** between the best performing BERT-based model and its variants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43da156",
   "metadata": {},
   "source": [
    "### Best model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4f764a455f16dc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_model_row = None\n",
    "\n",
    "for row in results_df.itertuples():\n",
    "    if best_model_row is None or row[\"F1 Score\"] > best_model_row[\"F1 Score\"]:\n",
    "        best_model_row = row\n",
    "        \n",
    "best_model = load_model(best_model_row[\"Model\"], best_model_row[\"Checkpoint path\"])\n",
    "\n",
    "f1_score_best_average = best_model_row[\"F1 Score\"]\n",
    "f1_score_best = best_model_row[level_3_categories] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220cfc0f90823351",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:49:21.969441700Z",
     "start_time": "2023-12-10T16:49:20.329955700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_model = load_model(\"bert_w_c\", \"./logs/lightning_logs/bert_w_c_seed6/version_0/checkpoints/bert_w_c-seed=6-epoch=00-val_loss=0.64-val_f1=0.00.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9646e0c",
   "metadata": {},
   "source": [
    "#### Precision/Recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c596864e44c68068",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:59:26.915219500Z",
     "start_time": "2023-12-10T16:59:25.202145100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "small_test_dataset = ArgumentDataset(df_test[:50])\n",
    "loader = DataLoader(small_test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "precision_curve = PrecisionRecallCurve(task=\"multilabel\", num_labels=4)\n",
    "\n",
    "y_pred = model_predict(best_model, loader)\n",
    "\n",
    "y_true = torch.cat([data[\"labels\"] for data in loader], dim=0)\n",
    "y_true = y_true.type(torch.LongTensor)\n",
    "\n",
    "curve = precision_curve(y_pred, y_true)\n",
    "precision, recall, _ = curve\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.grid()\n",
    "\n",
    "label_to_auc = {}\n",
    "for i in range(len(level_3_categories)):\n",
    "    label = level_3_categories[i]\n",
    "    auc = -1 * torch.trapz(precision[i], recall[i])\n",
    "    \n",
    "    label_to_auc[label] = auc.item()\n",
    "    \n",
    "    plt.plot(recall[i], precision[i], label=f\"{label}: {auc:.2f}\")\n",
    "\n",
    "plt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e157f7a7",
   "metadata": {},
   "source": [
    "#### Confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9054e8b02b426438",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T17:13:41.924346200Z",
     "start_time": "2023-12-10T17:13:41.738516Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confusion_matrix_metric = MultilabelConfusionMatrix(num_labels=len(level_3_categories))\n",
    "\n",
    "confusion_matrix = confusion_matrix_metric(y_pred, y_true)\n",
    "\n",
    "# Craete a subplot for each category\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axs = axs.flatten()\n",
    "\n",
    "\n",
    "for i, category in enumerate(level_3_categories):\n",
    "    axs[i].imshow(confusion_matrix[i].numpy(), cmap=\"Blues\")\n",
    "    axs[i].set_title(category)\n",
    "    axs[i].set_xlabel(\"Predicted label\")\n",
    "    axs[i].set_ylabel(\"True label\")\n",
    "    axs[i].set_xticks([0, 1])\n",
    "    axs[i].set_yticks([0, 1])\n",
    "    axs[i].set_xticklabels([\"Positive\", \"Negative\"])\n",
    "    axs[i].set_yticklabels([\"Positive\", \"Negative\"])\n",
    "    axs[i].grid(False)\n",
    "    \n",
    "    # add the values to the plot\n",
    "    for k in range(2):\n",
    "        for j in range(2):\n",
    "            axs[i].text(k, j, confusion_matrix[i][k, j].item(), ha=\"center\", va=\"center\", color=\"Red\", fontsize=20)\n",
    "    \n",
    "#\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f967b0b9",
   "metadata": {},
   "source": [
    "#### Model performance on most/least frequent classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab4c83b",
   "metadata": {},
   "source": [
    "#### Specific misclassified examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dd7bd9",
   "metadata": {},
   "source": [
    "### Best model vs baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "934f9c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begore f1_metric\n",
      "Begore f1_metric\n"
     ]
    }
   ],
   "source": [
    "baseline_random = RandomUniformClassifier()\n",
    "baseline_majority = MajorityClassifier(n_random_classifiers=10)\n",
    "f1_score_random, f1_score_random_average = evaluate_model(baseline_random, test_dataloader)\n",
    "f1_score_majority, f1_score_majority_average = evaluate_model(baseline_majority, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "957ae5ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f1_score_best_average' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [42], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m baseline_comparison \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest model\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMajority\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1 Score\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[43mf1_score_best_average\u001b[49m , f1_score_random_average\u001b[38;5;241m.\u001b[39mitem(), f1_score_majority_average\u001b[38;5;241m.\u001b[39mitem()],\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{category: [f1_score_best[i]\u001b[38;5;241m.\u001b[39mitem(), f1_score_random[i]\u001b[38;5;241m.\u001b[39mitem(), f1_score_majority[i]\u001b[38;5;241m.\u001b[39mitem()] \u001b[38;5;28;01mfor\u001b[39;00m i, category \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(level_3_categories)}\n\u001b[1;32m      5\u001b[0m     }\n\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'f1_score_best_average' is not defined"
     ]
    }
   ],
   "source": [
    "baseline_comparison = pd.DataFrame({\n",
    "    \"Model\": [\"Best model\", \"Random\", \"Majority\"],\n",
    "    \"F1 Score\": [f1_score_best_average , f1_score_random_average.item(), f1_score_majority_average.item()],\n",
    "    **{category: [f1_score_best[i].item(), f1_score_random[i].item(), f1_score_majority[i].item()] for i, category in enumerate(level_3_categories)}\n",
    "    }\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c558cc2",
   "metadata": {},
   "source": [
    "### Best model vs variants"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
