{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 - Human Value Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f812147f55c0220",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:22.961453700Z",
     "start_time": "2023-12-10T16:15:10.114241800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !pip install lightning\n",
    "# !pip install torchmetrics\n",
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b3cd2c7bd257608",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.149703Z",
     "start_time": "2023-12-10T16:15:22.963513600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# file management\n",
    "import urllib.request\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import dotenv\n",
    "\n",
    "# data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# torchmetrics\n",
    "from torchmetrics import PrecisionRecallCurve\n",
    "from torchmetrics.classification import MultilabelConfusionMatrix\n",
    "\n",
    "# pytorch lightning\n",
    "from lightning import LightningModule\n",
    "from lightning.pytorch import Trainer, seed_everything\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from torchmetrics.classification import MultilabelF1Score\n",
    "from torchmetrics import Metric\n",
    "from torchmetrics import ConfusionMatrix\n",
    "\n",
    "# transformers\n",
    "from transformers import BertModel, BertTokenizer, RobertaModel, RobertaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa152a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If torch deterministic gives problems, use this\n",
    "#dotenv.load_dotenv(\"./.env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8ba5f1",
   "metadata": {},
   "source": [
    "## TASK 1: Corpus\n",
    "\n",
    "* **Download** the specificed training, validation, and test files.\n",
    "* **Encode** split files into a pandas.DataFrame object.\n",
    "* For each split, **merge** the arguments and labels dataframes into a single dataframe.\n",
    "* **Merge** level 2 annotations to level 3 categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee80de80",
   "metadata": {},
   "source": [
    "### Download the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4516ac9d641c89e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.166590900Z",
     "start_time": "2023-12-10T16:15:24.150726800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File arguments-training.tsv already exists. Skipping download...\n",
      "File arguments-test.tsv already exists. Skipping download...\n",
      "File arguments-validation.tsv already exists. Skipping download...\n",
      "File labels-training.tsv already exists. Skipping download...\n",
      "File labels-test.tsv already exists. Skipping download...\n",
      "File labels-validation.tsv already exists. Skipping download...\n"
     ]
    }
   ],
   "source": [
    "# download data from url and save it to the data folder\n",
    "\n",
    "file_names = [\n",
    "    \"arguments-training.tsv\",\n",
    "    \"arguments-test.tsv\",\n",
    "    \"arguments-validation.tsv\",\n",
    "    \"labels-training.tsv\",\n",
    "    \"labels-test.tsv\",\n",
    "    \"labels-validation.tsv\"\n",
    "]\n",
    "\n",
    "# Create the data folder\n",
    "if not os.path.exists(\"./data\"):\n",
    "    os.makedirs(\"./data\")\n",
    "\n",
    "url = \"https://zenodo.org/records/8248658/files/{file_name}?download=1\"\n",
    "for file_name in file_names:\n",
    "    if os.path.exists(f\"./data/{file_name}\"):\n",
    "        print(f\"File {file_name} already exists. Skipping download...\")\n",
    "        continue\n",
    "\n",
    "    file_url = url.format(file_name=file_name)\n",
    "    print(f\"Downloading {file_name} from {file_url}...\")        \n",
    "    urllib.request.urlretrieve(url.format(file_name=file_name), f\"./data/{file_name}\")\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.212916600Z",
     "start_time": "2023-12-10T16:15:24.166590900Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Argument ID</th>\n",
       "      <th>Self-direction: thought</th>\n",
       "      <th>Self-direction: action</th>\n",
       "      <th>Stimulation</th>\n",
       "      <th>Hedonism</th>\n",
       "      <th>Achievement</th>\n",
       "      <th>Power: dominance</th>\n",
       "      <th>Power: resources</th>\n",
       "      <th>Face</th>\n",
       "      <th>Security: personal</th>\n",
       "      <th>...</th>\n",
       "      <th>Tradition</th>\n",
       "      <th>Conformity: rules</th>\n",
       "      <th>Conformity: interpersonal</th>\n",
       "      <th>Humility</th>\n",
       "      <th>Benevolence: caring</th>\n",
       "      <th>Benevolence: dependability</th>\n",
       "      <th>Universalism: concern</th>\n",
       "      <th>Universalism: nature</th>\n",
       "      <th>Universalism: tolerance</th>\n",
       "      <th>Universalism: objectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A26004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A26010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A26016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A26024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A26026</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Argument ID  Self-direction: thought  Self-direction: action  Stimulation  \\\n",
       "0      A26004                        0                       0            0   \n",
       "1      A26010                        0                       0            0   \n",
       "2      A26016                        0                       0            0   \n",
       "3      A26024                        0                       0            0   \n",
       "4      A26026                        0                       0            0   \n",
       "\n",
       "   Hedonism  Achievement  Power: dominance  Power: resources  Face  \\\n",
       "0         0            1                 0                 0     0   \n",
       "1         0            1                 0                 0     0   \n",
       "2         0            1                 0                 0     0   \n",
       "3         0            1                 0                 0     0   \n",
       "4         0            1                 0                 0     0   \n",
       "\n",
       "   Security: personal  ...  Tradition  Conformity: rules  \\\n",
       "0                   1  ...          0                  0   \n",
       "1                   0  ...          0                  0   \n",
       "2                   1  ...          0                  0   \n",
       "3                   0  ...          0                  0   \n",
       "4                   1  ...          0                  0   \n",
       "\n",
       "   Conformity: interpersonal  Humility  Benevolence: caring  \\\n",
       "0                          0         0                    0   \n",
       "1                          0         0                    0   \n",
       "2                          0         0                    0   \n",
       "3                          0         0                    0   \n",
       "4                          0         0                    1   \n",
       "\n",
       "   Benevolence: dependability  Universalism: concern  Universalism: nature  \\\n",
       "0                           0                      1                     0   \n",
       "1                           0                      1                     0   \n",
       "2                           1                      1                     0   \n",
       "3                           0                      0                     0   \n",
       "4                           1                      0                     0   \n",
       "\n",
       "   Universalism: tolerance  Universalism: objectivity  \n",
       "0                        1                          0  \n",
       "1                        1                          1  \n",
       "2                        0                          0  \n",
       "3                        0                          0  \n",
       "4                        0                          0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the dataframes\n",
    "df_arg_train = pd.read_csv('./data/arguments-training.tsv', sep='\\t')\n",
    "df_arg_test = pd.read_csv('./data/arguments-test.tsv', sep='\\t')\n",
    "df_arg_val = pd.read_csv('./data/arguments-validation.tsv', sep='\\t')\n",
    "\n",
    "df_labels_train = pd.read_csv('./data/labels-training.tsv', sep='\\t')\n",
    "df_labels_test = pd.read_csv('./data/labels-test.tsv', sep='\\t')\n",
    "df_labels_val = pd.read_csv('./data/labels-validation.tsv', sep='\\t')\n",
    "\n",
    "df_labels_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e4de79",
   "metadata": {},
   "source": [
    "### Annotations\n",
    "Since the task requires only to take in account *level 3 categories* a mapping between *level 2* and *level 3* is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2b4fe2c6cb107d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.255091700Z",
     "start_time": "2023-12-10T16:15:24.214959700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Argument ID</th>\n",
       "      <th>Openness to change</th>\n",
       "      <th>Self-enhancement</th>\n",
       "      <th>Conservation</th>\n",
       "      <th>Self-transcendence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A26004</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A26010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A26016</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A26024</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A26026</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Argument ID  Openness to change  Self-enhancement  Conservation  \\\n",
       "0      A26004                   0                 1             1   \n",
       "1      A26010                   0                 1             0   \n",
       "2      A26016                   0                 1             1   \n",
       "3      A26024                   0                 1             0   \n",
       "4      A26026                   0                 1             1   \n",
       "\n",
       "   Self-transcendence  \n",
       "0                   1  \n",
       "1                   1  \n",
       "2                   1  \n",
       "3                   0  \n",
       "4                   1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_3_categories = [\"Openness to change\", \"Self-enhancement\", \"Conservation\", \"Self-transcendence\"]\n",
    "\n",
    "level_3_to_2_mapping = {\n",
    "    \"Openness to change\": [\n",
    "        \"Self-direction: thought\",\n",
    "        \"Self-direction: action\",\n",
    "        \"Stimulation\",\n",
    "        \"Hedonism\",\n",
    "    ],\n",
    "    \"Self-enhancement\": [\n",
    "        \"Hedonism\",\n",
    "        \"Achievement\",\n",
    "        \"Power: dominance\",\n",
    "        \"Power: resources\",\n",
    "        \"Face\",\n",
    "    ],\n",
    "    \"Conservation\": [\n",
    "        \"Security: personal\",\n",
    "        \"Security: societal\",\n",
    "        \"Conformity: rules\",\n",
    "        \"Conformity: interpersonal\",\n",
    "        \"Tradition\",\n",
    "        \"Face\",\n",
    "        \"Humility\",\n",
    "    ],\n",
    "    \"Self-transcendence\": [\n",
    "        \"Benevolence: caring\",\n",
    "        \"Benevolence: dependability\",\n",
    "        \"Universalism: concern\",\n",
    "        \"Universalism: nature\",\n",
    "        \"Universalism: tolerance\",\n",
    "        \"Universalism: objectivity\",\n",
    "        \"Humility\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "column_to_drop = [level_2 for level_3 in level_3_to_2_mapping.values() for level_2 in level_3]\n",
    "\n",
    "for category in level_3_categories:\n",
    "    # make a logical OR of all the level 2 categories\n",
    "    df_labels_test[category] = df_labels_test[level_3_to_2_mapping[category]].any(axis=1).map({True: 1, False: 0})\n",
    "    df_labels_val[category] = df_labels_val[level_3_to_2_mapping[category]].any(axis=1).map({True: 1, False: 0})\n",
    "    df_labels_train[category] = df_labels_train[level_3_to_2_mapping[category]].any(axis=1).map({True: 1, False: 0})\n",
    "\n",
    "df_labels_test = df_labels_test.drop(columns=column_to_drop)\n",
    "df_labels_val = df_labels_val.drop(columns=column_to_drop)\n",
    "df_labels_train = df_labels_train.drop(columns=column_to_drop)\n",
    "\n",
    "df_labels_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8316839c9de44b89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.274578600Z",
     "start_time": "2023-12-10T16:15:24.244896500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Argument ID</th>\n",
       "      <th>Conclusion</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Premise</th>\n",
       "      <th>Openness to change</th>\n",
       "      <th>Self-enhancement</th>\n",
       "      <th>Conservation</th>\n",
       "      <th>Self-transcendence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A01002</td>\n",
       "      <td>We should ban human cloning</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>we should ban human cloning as it will only ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A01005</td>\n",
       "      <td>We should ban fast food</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>fast food should be banned because it is reall...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A01006</td>\n",
       "      <td>We should end the use of economic sanctions</td>\n",
       "      <td>against</td>\n",
       "      <td>sometimes economic sanctions are the only thin...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A01007</td>\n",
       "      <td>We should abolish capital punishment</td>\n",
       "      <td>against</td>\n",
       "      <td>capital punishment is sometimes the only optio...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A01008</td>\n",
       "      <td>We should ban factory farming</td>\n",
       "      <td>against</td>\n",
       "      <td>factory farming allows for the production of c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Argument ID                                   Conclusion       Stance  \\\n",
       "0      A01002                  We should ban human cloning  in favor of   \n",
       "1      A01005                      We should ban fast food  in favor of   \n",
       "2      A01006  We should end the use of economic sanctions      against   \n",
       "3      A01007         We should abolish capital punishment      against   \n",
       "4      A01008                We should ban factory farming      against   \n",
       "\n",
       "                                             Premise  Openness to change  \\\n",
       "0  we should ban human cloning as it will only ca...                   0   \n",
       "1  fast food should be banned because it is reall...                   0   \n",
       "2  sometimes economic sanctions are the only thin...                   0   \n",
       "3  capital punishment is sometimes the only optio...                   0   \n",
       "4  factory farming allows for the production of c...                   0   \n",
       "\n",
       "   Self-enhancement  Conservation  Self-transcendence  \n",
       "0                 0             1                   0  \n",
       "1                 0             1                   0  \n",
       "2                 1             1                   0  \n",
       "3                 0             1                   1  \n",
       "4                 0             1                   1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.merge(df_arg_train, df_labels_train, on='Argument ID')\n",
    "df_test = pd.merge(df_arg_test, df_labels_test, on='Argument ID')\n",
    "df_val = pd.merge(df_arg_val, df_labels_val, on='Argument ID')\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cdfe3378972543",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Task 1.5 - stance encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "232f6776a1ee9a80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.290104800Z",
     "start_time": "2023-12-10T16:15:24.260231300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Argument ID</th>\n",
       "      <th>Conclusion</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Premise</th>\n",
       "      <th>Openness to change</th>\n",
       "      <th>Self-enhancement</th>\n",
       "      <th>Conservation</th>\n",
       "      <th>Self-transcendence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A01002</td>\n",
       "      <td>We should ban human cloning</td>\n",
       "      <td>1</td>\n",
       "      <td>we should ban human cloning as it will only ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A01005</td>\n",
       "      <td>We should ban fast food</td>\n",
       "      <td>1</td>\n",
       "      <td>fast food should be banned because it is reall...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A01006</td>\n",
       "      <td>We should end the use of economic sanctions</td>\n",
       "      <td>0</td>\n",
       "      <td>sometimes economic sanctions are the only thin...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A01007</td>\n",
       "      <td>We should abolish capital punishment</td>\n",
       "      <td>0</td>\n",
       "      <td>capital punishment is sometimes the only optio...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A01008</td>\n",
       "      <td>We should ban factory farming</td>\n",
       "      <td>0</td>\n",
       "      <td>factory farming allows for the production of c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Argument ID                                   Conclusion  Stance  \\\n",
       "0      A01002                  We should ban human cloning       1   \n",
       "1      A01005                      We should ban fast food       1   \n",
       "2      A01006  We should end the use of economic sanctions       0   \n",
       "3      A01007         We should abolish capital punishment       0   \n",
       "4      A01008                We should ban factory farming       0   \n",
       "\n",
       "                                             Premise  Openness to change  \\\n",
       "0  we should ban human cloning as it will only ca...                   0   \n",
       "1  fast food should be banned because it is reall...                   0   \n",
       "2  sometimes economic sanctions are the only thin...                   0   \n",
       "3  capital punishment is sometimes the only optio...                   0   \n",
       "4  factory farming allows for the production of c...                   0   \n",
       "\n",
       "   Self-enhancement  Conservation  Self-transcendence  \n",
       "0                 0             1                   0  \n",
       "1                 0             1                   0  \n",
       "2                 1             1                   0  \n",
       "3                 0             1                   1  \n",
       "4                 0             1                   1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode stance into 0, 1 \n",
    "df_train[\"Stance\"] = df_train[\"Stance\"].map({\"in favor of\": 1, \"against\": 0})\n",
    "df_test[\"Stance\"] = df_test[\"Stance\"].map({\"in favor of\": 1, \"against\": 0})\n",
    "df_val[\"Stance\"] = df_val[\"Stance\"].map({\"in favor of\": 1, \"against\": 0})\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77076cfdcc028fa7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Dataset definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecad75b6100c0040",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.359095Z",
     "start_time": "2023-12-10T16:15:24.275596200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ArgumentDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        return {\n",
    "            \"Premise\": row[\"Premise\"],\n",
    "            \"Conclusion\": row[\"Conclusion\"],\n",
    "            \"labels\": torch.tensor(row[level_3_categories].values.tolist(), dtype=torch.float32),\n",
    "            \"Stance\": torch.tensor(row[\"Stance\"], dtype=torch.float32)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94fe31d775254160",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.377556300Z",
     "start_time": "2023-12-10T16:15:24.290104800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Premise': 'we should ban human cloning as it will only cause huge issues when you have a bunch of the same humans running around all acting the same.', 'Conclusion': 'We should ban human cloning', 'labels': tensor([0., 0., 1., 0.]), 'Stance': tensor(1.)}\n",
      "{'Premise': 'fast food should be banned because it is really bad for your health and is costly.', 'Conclusion': 'We should ban fast food', 'labels': tensor([0., 0., 1., 0.]), 'Stance': tensor(1.)}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = ArgumentDataset(df_train)\n",
    "test_dataset = ArgumentDataset(df_test)\n",
    "val_dataset = ArgumentDataset(df_val)\n",
    "\n",
    "# Create the dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(train_dataset[0])\n",
    "print(train_dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71f0112",
   "metadata": {},
   "source": [
    "## TASK 3: Metrics\n",
    "\n",
    "### Instructions\n",
    "\n",
    "* Evaluate your models using per-category binary F1-score.\n",
    "* Compute the average binary F1-score over all categories (macro F1-score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bab81187",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1ScoreCumulative(Metric):\n",
    "    def __init__(self, num_classes: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.add_state(\"true_positive\", default=torch.zeros([num_classes]), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"false_negative\", default=torch.zeros([num_classes]), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"false_positive\", default=torch.zeros([num_classes]), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, y_hat: torch.Tensor, y: torch.Tensor):\n",
    "        \n",
    "        for i in range(self.num_classes):\n",
    "            true_positive = torch.sum((y_hat[:, i] == 1) & (y[:, i] == 1))\n",
    "            false_negative = torch.sum((y_hat[:, i] == 0) & (y[:, i] == 1))\n",
    "            false_positive = torch.sum((y_hat[:, i] == 1) & (y[:, i] == 0))\n",
    "\n",
    "            self.true_positive[i] += true_positive\n",
    "            self.false_negative[i] += false_negative\n",
    "            self.false_positive[i] += false_positive\n",
    "\n",
    "    def compute(self):\n",
    "        precision = self.true_positive / (self.true_positive + self.false_positive)\n",
    "        recall = self.true_positive / (self.true_positive + self.false_negative)\n",
    "\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        \n",
    "        # TODO: check if this is correct, look at forum\n",
    "        # If there are not enough data to compute the f1 score, set it to 0\n",
    "        if f1.isnan().any():\n",
    "            f1[f1.isnan()] = 0\n",
    "\n",
    "        return f1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ffa5c2876fecbf",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## TASK 2: Model definition\n",
    "\n",
    "* **Baseline**: implement a random uniform classifier (an individual classifier per category).\n",
    "* **Baseline**: implement a majority classifier (an individual classifier per category).\n",
    "\n",
    "<br/>\n",
    "\n",
    "* **BERT w/ C**: define a BERT-based classifier that receives an argument **conclusion** as input.\n",
    "* **BERT w/ CP**: add argument **premise** as an additional input.\n",
    "* **BERT w/ CPS**: add argument premise-to-conclusion **stance** as an additional input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbd8b41505ded6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Baselines: random uniform classifier and majority classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "331380fdc13c462f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.395023600Z",
     "start_time": "2023-12-10T16:15:24.308674Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RandomUniformClassifier(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._random_state = np.random.RandomState()\n",
    "\n",
    "    def predict(self, X):\n",
    "        batch_size = len(X[\"Conclusion\"])\n",
    "        logits = self._random_state.uniform(size=(batch_size, 4))\n",
    "        logits = logits > 0.5\n",
    "        return torch.tensor(logits, dtype=torch.float32)\n",
    "\n",
    "\n",
    "class MajorityClassifier(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def train(self, train_dataloader):\n",
    "        labels = torch.cat([batch[\"labels\"] for batch in train_dataloader])\n",
    "        positives_rate = labels.sum(dim=0) / len(labels)\n",
    "        self.majority_classes = positives_rate > 0.5\n",
    "        print(self.majority_classes)\n",
    "\n",
    "    def predict(self, X):\n",
    "        batch_size = len(X[\"Conclusion\"])\n",
    "        return self.majority_classes.repeat(batch_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85576b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for loading the backbon given the name\n",
    "def load_backbone(backbone_name):\n",
    "    if backbone_name == \"bert-base-uncased\":\n",
    "        backbone = BertModel.from_pretrained(backbone_name)\n",
    "        tokenizer = BertTokenizer.from_pretrained(backbone_name)\n",
    "    elif backbone_name == \"roberta-base\":\n",
    "        backbone = RobertaModel.from_pretrained(backbone_name)\n",
    "        tokenizer = RobertaTokenizer.from_pretrained(backbone_name)\n",
    "    else:\n",
    "        raise ValueError(f\"Backbone {backbone_name} not supported\")\n",
    "\n",
    "    return backbone, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab6e80eded57efb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Bert models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc849dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationHead(LightningModule):\n",
    "    def __init__(self, in_size, hidden_size, n_classes):\n",
    "        super().__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self.activation = nn.Sigmoid()\n",
    "        self.l1 = nn.Linear(in_size, hidden_size)\n",
    "        self.l2 = nn.Linear(hidden_size, n_classes)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.l2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eef0d525e8b3e87e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.441482700Z",
     "start_time": "2023-12-10T16:15:24.326135400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BertConclusion(LightningModule):\n",
    "    def __init__(self, bert_model_name, hidden_size, num_classes, lr, model_type=\"Conclusion\"):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=['backbone', 'tokenizer'])\n",
    "        self.backbone, self.tokenizer = load_backbone(bert_model_name)\n",
    "\n",
    "        self.lr = lr\n",
    "        \n",
    "        # Define the input size of the classification head\n",
    "        if model_type == \"Conclusion\":\n",
    "            self.clf_input_size = self.backbone.config.hidden_size\n",
    "        elif model_type == \"Premise\":\n",
    "            self.clf_input_size = self.backbone.config.hidden_size*2\n",
    "        elif model_type == \"Stance\":\n",
    "            self.clf_input_size = self.backbone.config.hidden_size*2 + 1\n",
    "        else:\n",
    "            raise ValueError(f\"Model type {model_type} not supported. Supported model types: ['Conclusion', 'Premise', 'Stance']\")\n",
    "\n",
    "        # freeze bert layers\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.classifier = ClassificationHead(self.clf_input_size, hidden_size, num_classes)\n",
    "        \n",
    "        self._f1_train = F1ScoreCumulative(num_classes=num_classes)\n",
    "        self._f1_val = F1ScoreCumulative(num_classes=num_classes)\n",
    "        self._f1_test = F1ScoreCumulative(num_classes=num_classes)\n",
    "\n",
    "        self.f1_metrics = {\n",
    "            \"train\": self._f1_train,\n",
    "            \"val\": self._f1_val,\n",
    "            \"test\": self._f1_test\n",
    "        }\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "    \n",
    "    def on_save_checkpoint(self, checkpoint):\n",
    "        # Remove all the parameters of the backbone from the checkpoint\n",
    "        for name, param in self.backbone.named_parameters():\n",
    "            del checkpoint['state_dict']['backbone.' + name]\n",
    "\n",
    "\n",
    "    def encode(self, X):\n",
    "        encoded = self.tokenizer(X, padding=True, return_tensors=\"pt\").to(device)\n",
    "        model_output = self.backbone(**encoded)['last_hidden_state']\n",
    "\n",
    "        return model_output[:, 0, :].to(device)\n",
    "\n",
    "    def forward(self, X_data):\n",
    "        X = X_data[\"Conclusion\"]\n",
    "\n",
    "        encoded = self.encode(X)\n",
    "\n",
    "        # last_hidden_state contains the hidden representations for each token in each sequence of the batch:\n",
    "        # shape is (batch_size, seq_len, hidden_size)\n",
    "        # we only need the representation of the first token (the [CLS] token)\n",
    "        logits = self.classifier(encoded)\n",
    "        return logits\n",
    "    \n",
    "    def predict(self, X):\n",
    "        logits = self(X)\n",
    "        y_hat = torch.zeros_like(logits)\n",
    "        y_hat[torch.nn.functional.sigmoid(logits) > 0.5] = 1\n",
    "        return y_hat\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        data = batch\n",
    "        X_data = {key:value for key, value in data.items() if key != \"labels\"}\n",
    "        y = data[\"labels\"]\n",
    "\n",
    "        logits = self(X_data)\n",
    "\n",
    "        loss = nn.BCEWithLogitsLoss()(logits, y)\n",
    "        \n",
    "        self.log(\"train_loss\", loss, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        # Get predictions\n",
    "        y_hat = torch.zeros_like(y)\n",
    "        y_hat[torch.nn.functional.sigmoid(logits) > 0.5] = 1\n",
    "        self.f1_metrics[\"train\"].update(y_hat, y)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        data = batch\n",
    "        X = {key:value for key, value in data.items() if key != \"labels\"}\n",
    "        y = data[\"labels\"]\n",
    "\n",
    "        logits = self(X)\n",
    "\n",
    "        loss = nn.BCEWithLogitsLoss()(logits, y)\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        y_hat = torch.zeros_like(y)\n",
    "        y_hat[torch.nn.functional.sigmoid(logits) > 0.5] = 1\n",
    "        self.f1_metrics[\"val\"].update(y_hat, y)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        data = batch\n",
    "        X = {key:value for key, value in data.items() if key != \"labels\"}\n",
    "        y = data[\"labels\"]\n",
    "\n",
    "        logits = self(X)\n",
    "\n",
    "        loss = nn.BCEWithLogitsLoss()(logits, y)\n",
    "\n",
    "        self.log(\"test_loss\", loss, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        y_hat = torch.zeros_like(y)\n",
    "        y_hat[torch.nn.functional.sigmoid(logits) > 0.5] = 1\n",
    "        self.f1_metrics[\"test\"].update(y_hat, y)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def on_epoch_type_end(self, epoch_type) -> None:\n",
    "        f1_score_per_class = self.f1_metrics[epoch_type].compute()\n",
    "        f1_score_macro = f1_score_per_class.mean()\n",
    "\n",
    "        self.log(f\"{epoch_type}_f1_score\", f1_score_macro, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        for i, category in enumerate(level_3_categories):\n",
    "            self.log(f\"{epoch_type}_f1_score_{category}\", f1_score_per_class[i], on_epoch=True, prog_bar=True, logger=True)\n",
    "    \n",
    "        self.f1_metrics[epoch_type].reset()\n",
    "\n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        self.on_epoch_type_end(\"train\")\n",
    "\n",
    "    def on_validation_epoch_end(self) -> None:\n",
    "        self.on_epoch_type_end(\"val\")\n",
    "\n",
    "    def on_test_epoch_end(self) -> None:\n",
    "        self.on_epoch_type_end(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31dbbe5fe8eb3195",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.443528100Z",
     "start_time": "2023-12-10T16:15:24.357066200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BertPremiseConclusion(BertConclusion):\n",
    "    def __init__(self, bert_model_name, hidden_size, num_classes, lr, model_type=\"Premise\"):\n",
    "        super().__init__(bert_model_name, hidden_size, num_classes, lr, model_type)\n",
    "\n",
    "    def forward(self, X_data):\n",
    "        X_1 = X_data[\"Premise\"]\n",
    "        X_2 = X_data[\"Conclusion\"]\n",
    "\n",
    "        encoded_1 = self.encode(X_1)\n",
    "        encoded_2 = self.encode(X_2)\n",
    "\n",
    "        output = torch.cat((encoded_1, encoded_2), dim=1)\n",
    "\n",
    "        logits = self.classifier(output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b11eb0f4965923dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.444544200Z",
     "start_time": "2023-12-10T16:15:24.372404800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BertPremiseConclusionStance(BertConclusion):\n",
    "    def __init__(self, bert_model_name, hidden_size, num_classes, lr, model_type=\"Stance\"):\n",
    "        super().__init__(bert_model_name, hidden_size, num_classes, lr, model_type)\n",
    "                         \n",
    "\n",
    "    def forward(self, X_data):\n",
    "        X_1, X_2, stance = X_data[\"Premise\"], X_data[\"Conclusion\"], X_data[\"Stance\"]\n",
    "        \n",
    "        encoded_1 = self.encode(X_1)\n",
    "        encoded_2 = self.encode(X_2)\n",
    "        \n",
    "        stance = stance.unsqueeze(1)\n",
    "        output = torch.cat((encoded_1, encoded_2, stance), dim=1)\n",
    "        logits = self.classifier(output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4d886bff0ede4b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.444544200Z",
     "start_time": "2023-12-10T16:15:24.387844600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fix all possible sources of randomness\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e755d7ef",
   "metadata": {},
   "source": [
    "## Task 4 Training and Evaluation\n",
    "\n",
    "You are now tasked to train and evaluate **all** defined models.\n",
    "* Train **all** models on the train set.\n",
    "* Evaluate **all** models on the validation set.\n",
    "* Pick **at least** three seeds for robust estimation.\n",
    "* Compute metrics on the validation set.\n",
    "* Report **per-category** and **macro** F1-score for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "499c93fc7632db8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:15:24.463035600Z",
     "start_time": "2023-12-10T16:15:24.406432500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping training...\n"
     ]
    }
   ],
   "source": [
    "logs_path = Path.cwd() / \"logs\" / \"lightning_logs\"\n",
    "train = False\n",
    "\n",
    "seeds = [6, 90, 157]\n",
    "\n",
    "epochs = 15\n",
    "output_dim = len(level_3_categories)\n",
    "\n",
    "\n",
    "\n",
    "bert_model_name = \"roberta-base\"\n",
    "hidden_size = 128\n",
    "lr = 0.01\n",
    "\n",
    "model_classes = [BertPremiseConclusionStance, BertPremiseConclusion, BertConclusion]\n",
    "model_names = [\"bert_w_cps\", \"bert_w_cp\", \"bert_w_s\"]\n",
    "hyperparameters = [\n",
    "    {'bert_model_name': bert_model_name, 'num_classes': output_dim, \"hidden_size\": hidden_size, \"lr\":lr},\n",
    "    {'bert_model_name': bert_model_name, 'num_classes': output_dim, \"hidden_size\": hidden_size, \"lr\":lr},\n",
    "    {'bert_model_name': bert_model_name, 'num_classes': output_dim, \"hidden_size\": hidden_size, \"lr\":lr}\n",
    "]\n",
    "\n",
    "if train:\n",
    "    for model_class, model_name, hyperparameter in zip(model_classes, model_names, hyperparameters):\n",
    "        for seed in seeds:\n",
    "            print(f\"Training model {model_name} with seed {seed}...\")\n",
    "            seed_everything(seed, workers=True)\n",
    "\n",
    "            model = model_class(**hyperparameter)\n",
    "\n",
    "            logger = TensorBoardLogger(logs_path, name=f\"{model_name}_seed{seed}\")\n",
    "            checkpoint_callback = ModelCheckpoint(\n",
    "                monitor='val_loss',\n",
    "                dirpath=None,\n",
    "                filename=f'{model_name}-seed={seed}-backbone={bert_model_name}' + '-{epoch:02d}-{val_loss:.2f}-{val_f1_score:.2f}',\n",
    "                save_top_k=1,\n",
    "            )\n",
    "            early_stop_callback = EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=3,\n",
    "                verbose=True,\n",
    "                mode='min'\n",
    "            )\n",
    "\n",
    "            trainer = Trainer(\n",
    "                max_epochs=epochs,\n",
    "                logger=logger,\n",
    "                log_every_n_steps=1,\n",
    "                callbacks=[checkpoint_callback, early_stop_callback],\n",
    "                deterministic=True\n",
    "            )\n",
    "\n",
    "            trainer.fit(model, train_dataloader, val_dataloader)\n",
    "else:\n",
    "    print(\"Skipping training...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c0839fab615304c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:48:04.171446700Z",
     "start_time": "2023-12-10T16:48:04.167175500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Definition of some utility functions\n",
    "\n",
    "def model_predict(model, dataloader):\n",
    "    model.eval()  \n",
    "\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            X = {key:value for key, value in batch.items() if key != \"labels\"}\n",
    "\n",
    "            batch_predictions = model.predict(X)\n",
    "\n",
    "            predictions.append(batch_predictions)\n",
    "\n",
    "    all_predictions = torch.cat(predictions)\n",
    "\n",
    "    return all_predictions\n",
    "\n",
    "def evaluate_model(model, loader):    \n",
    "    prediction = model_predict(model, loader)\n",
    "    print(prediction.shape, target.shape)\n",
    "\n",
    "    f1_metric = MultilabelF1Score(num_labels=4, average=None, multidim_average='global')    # TODO: EDO shouldn't we be using binary F1 Score here?\n",
    "    \n",
    "    #Take the target from the loader\n",
    "    target = torch.cat([data[\"labels\"] for data in loader], dim=0)\n",
    "    print(\"Begore f1_metric\")\n",
    "    results = f1_metric(prediction, target)\n",
    "    average = sum(results) / 4\n",
    "\n",
    "    return results, average\n",
    "\n",
    "def load_model(model_name, model_path):\n",
    "    if model_name == \"bert_w_c\":\n",
    "        cls = BertConclusion\n",
    "    elif model_name == \"bert_w_cp\":\n",
    "        cls = BertPremiseConclusion\n",
    "    elif model_name == \"bert_w_cps\":\n",
    "        cls = BertPremiseConclusionStance\n",
    "    else:\n",
    "        raise ValueError(f\"Model name {model_name} not recognized.\")\n",
    "    hparams_path = Path(model_path).parent.parent / \"hparams.yaml\"\n",
    "    \n",
    "    model = cls.load_from_checkpoint(model_path, hparams_file=hparams_path, strict=False)\n",
    "    model.freeze()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17a05ea9d9aa6539",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:48:00.980078700Z",
     "start_time": "2023-12-10T16:47:36.753386800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model bert_w_cps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elements72/.local/lib/python3.10/site-packages/lightning/pytorch/utilities/migration/utils.py:55: The loaded checkpoint was produced with Lightning v2.1.3, which is newer than your current Lightning version: v2.1.0\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elements72/.local/lib/python3.10/site-packages/lightning/pytorch/core/saving.py:173: Found keys that are in the model state dict but not in the checkpoint: ['backbone.embeddings.word_embeddings.weight', 'backbone.embeddings.position_embeddings.weight', 'backbone.embeddings.token_type_embeddings.weight', 'backbone.embeddings.LayerNorm.weight', 'backbone.embeddings.LayerNorm.bias', 'backbone.encoder.layer.0.attention.self.query.weight', 'backbone.encoder.layer.0.attention.self.query.bias', 'backbone.encoder.layer.0.attention.self.key.weight', 'backbone.encoder.layer.0.attention.self.key.bias', 'backbone.encoder.layer.0.attention.self.value.weight', 'backbone.encoder.layer.0.attention.self.value.bias', 'backbone.encoder.layer.0.attention.output.dense.weight', 'backbone.encoder.layer.0.attention.output.dense.bias', 'backbone.encoder.layer.0.attention.output.LayerNorm.weight', 'backbone.encoder.layer.0.attention.output.LayerNorm.bias', 'backbone.encoder.layer.0.intermediate.dense.weight', 'backbone.encoder.layer.0.intermediate.dense.bias', 'backbone.encoder.layer.0.output.dense.weight', 'backbone.encoder.layer.0.output.dense.bias', 'backbone.encoder.layer.0.output.LayerNorm.weight', 'backbone.encoder.layer.0.output.LayerNorm.bias', 'backbone.encoder.layer.1.attention.self.query.weight', 'backbone.encoder.layer.1.attention.self.query.bias', 'backbone.encoder.layer.1.attention.self.key.weight', 'backbone.encoder.layer.1.attention.self.key.bias', 'backbone.encoder.layer.1.attention.self.value.weight', 'backbone.encoder.layer.1.attention.self.value.bias', 'backbone.encoder.layer.1.attention.output.dense.weight', 'backbone.encoder.layer.1.attention.output.dense.bias', 'backbone.encoder.layer.1.attention.output.LayerNorm.weight', 'backbone.encoder.layer.1.attention.output.LayerNorm.bias', 'backbone.encoder.layer.1.intermediate.dense.weight', 'backbone.encoder.layer.1.intermediate.dense.bias', 'backbone.encoder.layer.1.output.dense.weight', 'backbone.encoder.layer.1.output.dense.bias', 'backbone.encoder.layer.1.output.LayerNorm.weight', 'backbone.encoder.layer.1.output.LayerNorm.bias', 'backbone.encoder.layer.2.attention.self.query.weight', 'backbone.encoder.layer.2.attention.self.query.bias', 'backbone.encoder.layer.2.attention.self.key.weight', 'backbone.encoder.layer.2.attention.self.key.bias', 'backbone.encoder.layer.2.attention.self.value.weight', 'backbone.encoder.layer.2.attention.self.value.bias', 'backbone.encoder.layer.2.attention.output.dense.weight', 'backbone.encoder.layer.2.attention.output.dense.bias', 'backbone.encoder.layer.2.attention.output.LayerNorm.weight', 'backbone.encoder.layer.2.attention.output.LayerNorm.bias', 'backbone.encoder.layer.2.intermediate.dense.weight', 'backbone.encoder.layer.2.intermediate.dense.bias', 'backbone.encoder.layer.2.output.dense.weight', 'backbone.encoder.layer.2.output.dense.bias', 'backbone.encoder.layer.2.output.LayerNorm.weight', 'backbone.encoder.layer.2.output.LayerNorm.bias', 'backbone.encoder.layer.3.attention.self.query.weight', 'backbone.encoder.layer.3.attention.self.query.bias', 'backbone.encoder.layer.3.attention.self.key.weight', 'backbone.encoder.layer.3.attention.self.key.bias', 'backbone.encoder.layer.3.attention.self.value.weight', 'backbone.encoder.layer.3.attention.self.value.bias', 'backbone.encoder.layer.3.attention.output.dense.weight', 'backbone.encoder.layer.3.attention.output.dense.bias', 'backbone.encoder.layer.3.attention.output.LayerNorm.weight', 'backbone.encoder.layer.3.attention.output.LayerNorm.bias', 'backbone.encoder.layer.3.intermediate.dense.weight', 'backbone.encoder.layer.3.intermediate.dense.bias', 'backbone.encoder.layer.3.output.dense.weight', 'backbone.encoder.layer.3.output.dense.bias', 'backbone.encoder.layer.3.output.LayerNorm.weight', 'backbone.encoder.layer.3.output.LayerNorm.bias', 'backbone.encoder.layer.4.attention.self.query.weight', 'backbone.encoder.layer.4.attention.self.query.bias', 'backbone.encoder.layer.4.attention.self.key.weight', 'backbone.encoder.layer.4.attention.self.key.bias', 'backbone.encoder.layer.4.attention.self.value.weight', 'backbone.encoder.layer.4.attention.self.value.bias', 'backbone.encoder.layer.4.attention.output.dense.weight', 'backbone.encoder.layer.4.attention.output.dense.bias', 'backbone.encoder.layer.4.attention.output.LayerNorm.weight', 'backbone.encoder.layer.4.attention.output.LayerNorm.bias', 'backbone.encoder.layer.4.intermediate.dense.weight', 'backbone.encoder.layer.4.intermediate.dense.bias', 'backbone.encoder.layer.4.output.dense.weight', 'backbone.encoder.layer.4.output.dense.bias', 'backbone.encoder.layer.4.output.LayerNorm.weight', 'backbone.encoder.layer.4.output.LayerNorm.bias', 'backbone.encoder.layer.5.attention.self.query.weight', 'backbone.encoder.layer.5.attention.self.query.bias', 'backbone.encoder.layer.5.attention.self.key.weight', 'backbone.encoder.layer.5.attention.self.key.bias', 'backbone.encoder.layer.5.attention.self.value.weight', 'backbone.encoder.layer.5.attention.self.value.bias', 'backbone.encoder.layer.5.attention.output.dense.weight', 'backbone.encoder.layer.5.attention.output.dense.bias', 'backbone.encoder.layer.5.attention.output.LayerNorm.weight', 'backbone.encoder.layer.5.attention.output.LayerNorm.bias', 'backbone.encoder.layer.5.intermediate.dense.weight', 'backbone.encoder.layer.5.intermediate.dense.bias', 'backbone.encoder.layer.5.output.dense.weight', 'backbone.encoder.layer.5.output.dense.bias', 'backbone.encoder.layer.5.output.LayerNorm.weight', 'backbone.encoder.layer.5.output.LayerNorm.bias', 'backbone.encoder.layer.6.attention.self.query.weight', 'backbone.encoder.layer.6.attention.self.query.bias', 'backbone.encoder.layer.6.attention.self.key.weight', 'backbone.encoder.layer.6.attention.self.key.bias', 'backbone.encoder.layer.6.attention.self.value.weight', 'backbone.encoder.layer.6.attention.self.value.bias', 'backbone.encoder.layer.6.attention.output.dense.weight', 'backbone.encoder.layer.6.attention.output.dense.bias', 'backbone.encoder.layer.6.attention.output.LayerNorm.weight', 'backbone.encoder.layer.6.attention.output.LayerNorm.bias', 'backbone.encoder.layer.6.intermediate.dense.weight', 'backbone.encoder.layer.6.intermediate.dense.bias', 'backbone.encoder.layer.6.output.dense.weight', 'backbone.encoder.layer.6.output.dense.bias', 'backbone.encoder.layer.6.output.LayerNorm.weight', 'backbone.encoder.layer.6.output.LayerNorm.bias', 'backbone.encoder.layer.7.attention.self.query.weight', 'backbone.encoder.layer.7.attention.self.query.bias', 'backbone.encoder.layer.7.attention.self.key.weight', 'backbone.encoder.layer.7.attention.self.key.bias', 'backbone.encoder.layer.7.attention.self.value.weight', 'backbone.encoder.layer.7.attention.self.value.bias', 'backbone.encoder.layer.7.attention.output.dense.weight', 'backbone.encoder.layer.7.attention.output.dense.bias', 'backbone.encoder.layer.7.attention.output.LayerNorm.weight', 'backbone.encoder.layer.7.attention.output.LayerNorm.bias', 'backbone.encoder.layer.7.intermediate.dense.weight', 'backbone.encoder.layer.7.intermediate.dense.bias', 'backbone.encoder.layer.7.output.dense.weight', 'backbone.encoder.layer.7.output.dense.bias', 'backbone.encoder.layer.7.output.LayerNorm.weight', 'backbone.encoder.layer.7.output.LayerNorm.bias', 'backbone.encoder.layer.8.attention.self.query.weight', 'backbone.encoder.layer.8.attention.self.query.bias', 'backbone.encoder.layer.8.attention.self.key.weight', 'backbone.encoder.layer.8.attention.self.key.bias', 'backbone.encoder.layer.8.attention.self.value.weight', 'backbone.encoder.layer.8.attention.self.value.bias', 'backbone.encoder.layer.8.attention.output.dense.weight', 'backbone.encoder.layer.8.attention.output.dense.bias', 'backbone.encoder.layer.8.attention.output.LayerNorm.weight', 'backbone.encoder.layer.8.attention.output.LayerNorm.bias', 'backbone.encoder.layer.8.intermediate.dense.weight', 'backbone.encoder.layer.8.intermediate.dense.bias', 'backbone.encoder.layer.8.output.dense.weight', 'backbone.encoder.layer.8.output.dense.bias', 'backbone.encoder.layer.8.output.LayerNorm.weight', 'backbone.encoder.layer.8.output.LayerNorm.bias', 'backbone.encoder.layer.9.attention.self.query.weight', 'backbone.encoder.layer.9.attention.self.query.bias', 'backbone.encoder.layer.9.attention.self.key.weight', 'backbone.encoder.layer.9.attention.self.key.bias', 'backbone.encoder.layer.9.attention.self.value.weight', 'backbone.encoder.layer.9.attention.self.value.bias', 'backbone.encoder.layer.9.attention.output.dense.weight', 'backbone.encoder.layer.9.attention.output.dense.bias', 'backbone.encoder.layer.9.attention.output.LayerNorm.weight', 'backbone.encoder.layer.9.attention.output.LayerNorm.bias', 'backbone.encoder.layer.9.intermediate.dense.weight', 'backbone.encoder.layer.9.intermediate.dense.bias', 'backbone.encoder.layer.9.output.dense.weight', 'backbone.encoder.layer.9.output.dense.bias', 'backbone.encoder.layer.9.output.LayerNorm.weight', 'backbone.encoder.layer.9.output.LayerNorm.bias', 'backbone.encoder.layer.10.attention.self.query.weight', 'backbone.encoder.layer.10.attention.self.query.bias', 'backbone.encoder.layer.10.attention.self.key.weight', 'backbone.encoder.layer.10.attention.self.key.bias', 'backbone.encoder.layer.10.attention.self.value.weight', 'backbone.encoder.layer.10.attention.self.value.bias', 'backbone.encoder.layer.10.attention.output.dense.weight', 'backbone.encoder.layer.10.attention.output.dense.bias', 'backbone.encoder.layer.10.attention.output.LayerNorm.weight', 'backbone.encoder.layer.10.attention.output.LayerNorm.bias', 'backbone.encoder.layer.10.intermediate.dense.weight', 'backbone.encoder.layer.10.intermediate.dense.bias', 'backbone.encoder.layer.10.output.dense.weight', 'backbone.encoder.layer.10.output.dense.bias', 'backbone.encoder.layer.10.output.LayerNorm.weight', 'backbone.encoder.layer.10.output.LayerNorm.bias', 'backbone.encoder.layer.11.attention.self.query.weight', 'backbone.encoder.layer.11.attention.self.query.bias', 'backbone.encoder.layer.11.attention.self.key.weight', 'backbone.encoder.layer.11.attention.self.key.bias', 'backbone.encoder.layer.11.attention.self.value.weight', 'backbone.encoder.layer.11.attention.self.value.bias', 'backbone.encoder.layer.11.attention.output.dense.weight', 'backbone.encoder.layer.11.attention.output.dense.bias', 'backbone.encoder.layer.11.attention.output.LayerNorm.weight', 'backbone.encoder.layer.11.attention.output.LayerNorm.bias', 'backbone.encoder.layer.11.intermediate.dense.weight', 'backbone.encoder.layer.11.intermediate.dense.bias', 'backbone.encoder.layer.11.output.dense.weight', 'backbone.encoder.layer.11.output.dense.bias', 'backbone.encoder.layer.11.output.LayerNorm.weight', 'backbone.encoder.layer.11.output.LayerNorm.bias', 'backbone.pooler.dense.weight', 'backbone.pooler.dense.bias']\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m checkpoint_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(checkpoint_folder\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.ckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m))[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     16\u001b[0m model \u001b[38;5;241m=\u001b[39m load_model(model_name, checkpoint_path)\n\u001b[0;32m---> 17\u001b[0m results, average \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m temp \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model_name,\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheckpoint path\u001b[39m\u001b[38;5;124m\"\u001b[39m: checkpoint_path \n\u001b[1;32m     25\u001b[0m }, index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     27\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([results_df, temp], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn [20], line 20\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, loader)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_model\u001b[39m(model, loader):    \n\u001b[0;32m---> 20\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(prediction\u001b[38;5;241m.\u001b[39mshape, target\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     23\u001b[0m     f1_metric \u001b[38;5;241m=\u001b[39m MultilabelF1Score(num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multidim_average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglobal\u001b[39m\u001b[38;5;124m'\u001b[39m)    \u001b[38;5;66;03m# TODO: EDO shouldn't we be using binary F1 Score here?\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [20], line 11\u001b[0m, in \u001b[0;36mmodel_predict\u001b[0;34m(model, dataloader)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m      9\u001b[0m         X \u001b[38;5;241m=\u001b[39m {key:value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m---> 11\u001b[0m         batch_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m         predictions\u001b[38;5;241m.\u001b[39mappend(batch_predictions)\n\u001b[1;32m     15\u001b[0m all_predictions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(predictions)\n",
      "Cell \u001b[0;32mIn [15], line 63\u001b[0m, in \u001b[0;36mBertConclusion.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m---> 63\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(logits)\n\u001b[1;32m     65\u001b[0m     y_hat[torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msigmoid(logits) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [17], line 13\u001b[0m, in \u001b[0;36mBertPremiseConclusionStance.forward\u001b[0;34m(self, X_data)\u001b[0m\n\u001b[1;32m     10\u001b[0m encoded_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode(X_2)\n\u001b[1;32m     12\u001b[0m stance \u001b[38;5;241m=\u001b[39m stance\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoded_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstance\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(output)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(columns=[\"Model\", \"Seed\", \"F1 Score\"] + level_3_categories)\n",
    "\n",
    "for model_name in model_names:\n",
    "    print(f\"Evaluating model {model_name}...\")\n",
    "    for seed in seeds:\n",
    "        model_folder = logs_path / f\"{model_name}_seed{seed}\"\n",
    "        \n",
    "        version_folders = os.listdir(model_folder)\n",
    "        versions = [int(x.split(\"_\")[1]) for x in version_folders]\n",
    "        latest_version = max(versions)  \n",
    "        version_folder = model_folder / f\"version_{latest_version}\"\n",
    "        \n",
    "        checkpoint_folder = version_folder / \"checkpoints\"\n",
    "        checkpoint_path = list(checkpoint_folder.glob(\"*.ckpt\"))[0]\n",
    "        \n",
    "        model = load_model(model_name, checkpoint_path)\n",
    "        results, average = evaluate_model(model, test_dataloader)\n",
    "        \n",
    "        temp = pd.DataFrame({\n",
    "            \"Model\": model_name,\n",
    "            \"Seed\": seed,\n",
    "            \"F1 Score\": average.item(),\n",
    "            **{category: f1.item() for category, f1 in zip(level_3_categories, results)},\n",
    "            \"Checkpoint path\": checkpoint_path \n",
    "        }, index=[0])\n",
    "        \n",
    "        results_df = pd.concat([results_df, temp], ignore_index=True)\n",
    "        \n",
    "        print(f\"Seed {seed}:\")\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9937ee",
   "metadata": {},
   "source": [
    "## Task 5: Error analysis\n",
    "You are tasked to discuss your results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aeb6704",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "* **Compare** classification performance of BERT-based models with respect to baselines.\n",
    "* Discuss **difference in prediction** between the best performing BERT-based model and its variants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43da156",
   "metadata": {},
   "source": [
    "### Best model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4f764a455f16dc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_model_row = None\n",
    "\n",
    "for row in results_df.itertuples():\n",
    "    if best_model_row is None or row[\"F1 Score\"] > best_model_row[\"F1 Score\"]:\n",
    "        best_model_row = row\n",
    "        \n",
    "best_model = load_model(best_model_row[\"Model\"], best_model_row[\"Checkpoint path\"])\n",
    "\n",
    "f1_score_best_average = best_model_row[\"F1 Score\"]\n",
    "f1_score_best = best_model_row[level_3_categories] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220cfc0f90823351",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:49:21.969441700Z",
     "start_time": "2023-12-10T16:49:20.329955700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_model = load_model(\"bert_w_c\", \"./logs/lightning_logs/bert_w_c_seed6/version_0/checkpoints/bert_w_c-seed=6-epoch=00-val_loss=0.64-val_f1=0.00.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9646e0c",
   "metadata": {},
   "source": [
    "#### Precision/Recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c596864e44c68068",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:59:26.915219500Z",
     "start_time": "2023-12-10T16:59:25.202145100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "small_test_dataset = ArgumentDataset(df_test[:50])\n",
    "loader = DataLoader(small_test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "precision_curve = PrecisionRecallCurve(task=\"multilabel\", num_labels=4)\n",
    "\n",
    "y_pred = model_predict(best_model, loader)\n",
    "\n",
    "y_true = torch.cat([data[\"labels\"] for data in loader], dim=0)\n",
    "y_true = y_true.type(torch.LongTensor)\n",
    "\n",
    "curve = precision_curve(y_pred, y_true)\n",
    "precision, recall, _ = curve\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.grid()\n",
    "\n",
    "label_to_auc = {}\n",
    "for i in range(len(level_3_categories)):\n",
    "    label = level_3_categories[i]\n",
    "    auc = -1 * torch.trapz(precision[i], recall[i])\n",
    "    \n",
    "    label_to_auc[label] = auc.item()\n",
    "    \n",
    "    plt.plot(recall[i], precision[i], label=f\"{label}: {auc:.2f}\")\n",
    "\n",
    "plt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e157f7a7",
   "metadata": {},
   "source": [
    "#### Confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9054e8b02b426438",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T17:13:41.924346200Z",
     "start_time": "2023-12-10T17:13:41.738516Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confusion_matrix_metric = MultilabelConfusionMatrix(num_labels=len(level_3_categories))\n",
    "\n",
    "confusion_matrix = confusion_matrix_metric(y_pred, y_true)\n",
    "\n",
    "# Craete a subplot for each category\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axs = axs.flatten()\n",
    "\n",
    "\n",
    "for i, category in enumerate(level_3_categories):\n",
    "    axs[i].imshow(confusion_matrix[i].numpy(), cmap=\"Blues\")\n",
    "    axs[i].set_title(category)\n",
    "    axs[i].set_xlabel(\"Predicted label\")\n",
    "    axs[i].set_ylabel(\"True label\")\n",
    "    axs[i].set_xticks([0, 1])\n",
    "    axs[i].set_yticks([0, 1])\n",
    "    axs[i].set_xticklabels([\"Positive\", \"Negative\"])\n",
    "    axs[i].set_yticklabels([\"Positive\", \"Negative\"])\n",
    "    axs[i].grid(False)\n",
    "    \n",
    "    # add the values to the plot\n",
    "    for k in range(2):\n",
    "        for j in range(2):\n",
    "            axs[i].text(k, j, confusion_matrix[i][k, j].item(), ha=\"center\", va=\"center\", color=\"Red\", fontsize=20)\n",
    "    \n",
    "#\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f967b0b9",
   "metadata": {},
   "source": [
    "#### Model performance on most/least frequent classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab4c83b",
   "metadata": {},
   "source": [
    "#### Specific misclassified examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dd7bd9",
   "metadata": {},
   "source": [
    "### Best model vs baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934f9c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begore f1_metric\n",
      "Begore f1_metric\n"
     ]
    }
   ],
   "source": [
    "baseline_random = RandomUniformClassifier()\n",
    "baseline_majority = MajorityClassifier(n_random_classifiers=10)\n",
    "f1_score_random, f1_score_random_average = evaluate_model(baseline_random, test_dataloader)\n",
    "f1_score_majority, f1_score_majority_average = evaluate_model(baseline_majority, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957ae5ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f1_score_best_average' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [42], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m baseline_comparison \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest model\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMajority\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1 Score\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[43mf1_score_best_average\u001b[49m , f1_score_random_average\u001b[38;5;241m.\u001b[39mitem(), f1_score_majority_average\u001b[38;5;241m.\u001b[39mitem()],\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{category: [f1_score_best[i]\u001b[38;5;241m.\u001b[39mitem(), f1_score_random[i]\u001b[38;5;241m.\u001b[39mitem(), f1_score_majority[i]\u001b[38;5;241m.\u001b[39mitem()] \u001b[38;5;28;01mfor\u001b[39;00m i, category \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(level_3_categories)}\n\u001b[1;32m      5\u001b[0m     }\n\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'f1_score_best_average' is not defined"
     ]
    }
   ],
   "source": [
    "baseline_comparison = pd.DataFrame({\n",
    "    \"Model\": [\"Best model\", \"Random\", \"Majority\"],\n",
    "    \"F1 Score\": [f1_score_best_average , f1_score_random_average.item(), f1_score_majority_average.item()],\n",
    "    **{category: [f1_score_best[i].item(), f1_score_random[i].item(), f1_score_majority[i].item()] for i, category in enumerate(level_3_categories)}\n",
    "    }\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c558cc2",
   "metadata": {},
   "source": [
    "### Best model vs variants"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
