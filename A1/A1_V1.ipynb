{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 - Part of Speech Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install lightning\n",
    "# !pip install torchtext.data\n",
    "# !pip install torchtext\n",
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: remove unused dependencies\n",
    "\n",
    "# file management\n",
    "import sys\n",
    "import shutil\n",
    "import urllib\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# DL framework\n",
    "from torchmetrics import Accuracy, F1Score\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "# dataframe management\n",
    "import pandas as pd\n",
    "\n",
    "# data manipulation\n",
    "import numpy as np\n",
    "\n",
    "# for readability\n",
    "from typing import Iterable\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownloadProgressBar(tqdm):\n",
    "    def update_to(self, b=1, bsize=1, tsize=None):\n",
    "        if tsize is not None:\n",
    "            self.total = tsize\n",
    "        self.update(b * bsize - self.n)\n",
    "\n",
    "\n",
    "def download_url(download_path: Path, url: str):\n",
    "    with DownloadProgressBar(unit='B', unit_scale=True,\n",
    "                             miniters=1, desc=url.split('/')[-1]) as t:\n",
    "        urllib.request.urlretrieve(url, filename=download_path, reporthook=t.update_to)\n",
    "\n",
    "\n",
    "def download_dataset(download_path: Path, url: str):\n",
    "    print(\"Downloading dataset...\")\n",
    "    download_url(url=url, download_path=download_path)\n",
    "    print(\"Download complete!\")\n",
    "\n",
    "\n",
    "def extract_dataset(download_path: Path, extract_path: Path):\n",
    "    print(\"Extracting dataset... (it may take a while...)\")\n",
    "    with zipfile.ZipFile(download_path, 'r') as zip_file:\n",
    "        zip_file.extractall(extract_path)\n",
    "\n",
    "    print(\"Extraction completed!\")\n",
    "\n",
    "    Path.unlink(download_path)\n",
    "    print(\"Deleted .zip dataset file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip\"\n",
    "dataset_name = \"dependency_treebank\"\n",
    "\n",
    "print(f\"Current work directory: {Path.cwd()}\")\n",
    "\n",
    "dataset_folder = Path.cwd().joinpath(\"Datasets\")\n",
    "\n",
    "if not dataset_folder.exists():\n",
    "    dataset_folder.mkdir(parents=True)\n",
    "\n",
    "dataset_zip_path = dataset_folder.joinpath(\"dependency_treebank.zip\")\n",
    "dataset_path = dataset_folder.joinpath(dataset_name)\n",
    "\n",
    "if not dataset_zip_path.exists():\n",
    "    download_dataset(dataset_zip_path, url)\n",
    "\n",
    "if not dataset_path.exists():\n",
    "    extract_dataset(dataset_zip_path, dataset_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode the corpus into a pandas.DataFrame object and split it into train, validation and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corpus contains 200 documents.\n",
    "\n",
    "   * **Train**: Documents 1-100\n",
    "   * **Validation**: Documents 101-150\n",
    "   * **Test**: Documents 151-199"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_rows = []  # list for DataFrame rows\n",
    "id = 0\n",
    "\n",
    "for i, file_path in enumerate(sorted(dataset_path.iterdir())):\n",
    "    if file_path.is_file():  # split corpus documents in the tree categories: train, validation, tests\n",
    "        if 1 <= i + 1 <= 100:\n",
    "            split = 'train'\n",
    "        elif 101 <= i + 1 <= 150:\n",
    "            split = 'validation'\n",
    "        else:\n",
    "            split = 'test'\n",
    "\n",
    "        with file_path.open(mode='r', encoding='utf-8') as text_file:  # read corpus lines\n",
    "            lines = text_file.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            fields = line.strip().split('\\t')\n",
    "            if len(fields) == 1:\n",
    "                id = id + 1\n",
    "            if len(fields) >= 2:\n",
    "                text = fields[0]  # store the first field as 'text'\n",
    "                POS = fields[1]  # store the second field as 'POS'\n",
    "                dataframe_row = {  #build DataFrame rows\n",
    "                    \"text\": text,\n",
    "                    \"POS\": POS,\n",
    "                    \"split\": split,\n",
    "                    \"id\": id\n",
    "                }\n",
    "\n",
    "                dataframe_rows.append(dataframe_row)  #append rows\n",
    "# corpus DataFrame\n",
    "corpus_df = pd.DataFrame(dataframe_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## TASK 1: Corpus\n",
    "\n",
    "* **Download** the corpus.\n",
    "* **Encode** the corpus into a pandas.DataFrame object.\n",
    "* **Split** it in training, validation, and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, test, validation split\n",
    "df_train = corpus_df[corpus_df['split'] == 'train'].drop(columns=['split'])\n",
    "df_test = corpus_df[corpus_df['split'] == 'test'].drop(columns=['split'])\n",
    "df_val = corpus_df[corpus_df['split'] == 'validation'].drop(columns=['split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataframe structure:\")\n",
    "print(corpus_df)\n",
    "print()\n",
    "\n",
    "print(\"Total rows %d\" % (len(corpus_df)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 2: Text encoding\n",
    "\n",
    "* Embed words using **GloVe embeddings**.\n",
    "* TODO: see if we want to do it, otherwise remove it -> [Optional] You are free to experiment with text pre-processing: **make sure you do not delete any token!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed words unsing GloVe embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import GloVe, build_vocab_from_iterator\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from lightning.pytorch import loggers as pl_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embedding_model(embedding_dimension: int = 300):\n",
    "    emb_model = GloVe(name=\"6B\", dim=embedding_dimension)\n",
    "    return emb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "punctuation_and_symbol_pos = [\".\", \",\", \":\", '``', \"''\", \"$\", \"#\", \"-LRB-\", \"-RRB-\", \"SYM\", \"LS\"] #TODO check \"LS\" "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = ([text] for text in corpus_df[\"POS\"].unique())\n",
    "vocab = build_vocab_from_iterator(iterator)\n",
    "vocab.append_token(\"<PAD>\")\n",
    "\n",
    "pos_padding_value = vocab[\"<PAD>\"]\n",
    "punctuation_and_symbol_pos_indices = [vocab[token] for token in punctuation_and_symbol_pos]\n",
    "\n",
    "\n",
    "class CorpusDataset(Dataset):\n",
    "    def __init__(self, dataframe: pd.DataFrame, embedder):\n",
    "        min_id = dataframe['id'].min()\n",
    "        dataframe['id'] = dataframe['id'] - min_id\n",
    "        self.dataframe = dataframe.groupby(\"id\")\n",
    "        self.embedder = embedder\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.dataframe.get_group(idx)\n",
    "        text = sentence['text'].to_list()\n",
    "        text = [token.lower() for token in text]        \n",
    "        \n",
    "        POS = sentence['POS'].to_list()\n",
    "        POS = torch.Tensor([vocab[token] for token in POS])\n",
    "\n",
    "        # POS_one_hot = torch.nn.functional.one_hot(POS.to(torch.int64), num_classes=len(vocab))\n",
    "        # TODO: remove\n",
    "        embedded_text = self.embedder.get_vecs_by_tokens(text)\n",
    "\n",
    "        return embedded_text, POS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the dataset\n",
    "EMBEDDING_DIM = 50\n",
    "embedder = load_embedding_model(EMBEDDING_DIM)\n",
    "dataset_train = CorpusDataset(df_train, embedder)\n",
    "dataset_test = CorpusDataset(df_test, embedder)\n",
    "dataset_val = CorpusDataset(df_val, embedder)\n",
    "dataset_all = CorpusDataset(corpus_df, embedder)\n",
    "\n",
    "\n",
    "# TODO - test if it works in the LSTM training\n",
    "def my_collate(batch):\n",
    "    sequences, labels = zip(*batch)\n",
    "\n",
    "    # max_len = max([len(seq) for seq in sequences])\n",
    "    # sequences_padded = [seq + [\"<PAD>\"] * (max_len - len(seq)) for seq in sequences]\n",
    "\n",
    "    sequences_padded = torch.nn.utils.rnn.pad_sequence(sequences, batch_first=True, padding_value=0)\n",
    "    labels_padded = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=pos_padding_value)\n",
    "\n",
    "    sequences_padded = sequences_padded.type(torch.float)\n",
    "    labels_padded = labels_padded.type(torch.long)\n",
    "\n",
    "    return [sequences_padded, labels_padded]\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset_train, batch_size=32, collate_fn=my_collate)\n",
    "val_loader = DataLoader(dataset_val, batch_size=32, collate_fn=my_collate)\n",
    "test_loader = DataLoader(dataset_test, batch_size=32, collate_fn=my_collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 3: Model definition\n",
    "\n",
    "* **Baseline**: implement a Bidirectional LSTM with a Dense layer on top.\n",
    "\n",
    "* **Model 1**: add an additional LSTM layer to the Baseline model.\n",
    "* **Model 2**: add an additional Dense layer to the Baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model: Bidirectional LSTM + Dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torchmetrics import Metric\n",
    "from torchmetrics import ConfusionMatrix\n",
    "\n",
    "\n",
    "class F1ScoreCustom(Metric):\n",
    "    def __init__(self, num_classes: int, pos_padding_value: int = pos_padding_value, punctuation_and_symbol_pos_indices: list = punctuation_and_symbol_pos_indices):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.mask = torch.ones([num_classes])\n",
    "        self.mask[[pos_padding_value] + punctuation_and_symbol_pos_indices] = 0\n",
    "        \n",
    "        self.add_state(\"true_positive\", default=torch.zeros([num_classes]), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"false_negative\", default=torch.zeros([num_classes]), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"false_positive\", default=torch.zeros([num_classes]), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, y_hat_class: torch.Tensor, y_class: torch.Tensor):\n",
    "        confusion_matrix_metric = ConfusionMatrix(num_classes=self.num_classes, task=\"multiclass\")\n",
    "        confusion_matrix = confusion_matrix_metric(y_hat_class, y_class)\n",
    "\n",
    "        # # Confusion matrix, TP, FN and FP for class 0 \n",
    "        # #   TRUE LABEL\n",
    "        # #   0               TP     FN    FN     FN      FN        \n",
    "        # #   1               FP       \n",
    "        # #   2               FP               \n",
    "        # #   3               FP                       \n",
    "        # #   4               FP                                \n",
    "        # # PREDICTED LABEL   0       1      2       3       4\n",
    "        # \n",
    "\n",
    "        true_positive = torch.Tensor([confusion_matrix[i][i] for i in range(self.num_classes)])\n",
    "        false_negative = torch.Tensor([sum(confusion_matrix[i, :]) - true_positive[i] for i in range(self.num_classes)])\n",
    "        false_positive = torch.Tensor([sum(confusion_matrix[:, i]) - true_positive[i] for i in range(self.num_classes)])\n",
    "\n",
    "        self.true_positive += true_positive\n",
    "        self.false_negative += false_negative\n",
    "        self.false_positive += false_positive\n",
    "\n",
    "    def compute(self):\n",
    "        precision = self.true_positive / (self.true_positive + self.false_positive)\n",
    "        recall = self.true_positive / (self.true_positive + self.false_negative)\n",
    "\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "        f1 = f1 * self.mask\n",
    "\n",
    "        return f1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMModel(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, target_padding_value=pos_padding_value):  #, embedder):\n",
    "        super(BiLSTMModel, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.target_padding_value = target_padding_value\n",
    "\n",
    "        # self.embedder = embedder\n",
    "        # self.embedding_layer = nn.Embedding.from_pretrained(embedder.vectors)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_dim,\n",
    "                            hidden_size=hidden_dim,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)  # Multiplied by 2 due to the bidirectionality\n",
    "\n",
    "        self._train_f1_metric = F1ScoreCustom(num_classes=output_dim, pos_padding_value=self.target_padding_value)\n",
    "        self._val_f1_metric = F1ScoreCustom(num_classes=output_dim, pos_padding_value=self.target_padding_value)\n",
    "        self._test_f1_metric = F1ScoreCustom(num_classes=output_dim, pos_padding_value=self.target_padding_value)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # embedding = self.embedding_layer(x)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        # lstm_out (batch_size, seq_length, hidden_size * 2)\n",
    "        out = self.fc(lstm_out)\n",
    "        # out (batch_size, seq_length, output_dim)\n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "\n",
    "        # Change shape from (batchsize, sequence_len, classes) to be (batchsize, classes, sequence_len) to compute loss function\n",
    "        y_hat = torch.movedim(y_hat, 1, 2)\n",
    "        loss = nn.functional.cross_entropy(y_hat, y, ignore_index=self.target_padding_value)\n",
    "\n",
    "        self.log_dict({'train_loss': loss, 'step': self.current_epoch}, on_epoch=True, prog_bar=True, logger=True,\n",
    "                      on_step=False, reduce_fx=\"mean\")\n",
    "\n",
    "        y_hat_class = torch.argmax(y_hat, dim=1)\n",
    "        self._train_f1_metric.update(y_hat_class, y)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        y_hat = torch.movedim(y_hat, 1, 2)\n",
    "\n",
    "        loss = nn.functional.cross_entropy(y_hat, y, ignore_index=self.target_padding_value)\n",
    "        self.log_dict({'val_loss': loss, 'step': self.current_epoch}, on_epoch=True, prog_bar=True, logger=True,\n",
    "                      reduce_fx=\"mean\")\n",
    "\n",
    "        y_hat_class = torch.argmax(y_hat, dim=1)\n",
    "        self._val_f1_metric.update(y_hat_class, y)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        y_hat = torch.movedim(y_hat, 1, 2)\n",
    "        loss = nn.functional.cross_entropy(y_hat, y, ignore_index=self.target_padding_value)\n",
    "\n",
    "        self.log_dict({'test_loss': loss, 'step': self.current_epoch}, on_epoch=True, prog_bar=True, logger=True,\n",
    "                      reduce_fx=\"mean\")\n",
    "\n",
    "        y_hat_class = torch.argmax(y_hat, dim=1)\n",
    "        self._test_f1_metric.update(y_hat_class, y)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "    def _compute_f1(self, f1_metric):\n",
    "        mean_f1_score = f1_metric.compute()\n",
    "\n",
    "        # Create a mask that is False for NaNs\n",
    "        mask = torch.isnan(mean_f1_score)\n",
    "\n",
    "        # Invert the mask: True for valid entries, False for NaNs\n",
    "        valid_data = mean_f1_score[~mask]\n",
    "\n",
    "        # Compute the mean of the non-NaN values\n",
    "        mean_value = torch.mean(valid_data)\n",
    "\n",
    "        return mean_value\n",
    "\n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        mean_f1_score = self._compute_f1(self._train_f1_metric)\n",
    "        self.log_dict({\"train_f1\": mean_f1_score, 'step': float(self.current_epoch)}, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self._train_f1_metric.reset()\n",
    "\n",
    "    def on_validation_epoch_end(self) -> None:\n",
    "        mean_f1_score = self._compute_f1(self._val_f1_metric)\n",
    "        self.log_dict({\"val_f1\": mean_f1_score, 'step': float(self.current_epoch)}, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self._val_f1_metric.reset()\n",
    "\n",
    "    def on_test_epoch_end(self) -> None:\n",
    "        mean_f1_score = self._compute_f1(self._test_f1_metric)\n",
    "        self.log_dict({\"test_f1\": mean_f1_score, 'step': float(self.current_epoch)}, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self._test_f1_metric.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "output_dim = len(df_train[\"POS\"].unique()) + 1  # +1 for padding\n",
    "input_dim = EMBEDDING_DIM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_version = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "hidden_dim = 128\n",
    "max_epochs = 50\n",
    "\n",
    "save_dir = \"logs\"\n",
    "load_model = False\n",
    "train_model = True\n",
    "model_ckpt = \"baseline.ckpt\"\n",
    "\n",
    "PATH = os.path.join(save_dir, \"lightning_logs\", \"version_\" + str(baseline_version), \"checkpoints\", model_ckpt)\n",
    "\n",
    "if load_model:\n",
    "    model = BiLSTMModel.load_from_checkpoint(PATH, input_dim=input_dim, hidden_dim=hidden_dim,\n",
    "                                             output_dim=output_dim)  #, embedder=embedder)\n",
    "else:\n",
    "    model = BiLSTMModel(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim)  #, embedder=embedder)\n",
    "\n",
    "if train_model:\n",
    "    tb_logger = TensorBoardLogger(version=baseline_version, save_dir='logs')\n",
    "    trainer = pl.Trainer(max_epochs=max_epochs, logger=tb_logger, default_root_dir='./', log_every_n_steps=1)\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    trainer.save_checkpoint(PATH)\n",
    "    baseline_version += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model\n",
    "validation_results_baseline_model = trainer.validate(model, dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Bidirectional 2-layers LSTM + Dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model1(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, target_padding_value=pos_padding_value):  #, embedder):\n",
    "        super(Model1, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.target_padding_value = target_padding_value\n",
    "\n",
    "        # self.embedder = embedder\n",
    "        # self.embedding_layer = nn.Embedding.from_pretrained(embedder.vectors)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_dim,\n",
    "                            hidden_size=hidden_dim,\n",
    "                            num_layers=2,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)  # Multiplied by 2 due to the bidirectionality\n",
    "\n",
    "        self._train_f1_metric = F1ScoreCustom(num_classes=output_dim, pos_padding_value=self.target_padding_value)\n",
    "        self._val_f1_metric = F1ScoreCustom(num_classes=output_dim, pos_padding_value=self.target_padding_value)\n",
    "        self._test_f1_metric = F1ScoreCustom(num_classes=output_dim, pos_padding_value=self.target_padding_value)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # embedding = self.embedding_layer(x)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        # lstm_out (batch_size, seq_length, hidden_size * 2)\n",
    "        out = self.fc(lstm_out)\n",
    "        # out (batch_size, seq_length, output_dim)\n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "\n",
    "        # Change shape from (batchsize, sequence_len, classes) to be (batchsize, classes, sequence_len) to compute loss function\n",
    "        y_hat = torch.movedim(y_hat, 1, 2)\n",
    "        loss = nn.functional.cross_entropy(y_hat, y, ignore_index=self.target_padding_value)\n",
    "\n",
    "        self.log_dict({'train_loss': loss, 'step': self.current_epoch}, on_epoch=True, prog_bar=True, logger=True,\n",
    "                      on_step=False, reduce_fx=\"mean\")\n",
    "\n",
    "        y_hat_class = torch.argmax(y_hat, dim=1)\n",
    "        self._train_f1_metric.update(y_hat_class, y)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        y_hat = torch.movedim(y_hat, 1, 2)\n",
    "\n",
    "        loss = nn.functional.cross_entropy(y_hat, y, ignore_index=self.target_padding_value)\n",
    "        self.log_dict({'val_loss': loss, 'step': self.current_epoch}, on_epoch=True, prog_bar=True, logger=True,\n",
    "                      reduce_fx=\"mean\")\n",
    "\n",
    "        y_hat_class = torch.argmax(y_hat, dim=1)\n",
    "        self._val_f1_metric.update(y_hat_class, y)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        y_hat = torch.movedim(y_hat, 1, 2)\n",
    "        loss = nn.functional.cross_entropy(y_hat, y, ignore_index=self.target_padding_value)\n",
    "\n",
    "        self.log_dict({'test_loss': loss, 'step': self.current_epoch}, on_epoch=True, prog_bar=True, logger=True,\n",
    "                      reduce_fx=\"mean\")\n",
    "\n",
    "        y_hat_class = torch.argmax(y_hat, dim=1)\n",
    "        self._test_f1_metric.update(y_hat_class, y)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "    def _compute_f1(self, f1_metric):\n",
    "        mean_f1_score = f1_metric.compute()\n",
    "\n",
    "        # Create a mask that is False for NaNs\n",
    "        mask = torch.isnan(mean_f1_score)\n",
    "\n",
    "        # Invert the mask: True for valid entries, False for NaNs\n",
    "        valid_data = mean_f1_score[~mask]\n",
    "\n",
    "        # Compute the mean of the non-NaN values\n",
    "        mean_value = torch.mean(valid_data)\n",
    "\n",
    "        return mean_value\n",
    "\n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        mean_f1_score = self._compute_f1(self._train_f1_metric)\n",
    "        self.log_dict({\"train_f1\": mean_f1_score, 'step': self.current_epoch}, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self._train_f1_metric.reset()\n",
    "\n",
    "    def on_validation_epoch_end(self) -> None:\n",
    "        mean_f1_score = self._compute_f1(self._val_f1_metric)\n",
    "        self.log_dict({\"val_f1\": mean_f1_score, 'step': self.current_epoch}, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self._val_f1_metric.reset()\n",
    "\n",
    "    def on_test_epoch_end(self) -> None:\n",
    "        mean_f1_score = self._compute_f1(self._test_f1_metric)\n",
    "        self.log_dict({\"test_f1\": mean_f1_score, 'step': self.current_epoch}, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self._test_f1_metric.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_version = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hidden_dim = 28\n",
    "max_epochs = 50\n",
    "\n",
    "save_dir = \"logs\"\n",
    "load_model = False\n",
    "train_model = True\n",
    "model_ckpt = \"model1.ckpt\"\n",
    "\n",
    "PATH = os.path.join(save_dir, \"lightning_logs\", \"version_\" + str(model1_version), \"checkpoints\", model_ckpt)\n",
    "\n",
    "if load_model:\n",
    "    model_1 = Model1.load_from_checkpoint(PATH, input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim)\n",
    "else:\n",
    "    model_1 = Model1(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim)\n",
    "\n",
    "if train_model:\n",
    "    tb_logger = TensorBoardLogger(version=model1_version, save_dir='logs')\n",
    "    trainer = pl.Trainer(max_epochs=max_epochs, logger=tb_logger, default_root_dir='./', log_every_n_steps=1)\n",
    "    trainer.fit(model_1, train_loader, val_loader)\n",
    "    trainer.save_checkpoint(PATH)\n",
    "    model1_version += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_results_model_1 = trainer.validate(model_1, dataloaders=val_loader);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Bidirectional LSTM + 2 Dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Model2(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, fc_size,\n",
    "                 target_padding_value=pos_padding_value):  #, embedder):\n",
    "        super(Model2, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.target_padding_value = target_padding_value\n",
    "\n",
    "        # self.embedder = embedder\n",
    "        # self.embedding_layer = nn.Embedding.from_pretrained(embedder.vectors)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_dim,\n",
    "                            hidden_size=hidden_dim,\n",
    "                            num_layers=2,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "        self.fc_1 = nn.Linear(hidden_dim * 2, fc_size)  # Multiplied by 2 due to bidirectionality\n",
    "        self.fc_2 = nn.Linear(fc_size, output_dim)\n",
    "\n",
    "        self._train_f1_metric = F1ScoreCustom(num_classes=output_dim, pos_padding_value=self.target_padding_value)\n",
    "        self._val_f1_metric = F1ScoreCustom(num_classes=output_dim, pos_padding_value=self.target_padding_value)\n",
    "        self._test_f1_metric = F1ScoreCustom(num_classes=output_dim, pos_padding_value=self.target_padding_value)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # embedding = self.embedding_layer(x)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        # lstm_out (batch_size, seq_length, hidden_size * 2)\n",
    "        out = self.fc_1(lstm_out)\n",
    "        out = self.fc_2(out)\n",
    "        # out (batch_size, seq_length, output_dim)\n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "\n",
    "        # Change shape from (batchsize, sequence_len, classes) to be (batchsize, classes, sequence_len) to compute loss function\n",
    "        y_hat = torch.movedim(y_hat, 1, 2)\n",
    "        loss = nn.functional.cross_entropy(y_hat, y, ignore_index=self.target_padding_value)\n",
    "\n",
    "        self.log_dict({'train_loss': loss, 'step': self.current_epoch}, on_epoch=True, prog_bar=True, logger=True,\n",
    "                      on_step=False, reduce_fx=\"mean\")\n",
    "\n",
    "        y_hat_class = torch.argmax(y_hat, dim=1)\n",
    "        self._train_f1_metric.update(y_hat_class, y)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        y_hat = torch.movedim(y_hat, 1, 2)\n",
    "\n",
    "        loss = nn.functional.cross_entropy(y_hat, y, ignore_index=self.target_padding_value)\n",
    "        self.log_dict({'val_loss': loss, 'step': self.current_epoch}, on_epoch=True, prog_bar=True, logger=True,\n",
    "                      reduce_fx=\"mean\")\n",
    "\n",
    "        y_hat_class = torch.argmax(y_hat, dim=1)\n",
    "        self._val_f1_metric.update(y_hat_class, y)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        y_hat = torch.movedim(y_hat, 1, 2)\n",
    "        loss = nn.functional.cross_entropy(y_hat, y, ignore_index=self.target_padding_value)\n",
    "\n",
    "        self.log_dict({'test_loss': loss, 'step': self.current_epoch}, on_epoch=True, prog_bar=True, logger=True,\n",
    "                      reduce_fx=\"mean\")\n",
    "\n",
    "        y_hat_class = torch.argmax(y_hat, dim=1)\n",
    "        self._test_f1_metric.update(y_hat_class, y)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "    def _compute_f1(self, f1_metric):\n",
    "        mean_f1_score = f1_metric.compute()\n",
    "\n",
    "        # Create a mask that is False for NaNs\n",
    "        mask = torch.isnan(mean_f1_score)\n",
    "\n",
    "        # Invert the mask: True for valid entries, False for NaNs\n",
    "        valid_data = mean_f1_score[~mask]\n",
    "\n",
    "        # Compute the mean of the non-NaN values\n",
    "        mean_value = torch.mean(valid_data)\n",
    "\n",
    "        return mean_value\n",
    "\n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        mean_f1_score = self._compute_f1(self._train_f1_metric)\n",
    "        self.log_dict({\"train_f1\": mean_f1_score, 'step': self.current_epoch}, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self._train_f1_metric.reset()\n",
    "\n",
    "    def on_validation_epoch_end(self) -> None:\n",
    "        mean_f1_score = self._compute_f1(self._val_f1_metric)\n",
    "        self.log_dict({\"val_f1\": mean_f1_score, 'step': self.current_epoch}, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self._val_f1_metric.reset()\n",
    "\n",
    "    def on_test_epoch_end(self) -> None:\n",
    "        mean_f1_score = self._compute_f1(self._test_f1_metric)\n",
    "        self.log_dict({\"test_f1\": mean_f1_score, 'step': self.current_epoch}, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self._test_f1_metric.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_version = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hidden_dim = 28\n",
    "fc_size = 100\n",
    "\n",
    "max_epochs = 10\n",
    "\n",
    "save_dir = \"logs\"\n",
    "load_model = False\n",
    "train_model = True\n",
    "model_ckpt = \"model2.ckpt\"\n",
    "\n",
    "PATH = os.path.join(save_dir, \"lightning_logs\", \"version_\" + str(model2_version), \"checkpoints\", model_ckpt)\n",
    "\n",
    "if load_model:\n",
    "    model_2 = Model2.load_from_checkpoint(PATH, input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim,\n",
    "                                          fc_size=fc_size)\n",
    "else:\n",
    "    model_2 = Model2(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, fc_size=fc_size)\n",
    "\n",
    "if train_model:\n",
    "    tb_logger = TensorBoardLogger(version=model2_version, save_dir='logs')\n",
    "    trainer = pl.Trainer(max_epochs=max_epochs, logger=tb_logger, default_root_dir='./', log_every_n_steps=1)\n",
    "    trainer.fit(model_2, train_loader, val_loader)\n",
    "    trainer.save_checkpoint(PATH)\n",
    "    model2_version += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_results_model_2 = trainer.validate(model_2, dataloaders=val_loader);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 4: Metrics\n",
    "\n",
    "* Assign static embedding to validation and test set OOV words (Edo: see unk_init param at [docs](https://torchtext.readthedocs.io/en/latest/vocab.html))\n",
    "* **Concatenate** all tokens in a data split -> (**Hint**: accumulate FP, TP, FN, TN iteratively) TODO: rewrite \n",
    "* Evaluate models using macro F1-score, computed over **all** tokens.\n",
    "* TODO: remove -> **Do not consider punctuation and symbol classes** $\\rightarrow$ [What is punctuation?](https://en.wikipedia.org/wiki/English_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OOV words\n",
    "\n",
    "existing_vocab_words = set(embedder.stoi.keys())  # Words in the vocabulary\n",
    "\n",
    "val_text = [word.lower() for word in df_val['text']]\n",
    "test_text = [word.lower() for word in df_test['text']]\n",
    "\n",
    "\n",
    "val_oov_words = set(val_text) - existing_vocab_words  # OOV words in validation set\n",
    "test_oov_words = set(test_text) - existing_vocab_words  # OOV words in test set\n",
    "\n",
    "# print(existing_vocab_words)\n",
    "# \n",
    "print(\"Out-of-vocabulary words in validation set:\", val_oov_words)\n",
    "print('len:', len(val_oov_words))\n",
    "print(\"Out-of-vocabulary words in test set:\", test_oov_words)\n",
    "print('len:', len(test_oov_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static embeddings\n",
    "static_embeddings_val = {}\n",
    "static_embeddings_test = {}\n",
    "\n",
    "# Assign static embeddings to OOV words in the validation set\n",
    "for word in val_oov_words:\n",
    "    if word in embedder.stoi:  #For each word assign a static embedding\n",
    "        static_embeddings_val[word] = embedder[word]\n",
    "\n",
    "# Assign static embeddings to OOV words in the test set\n",
    "for word in test_oov_words:\n",
    "    if word in embedder.stoi:\n",
    "        static_embeddings_test[word] = embedder[word]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_oov_words_to_display = 3\n",
    "\n",
    "# print to check the validation set oov embeddings\n",
    "print(f\"Static embeddings for OOV words in the validation set:\")\n",
    "for i, (word, embedding) in enumerate(static_embeddings_val.items()):\n",
    "    if i < num_oov_words_to_display:\n",
    "        print(f\"Word: {word}, Embedding: {embedding}\")\n",
    "    else:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print to check the test set oov embeddings\n",
    "print(f\"Static embeddings for OOV words in the test set:\")\n",
    "for i, (word, embedding) in enumerate(static_embeddings_test.items()):\n",
    "    if i < num_oov_words_to_display:\n",
    "        print(f\"Word: {word}, Embedding: {embedding}\")\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 5: Training and Evaluation\n",
    "\n",
    "* Train **all** models on the train set.\n",
    "* Evaluate **all** models on the validation set.\n",
    "* Compute metrics on the validation set.\n",
    "* Pick **at least** three seeds for robust estimation.\n",
    "* Pick the **best** performing model according to the observed validation set performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 6: Error analysis\n",
    "\n",
    "* Compare the errors made on the validation and test sets.\n",
    "* Aggregate model errors into categories (if possible) \n",
    "* Comment about errors and propose possible solutions on how to address them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: REPORT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
