{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightning in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: PyYAML<8.0,>=5.4 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightning) (6.0)\n",
      "Requirement already satisfied: fsspec[http]<2025.0,>2021.06.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightning) (2023.10.0)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightning) (0.9.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.17.2 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightning) (1.23.5)\n",
      "Requirement already satisfied: packaging<25.0,>=20.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightning) (23.0)\n",
      "Requirement already satisfied: torch<4.0,>=1.12.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightning) (2.1.0)\n",
      "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightning) (1.2.0)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightning) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightning) (4.5.0)\n",
      "Requirement already satisfied: pytorch-lightning in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightning) (2.1.0)\n",
      "Requirement already satisfied: requests in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]<2025.0,>2021.06.0->lightning) (2.28.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]<2025.0,>2021.06.0->lightning) (3.8.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch<4.0,>=1.12.0->lightning) (3.13.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch<4.0,>=1.12.0->lightning) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch<4.0,>=1.12.0->lightning) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch<4.0,>=1.12.0->lightning) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm<6.0,>=4.57.0->lightning) (0.4.6)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (22.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (3.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch<4.0,>=1.12.0->lightning) (2.1.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch<4.0,>=1.12.0->lightning) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement torchtext.data (from versions: none)\n",
      "ERROR: No matching distribution found for torchtext.data\n",
      "\n",
      "[notice] A new release of pip is available: 23.0 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext\n",
      "  Downloading torchtext-0.16.0-cp311-cp311-win_amd64.whl (1.9 MB)\n",
      "     ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "     ----- ---------------------------------- 0.3/1.9 MB 8.9 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 0.8/1.9 MB 9.8 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 1.4/1.9 MB 10.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.9/1.9 MB 11.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchtext) (4.64.1)\n",
      "Requirement already satisfied: requests in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchtext) (2.28.2)\n",
      "Requirement already satisfied: torch==2.1.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchtext) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchtext) (1.23.5)\n",
      "Collecting torchdata==0.7.0\n",
      "  Downloading torchdata-0.7.0-cp311-cp311-win_amd64.whl (1.3 MB)\n",
      "     ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "     ---------------------------- ----------- 0.9/1.3 MB 29.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.3/1.3 MB 21.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.1.0->torchtext) (3.13.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.1.0->torchtext) (4.5.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.1.0->torchtext) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.1.0->torchtext) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.1.0->torchtext) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.1.0->torchtext) (2023.10.0)\n",
      "Requirement already satisfied: urllib3>=1.25 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchdata==0.7.0->torchtext) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchtext) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchtext) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchtext) (2022.12.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->torchtext) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch==2.1.0->torchtext) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch==2.1.0->torchtext) (1.3.0)\n",
      "Installing collected packages: torchdata, torchtext\n",
      "Successfully installed torchdata-0.7.0 torchtext-0.16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.13.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install lightning\n",
    "!pip install torchtext.data\n",
    "!pip install torchtext\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file management\n",
    "import sys\n",
    "import shutil\n",
    "import urllib\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "\n",
    "# dataframe management\n",
    "import pandas as pd\n",
    "\n",
    "# data manipulation\n",
    "import numpy as np\n",
    "\n",
    "# for readability\n",
    "from typing import Iterable\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 1: Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownloadProgressBar(tqdm):\n",
    "    def update_to(self, b=1, bsize=1, tsize=None):\n",
    "        if tsize is not None:\n",
    "            self.total = tsize\n",
    "        self.update(b * bsize - self.n)\n",
    "        \n",
    "def download_url(download_path: Path, url: str):\n",
    "    with DownloadProgressBar(unit='B', unit_scale=True,\n",
    "                             miniters=1, desc=url.split('/')[-1]) as t:\n",
    "        urllib.request.urlretrieve(url, filename=download_path, reporthook=t.update_to)\n",
    "\n",
    "        \n",
    "def download_dataset(download_path: Path, url: str):\n",
    "    print(\"Downloading dataset...\")\n",
    "    download_url(url=url, download_path=download_path)\n",
    "    print(\"Download complete!\")\n",
    "\n",
    "def extract_dataset(download_path: Path, extract_path: Path):\n",
    "    print(\"Extracting dataset... (it may take a while...)\")\n",
    "    with zipfile.ZipFile(download_path, 'r') as zip_file:\n",
    "        zip_file.extractall(extract_path)\n",
    "\n",
    "    print(\"Extraction completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current work directory: c:\\Users\\Acer\\Dropbox\\PC\\Desktop\\NLP_project\\A1\n"
     ]
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip\"\n",
    "dataset_name = \"dependency_treebank\"\n",
    "\n",
    "print(f\"Current work directory: {Path.cwd()}\")\n",
    "\n",
    "dataset_folder = Path.cwd().joinpath(\"Datasets\")\n",
    "\n",
    "if not dataset_folder.exists():\n",
    "    dataset_folder.mkdir(parents=True)\n",
    "\n",
    "dataset_zip_path = dataset_folder.joinpath(\"dependency_treebank.zip\")\n",
    "dataset_path = dataset_folder.joinpath(dataset_name)\n",
    "\n",
    "if not dataset_zip_path.exists():\n",
    "    download_dataset(dataset_zip_path, url)\n",
    "\n",
    "if not dataset_path.exists():\n",
    "    extract_dataset(dataset_zip_path, dataset_folder)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding the corpus into a pandas.DataFrame object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corpus contains 200 documents.\n",
    "\n",
    "   * **Train**: Documents 1-100\n",
    "   * **Validation**: Documents 101-150\n",
    "   * **Test**: Documents 151-199"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_rows = []  # list for DataFrame rows\n",
    "id = 0\n",
    "\n",
    "for i, file_path in enumerate(sorted(dataset_path.iterdir())):\n",
    "    if file_path.is_file(): # split corpus documents in the tree categories: train, validation, tests\n",
    "        if 1 <= i + 1 <= 100:\n",
    "            split = 'train'\n",
    "        elif 101 <= i + 1 <= 150:\n",
    "            split = 'validation'\n",
    "        else:\n",
    "            split = 'test'\n",
    "\n",
    "        with file_path.open(mode='r', encoding='utf-8') as text_file: # read corpus lines\n",
    "                lines = text_file.readlines()\n",
    "                \n",
    "        for line in lines:\n",
    "            fields = line.strip().split('\\t')\n",
    "            if len(fields) == 1:\n",
    "                id = id + 1\n",
    "            if len(fields) >= 2:\n",
    "                text = fields[0]  # store the first field as 'text'\n",
    "                POS = fields[1]   # store the second field as 'POS'\n",
    "                dataframe_row = {  #build DataFrame rows\n",
    "                    \"text\": text,\n",
    "                    \"POS\": POS,\n",
    "                    \"split\": split,\n",
    "                    \"id\": id\n",
    "                }\n",
    "\n",
    "                dataframe_rows.append(dataframe_row) #append rows\n",
    "# corpus DataFrame\n",
    "corpus_df = pd.DataFrame(dataframe_rows) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>POS</th>\n",
       "      <th>split</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pierre</td>\n",
       "      <td>NNP</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vinken</td>\n",
       "      <td>NNP</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>CD</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>years</td>\n",
       "      <td>NNS</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>old</td>\n",
       "      <td>JJ</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>will</td>\n",
       "      <td>MD</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>join</td>\n",
       "      <td>VB</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     text  POS  split  id\n",
       "0  Pierre  NNP  train   0\n",
       "1  Vinken  NNP  train   0\n",
       "2       ,    ,  train   0\n",
       "3      61   CD  train   0\n",
       "4   years  NNS  train   0\n",
       "5     old   JJ  train   0\n",
       "6       ,    ,  train   0\n",
       "7    will   MD  train   0\n",
       "8    join   VB  train   0\n",
       "9     the   DT  train   0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, test, validation split\n",
    "df_train = corpus_df[corpus_df['split'] == 'train'].drop(columns=['split'])\n",
    "df_test = corpus_df[corpus_df['split'] == 'test'].drop(columns=['split'])\n",
    "df_val = corpus_df[corpus_df['split'] == 'validation'].drop(columns=['split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe structure:\n",
      "          text  POS  split    id\n",
      "0       Pierre  NNP  train     0\n",
      "1       Vinken  NNP  train     0\n",
      "2            ,    ,  train     0\n",
      "3           61   CD  train     0\n",
      "4        years  NNS  train     0\n",
      "...        ...  ...    ...   ...\n",
      "94079  quarter   NN   test  3715\n",
      "94080       of   IN   test  3715\n",
      "94081     next   JJ   test  3715\n",
      "94082     year   NN   test  3715\n",
      "94083        .    .   test  3715\n",
      "\n",
      "[94084 rows x 4 columns]\n",
      "\n",
      "Total rows 94084\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataframe structure:\")\n",
    "print(corpus_df)\n",
    "print()\n",
    "\n",
    "print(\"Total rows %d\" % (len(corpus_df)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 2: Text encoding\n",
    "\n",
    "### Instructions\n",
    "\n",
    "* Embed words using **GloVe embeddings**.\n",
    "* You are **free** to pick any embedding dimension.\n",
    "* [Optional] You are free to experiment with text pre-processing: **make sure you do not delete any token!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode text into numerical format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import GloVe\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embedding_model(embedding_dimension: int = 300):\n",
    "    emb_model = GloVe(name=\"6B\", dim=embedding_dimension)\n",
    "    return emb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorpusDataset(Dataset):\n",
    "    def __init__(self, dataframe: pd.DataFrame, embedder):\n",
    "        self.dataframe = dataframe.groupby(\"id\")\n",
    "        self.embedder = embedder\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.dataframe.get_group(idx)\n",
    "        text = sentence['text'].to_list()\n",
    "        POS = sentence['POS'].to_list()\n",
    "        embedded_text = self.embedder.get_vecs_by_tokens(text)\n",
    "        return embedded_text, POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache\\glove.6B.zip: 862MB [37:03, 388kB/s]                                \n",
      "100%|█████████▉| 399999/400000 [00:08<00:00, 49946.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# Definition of the dataset\n",
    "embedder = load_embedding_model(50)\n",
    "dataset_train = CorpusDataset(df_train, embedder)\n",
    "dataset_test = CorpusDataset(df_test, embedder)\n",
    "dataset_val = CorpusDataset(df_val, embedder)\n",
    "\n",
    "\n",
    "# TODO - test if it works in the LSTM training\n",
    "def my_collate(batch):\n",
    "    data = [item[0] for item in batch]\n",
    "    target = [item[1] for item in batch]\n",
    "    return [data, target]\n",
    "\n",
    "train_loader = DataLoader(dataset_train, batch_size=32, collate_fn=my_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_loader:\n",
    "    print(len(x))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
