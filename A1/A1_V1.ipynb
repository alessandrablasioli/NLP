{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightning in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: PyYAML<8.0,>=5.4 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightning) (6.0)\n",
      "Requirement already satisfied: fsspec[http]<2025.0,>2021.06.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightning) (2023.10.0)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightning) (0.9.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.17.2 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightning) (1.23.5)\n",
      "Requirement already satisfied: packaging<25.0,>=20.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightning) (23.0)\n",
      "Requirement already satisfied: torch<4.0,>=1.12.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightning) (2.1.0)\n",
      "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightning) (1.2.0)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightning) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightning) (4.5.0)\n",
      "Requirement already satisfied: pytorch-lightning in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightning) (2.1.0)\n",
      "Requirement already satisfied: requests in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]<2025.0,>2021.06.0->lightning) (2.28.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]<2025.0,>2021.06.0->lightning) (3.8.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch<4.0,>=1.12.0->lightning) (3.13.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch<4.0,>=1.12.0->lightning) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch<4.0,>=1.12.0->lightning) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch<4.0,>=1.12.0->lightning) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm<6.0,>=4.57.0->lightning) (0.4.6)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (22.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (3.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch<4.0,>=1.12.0->lightning) (2.1.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch<4.0,>=1.12.0->lightning) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file management\n",
    "import sys\n",
    "import shutil\n",
    "import urllib\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "\n",
    "# dataframe management\n",
    "import pandas as pd\n",
    "\n",
    "# data manipulation\n",
    "import numpy as np\n",
    "\n",
    "# for readability\n",
    "from typing import Iterable\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 1: Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownloadProgressBar(tqdm):\n",
    "    def update_to(self, b=1, bsize=1, tsize=None):\n",
    "        if tsize is not None:\n",
    "            self.total = tsize\n",
    "        self.update(b * bsize - self.n)\n",
    "        \n",
    "def download_url(download_path: Path, url: str):\n",
    "    with DownloadProgressBar(unit='B', unit_scale=True,\n",
    "                             miniters=1, desc=url.split('/')[-1]) as t:\n",
    "        urllib.request.urlretrieve(url, filename=download_path, reporthook=t.update_to)\n",
    "\n",
    "        \n",
    "def download_dataset(download_path: Path, url: str):\n",
    "    print(\"Downloading dataset...\")\n",
    "    download_url(url=url, download_path=download_path)\n",
    "    print(\"Download complete!\")\n",
    "\n",
    "def extract_dataset(download_path: Path, extract_path: Path):\n",
    "    print(\"Extracting dataset... (it may take a while...)\")\n",
    "    with zipfile.ZipFile(download_path, 'r') as zip_file:\n",
    "        zip_file.extractall(extract_path)\n",
    "\n",
    "    print(\"Extraction completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current work directory: c:\\Users\\Acer\\Dropbox\\PC\\Desktop\\NLP_project\\A1\n"
     ]
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip\"\n",
    "dataset_name = \"dependency_treebank\"\n",
    "\n",
    "print(f\"Current work directory: {Path.cwd()}\")\n",
    "\n",
    "dataset_folder = Path.cwd().joinpath(\"Datasets\")\n",
    "\n",
    "if not dataset_folder.exists():\n",
    "    dataset_folder.mkdir(parents=True)\n",
    "\n",
    "dataset_zip_path = dataset_folder.joinpath(\"dependency_treebank.zip\")\n",
    "dataset_path = dataset_folder.joinpath(dataset_name)\n",
    "\n",
    "if not dataset_zip_path.exists():\n",
    "    download_dataset(dataset_zip_path, url)\n",
    "\n",
    "if not dataset_path.exists():\n",
    "    extract_dataset(dataset_zip_path, dataset_folder)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding the corpus into a pandas.DataFrame object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corpus contains 200 documents.\n",
    "\n",
    "   * **Train**: Documents 1-100\n",
    "   * **Validation**: Documents 101-150\n",
    "   * **Test**: Documents 151-199"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_rows = []  # list for DataFrame rows\n",
    "dataset_folder = Path('.\\Datasets\\dependency_treebank') #unzipped folder\n",
    "for i, file_path in enumerate(dataset_folder.iterdir()):\n",
    "    if file_path.is_file(): # split corpus documents in the tree cathegories: train, validation, tests\n",
    "        if 1 <= i + 1 <= 100:\n",
    "            split = 'train'\n",
    "        elif 101 <= i + 1 <= 150:\n",
    "            split = 'validation'\n",
    "        else:\n",
    "            split = 'test'\n",
    "\n",
    "        with file_path.open(mode='r', encoding='utf-8') as text_file: # read corpus lines\n",
    "                lines = text_file.readlines()\n",
    "\n",
    "        if len(lines) > 0:\n",
    "        # split the first line based on tabs\n",
    "                    fields = lines[0].strip().split('\\t')\n",
    "        if len(fields) >= 2:\n",
    "                text = fields[0]  # store the first field as 'text'\n",
    "                POS = fields[1]   # store the second field as 'POS'\n",
    "\n",
    "                dataframe_row = {  #build DataFrame rows\n",
    "                    \"text\": text,\n",
    "                    \"POS\": POS,\n",
    "                    \"split\": split\n",
    "                }\n",
    "\n",
    "                dataframe_rows.append(dataframe_row) #append rows\n",
    "\n",
    "# corpus DataFrame\n",
    "corpus_df = pd.DataFrame(dataframe_rows) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>POS</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pierre</td>\n",
       "      <td>NNP</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rudolph</td>\n",
       "      <td>NNP</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>DT</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yields</td>\n",
       "      <td>NNS</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J.P.</td>\n",
       "      <td>NNP</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      text  POS  split\n",
       "0   Pierre  NNP  train\n",
       "1  Rudolph  NNP  train\n",
       "2        A   DT  train\n",
       "3   Yields  NNS  train\n",
       "4     J.P.  NNP  train"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe structure:\n",
      "        text  POS  split\n",
      "0     Pierre  NNP  train\n",
      "1    Rudolph  NNP  train\n",
      "2          A   DT  train\n",
      "3     Yields  NNS  train\n",
      "4       J.P.  NNP  train\n",
      "..       ...  ...    ...\n",
      "194     John  NNP   test\n",
      "195     Leon  NNP   test\n",
      "196    David  NNP   test\n",
      "197      Two   CD   test\n",
      "198  Trinity  NNP   test\n",
      "\n",
      "[199 rows x 3 columns]\n",
      "\n",
      "Total rows 199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataframe structure:\")\n",
    "print(corpus_df)\n",
    "print()\n",
    "\n",
    "print(\"Total rows %d\" % (len(corpus_df)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 2: Text encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode text into numerical format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.3.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gensim) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gensim) (1.10.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gensim) (6.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install gensim\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
