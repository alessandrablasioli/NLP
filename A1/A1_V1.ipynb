{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting lightning\n",
      "  Downloading lightning-2.1.0-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec[http]<2025.0,>2021.06.0 in /home/elements72/.local/lib/python3.10/site-packages (from lightning) (2023.3.0)\n",
      "Requirement already satisfied: torch<4.0,>=1.12.0 in /home/elements72/.local/lib/python3.10/site-packages (from lightning) (1.13.1)\n",
      "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /home/elements72/.local/lib/python3.10/site-packages (from lightning) (0.11.4)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /home/elements72/.local/lib/python3.10/site-packages (from lightning) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in /home/elements72/.local/lib/python3.10/site-packages (from lightning) (4.3.0)\n",
      "Requirement already satisfied: pytorch-lightning in /home/elements72/.local/lib/python3.10/site-packages (from lightning) (1.9.4)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in /home/elements72/.local/lib/python3.10/site-packages (from lightning) (0.8.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.17.2 in /home/elements72/.local/lib/python3.10/site-packages (from lightning) (1.23.3)\n",
      "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/lib/python3/dist-packages (from lightning) (5.4.1)\n",
      "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/lib/python3/dist-packages (from lightning) (21.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/elements72/.local/lib/python3.10/site-packages (from fsspec[http]<2025.0,>2021.06.0->lightning) (3.8.4)\n",
      "Requirement already satisfied: requests in /home/elements72/.local/lib/python3.10/site-packages (from fsspec[http]<2025.0,>2021.06.0->lightning) (2.31.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/elements72/.local/lib/python3.10/site-packages (from torch<4.0,>=1.12.0->lightning) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/elements72/.local/lib/python3.10/site-packages (from torch<4.0,>=1.12.0->lightning) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/elements72/.local/lib/python3.10/site-packages (from torch<4.0,>=1.12.0->lightning) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/elements72/.local/lib/python3.10/site-packages (from torch<4.0,>=1.12.0->lightning) (8.5.0.96)\n",
      "Requirement already satisfied: setuptools in /home/elements72/.local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch<4.0,>=1.12.0->lightning) (67.3.2)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<4.0,>=1.12.0->lightning) (0.37.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/elements72/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/elements72/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.8.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/elements72/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/elements72/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (3.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/elements72/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/elements72/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/elements72/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (6.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/elements72/.local/lib/python3.10/site-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning) (3.3)\n",
      "Installing collected packages: lightning\n",
      "Successfully installed lightning-2.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file management\n",
    "import sys\n",
    "import shutil\n",
    "import urllib\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "\n",
    "# dataframe management\n",
    "import pandas as pd\n",
    "\n",
    "# data manipulation\n",
    "import numpy as np\n",
    "\n",
    "# for readability\n",
    "from typing import Iterable\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 1: Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownloadProgressBar(tqdm):\n",
    "    def update_to(self, b=1, bsize=1, tsize=None):\n",
    "        if tsize is not None:\n",
    "            self.total = tsize\n",
    "        self.update(b * bsize - self.n)\n",
    "        \n",
    "def download_url(download_path: Path, url: str):\n",
    "    with DownloadProgressBar(unit='B', unit_scale=True,\n",
    "                             miniters=1, desc=url.split('/')[-1]) as t:\n",
    "        urllib.request.urlretrieve(url, filename=download_path, reporthook=t.update_to)\n",
    "\n",
    "        \n",
    "def download_dataset(download_path: Path, url: str):\n",
    "    print(\"Downloading dataset...\")\n",
    "    download_url(url=url, download_path=download_path)\n",
    "    print(\"Download complete!\")\n",
    "\n",
    "def extract_dataset(download_path: Path, extract_path: Path):\n",
    "    print(\"Extracting dataset... (it may take a while...)\")\n",
    "    with zipfile.ZipFile(download_path, 'r') as zip_file:\n",
    "        zip_file.extractall(extract_path)\n",
    "\n",
    "    print(\"Extraction completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current work directory: /home/elements72/unibo/Vanno/NLP/Assignments/NLP/A1\n"
     ]
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip\"\n",
    "dataset_name = \"dependency_treebank\"\n",
    "\n",
    "print(f\"Current work directory: {Path.cwd()}\")\n",
    "\n",
    "dataset_folder = Path.cwd().joinpath(\"Datasets\")\n",
    "\n",
    "if not dataset_folder.exists():\n",
    "    dataset_folder.mkdir(parents=True)\n",
    "\n",
    "dataset_zip_path = dataset_folder.joinpath(\"dependency_treebank.zip\")\n",
    "dataset_path = dataset_folder.joinpath(dataset_name)\n",
    "\n",
    "if not dataset_zip_path.exists():\n",
    "    download_dataset(dataset_zip_path, url)\n",
    "\n",
    "if not dataset_path.exists():\n",
    "    extract_dataset(dataset_zip_path, dataset_folder)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding the corpus into a pandas.DataFrame object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corpus contains 200 documents.\n",
    "\n",
    "   * **Train**: Documents 1-100\n",
    "   * **Validation**: Documents 101-150\n",
    "   * **Test**: Documents 151-199"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_rows = []  # list for DataFrame rows\n",
    "for i, file_path in enumerate(dataset_folder.iterdir()):\n",
    "    if file_path.is_file(): # split corpus documents in the tree categories: train, validation, tests\n",
    "        if 1 <= i + 1 <= 100:\n",
    "            split = 'train'\n",
    "        elif 101 <= i + 1 <= 150:\n",
    "            split = 'validation'\n",
    "        else:\n",
    "            split = 'test'\n",
    "\n",
    "        with file_path.open(mode='r', encoding='utf-8') as text_file: # read corpus lines\n",
    "                lines = text_file.readlines()\n",
    "\n",
    "        if len(lines) > 0:\n",
    "        # split the first line based on tabs\n",
    "                    fields = lines[0].strip().split('\\t')\n",
    "        if len(fields) >= 2:\n",
    "                text = fields[0]  # store the first field as 'text'\n",
    "                POS = fields[1]   # store the second field as 'POS'\n",
    "\n",
    "                dataframe_row = {  #build DataFrame rows\n",
    "                    \"text\": text,\n",
    "                    \"POS\": POS,\n",
    "                    \"split\": split\n",
    "                }\n",
    "\n",
    "                dataframe_rows.append(dataframe_row) #append rows\n",
    "\n",
    "# corpus DataFrame\n",
    "corpus_df = pd.DataFrame(dataframe_rows) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>POS</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Japan</td>\n",
       "      <td>NNP</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GOODY</td>\n",
       "      <td>NNP</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lancaster</td>\n",
       "      <td>NNP</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Komatsu</td>\n",
       "      <td>NNP</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Criticism</td>\n",
       "      <td>NNP</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text  POS  split\n",
       "0      Japan  NNP  train\n",
       "1      GOODY  NNP  train\n",
       "2  Lancaster  NNP  train\n",
       "3    Komatsu  NNP  train\n",
       "4  Criticism  NNP  train"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe structure:\n",
      "          text  POS  split\n",
      "0        Japan  NNP  train\n",
      "1        GOODY  NNP  train\n",
      "2    Lancaster  NNP  train\n",
      "3      Komatsu  NNP  train\n",
      "4    Criticism  NNP  train\n",
      "..         ...  ...    ...\n",
      "194          @   IN   test\n",
      "195     PAPERS  NNS   test\n",
      "196   Heritage  NNP   test\n",
      "197   Genetics  NNP   test\n",
      "198       When  WRB   test\n",
      "\n",
      "[199 rows x 3 columns]\n",
      "\n",
      "Total rows 199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataframe structure:\")\n",
    "print(corpus_df)\n",
    "print()\n",
    "\n",
    "print(\"Total rows %d\" % (len(corpus_df)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 2: Text encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode text into numerical format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gensim in /home/elements72/.local/lib/python3.10/site-packages (4.3.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/elements72/.local/lib/python3.10/site-packages (from gensim) (6.4.0)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /home/elements72/.local/lib/python3.10/site-packages (from gensim) (1.9.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/elements72/.local/lib/python3.10/site-packages (from gensim) (1.23.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
