{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 - Part of Speech Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install lightning\n",
    "# !pip install torchtext.data\n",
    "# !pip install torchtext\n",
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: remove unused dependencies\n",
    "\n",
    "# file management\n",
    "import urllib\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# dataframe management\n",
    "import pandas as pd\n",
    "\n",
    "# data manipulation\n",
    "import numpy as np\n",
    "\n",
    "# for readability\n",
    "from tqdm import tqdm\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# pytorch lightning\n",
    "from lightning import LightningModule\n",
    "from lightning.pytorch import Trainer, seed_everything\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "# Glove and vocabulary\n",
    "from torchtext.vocab import GloVe, build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1: Corpus\n",
    "\n",
    "* **Download** the corpus.\n",
    "* **Encode** the corpus into a pandas.DataFrame object.\n",
    "* **Split** it in training, validation, and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownloadProgressBar(tqdm):\n",
    "    def update_to(self, b=1, bsize=1, tsize=None):\n",
    "        if tsize is not None:\n",
    "            self.total = tsize\n",
    "        self.update(b * bsize - self.n)\n",
    "\n",
    "\n",
    "def download_url(download_path: Path, url: str):\n",
    "    with DownloadProgressBar(unit='B', unit_scale=True,\n",
    "                             miniters=1, desc=url.split('/')[-1]) as t:\n",
    "        urllib.request.urlretrieve(url, filename=download_path, reporthook=t.update_to)\n",
    "\n",
    "\n",
    "def download_dataset(download_path: Path, url: str):\n",
    "    print(\"Downloading dataset...\")\n",
    "    download_url(url=url, download_path=download_path)\n",
    "    print(\"Download complete!\")\n",
    "\n",
    "\n",
    "def extract_dataset(download_path: Path, extract_path: Path):\n",
    "    print(\"Extracting dataset... (it may take a while...)\")\n",
    "    with zipfile.ZipFile(download_path, 'r') as zip_file:\n",
    "        zip_file.extractall(extract_path)\n",
    "\n",
    "    print(\"Extraction completed!\")\n",
    "\n",
    "    Path.unlink(download_path)\n",
    "    print(\"Deleted .zip dataset file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current work directory: c:\\Users\\merli\\OneDrive\\Desktop\\Github repos\\NLP\\A1\n"
     ]
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip\"\n",
    "dataset_name = \"dependency_treebank\"\n",
    "\n",
    "print(f\"Current work directory: {Path.cwd()}\")\n",
    "\n",
    "dataset_folder = Path.cwd().joinpath(\"Datasets\")\n",
    "\n",
    "if not dataset_folder.exists():\n",
    "    dataset_folder.mkdir(parents=True)\n",
    "\n",
    "dataset_zip_path = dataset_folder.joinpath(\"dependency_treebank.zip\")\n",
    "dataset_path = dataset_folder.joinpath(dataset_name)\n",
    "\n",
    "if not dataset_zip_path.exists():\n",
    "    download_dataset(dataset_zip_path, url)\n",
    "\n",
    "if not dataset_path.exists():\n",
    "    extract_dataset(dataset_zip_path, dataset_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the corpus into a pandas.DataFrame object and split it into train, validation and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corpus contains 200 documents.\n",
    "\n",
    "   * **Train**: Documents 1-100\n",
    "   * **Validation**: Documents 101-150\n",
    "   * **Test**: Documents 151-199"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_rows = []\n",
    "id = 0\n",
    "\n",
    "for i, file_path in enumerate(sorted(dataset_path.iterdir())):\n",
    "    if file_path.is_file():  # split corpus documents in the tree categories: train, validation, tests\n",
    "        if 1 <= i + 1 <= 100:\n",
    "            split = 'train'\n",
    "        elif 101 <= i + 1 <= 150:\n",
    "            split = 'validation'\n",
    "        else:\n",
    "            split = 'test'\n",
    "\n",
    "        with file_path.open(mode='r', encoding='utf-8') as text_file:  # read corpus lines\n",
    "            lines = text_file.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            fields = line.strip().split('\\t')\n",
    "            if len(fields) == 1:\n",
    "                id = id + 1\n",
    "            if len(fields) >= 2:\n",
    "                text = fields[0]  # store the first field as 'text'\n",
    "                POS = fields[1]  # store the second field as 'POS'\n",
    "                dataframe_row = {  #build DataFrame rows\n",
    "                    \"text\": text,\n",
    "                    \"POS\": POS,\n",
    "                    \"split\": split,\n",
    "                    \"id\": id\n",
    "                }\n",
    "\n",
    "                dataframe_rows.append(dataframe_row)  #append rows\n",
    "# corpus DataFrame\n",
    "corpus_df = pd.DataFrame(dataframe_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>POS</th>\n",
       "      <th>split</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pierre</td>\n",
       "      <td>NNP</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vinken</td>\n",
       "      <td>NNP</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>CD</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>years</td>\n",
       "      <td>NNS</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>old</td>\n",
       "      <td>JJ</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>will</td>\n",
       "      <td>MD</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>join</td>\n",
       "      <td>VB</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     text  POS  split  id\n",
       "0  Pierre  NNP  train   0\n",
       "1  Vinken  NNP  train   0\n",
       "2       ,    ,  train   0\n",
       "3      61   CD  train   0\n",
       "4   years  NNS  train   0\n",
       "5     old   JJ  train   0\n",
       "6       ,    ,  train   0\n",
       "7    will   MD  train   0\n",
       "8    join   VB  train   0\n",
       "9     the   DT  train   0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe structure:\n",
      "          text  POS  split    id\n",
      "0       Pierre  NNP  train     0\n",
      "1       Vinken  NNP  train     0\n",
      "2            ,    ,  train     0\n",
      "3           61   CD  train     0\n",
      "4        years  NNS  train     0\n",
      "...        ...  ...    ...   ...\n",
      "94079  quarter   NN   test  3715\n",
      "94080       of   IN   test  3715\n",
      "94081     next   JJ   test  3715\n",
      "94082     year   NN   test  3715\n",
      "94083        .    .   test  3715\n",
      "\n",
      "[94084 rows x 4 columns]\n",
      "\n",
      "Total rows 94084\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataframe structure:\")\n",
    "print(corpus_df)\n",
    "print()\n",
    "\n",
    "print(f\"Total rows {len(corpus_df)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, test, validation split\n",
    "df_train = corpus_df[corpus_df['split'] == 'train'].drop(columns=['split'])\n",
    "df_test = corpus_df[corpus_df['split'] == 'test'].drop(columns=['split'])\n",
    "df_val = corpus_df[corpus_df['split'] == 'validation'].drop(columns=['split'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 2: Text encoding\n",
    "\n",
    "* Embed words using **GloVe embeddings**.\n",
    "* TODO: see if we want to do it, otherwise remove it -> [Optional] You are free to experiment with text pre-processing: **make sure you do not delete any token!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embedding_model(embedding_dimension: int = 300):\n",
    "    emb_model = GloVe(name=\"6B\", dim=embedding_dimension)\n",
    "    return emb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "punctuation_and_symbol_pos = [\".\", \",\", \":\", '``', \"''\", \"$\", \"#\", \"-LRB-\", \"-RRB-\", \"SYM\", \"LS\"] #TODO check \"LS\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 4.b: OOV tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our vocabulary is stored in the GloVe object, and we simply edit its fields to add tokens and embedding vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOV tokens in the training set: 359\n",
      "Some OOV tokens: ['savers\\\\/investors', '520-lawyer', 'glenham', '3\\\\/4', 'index-arbitrage', 'ghkm', '436.01', '37-a-share', 'new-home', 'wtd', 'sometimes-tawdry', 'anti-china', 'intellectual-property', 'one-country', '-lrb-', 'bridgestone\\\\/firestone', '84-month', 'purepac', 'boorse', 'school-research', '2645.90', 'integra-a', 'junk-bond', '1\\\\/4', 'equal-opportunity', 'landonne', '18,444', 'satrum', 'rope-sight', 'nekoosa', 'language-housekeeper', 'tarwhine', 'securities-based', 'purhasing', '446.62', 'ratners', 'abortion-related', '497.34', 'chilver', 'less-serious', '456.64', 'incentive-bonus', 'school-board', 'veselich', 'we-japanese', 'higher-salaried', 'hummerstone', 'test-prep', 'ariail', '1.457']\n"
     ]
    }
   ],
   "source": [
    "# Find training set OOV tokens\n",
    "embedding_dim = 50\n",
    "embedder = load_embedding_model(embedding_dim)\n",
    "\n",
    "existing_vocab_tokens = set(embedder.itos)  # Tokens in the vocabulary, i.e. present in GloVe\n",
    "train_text = set([word.lower() for word in df_train['text']])\n",
    "\n",
    "train_oov_tokens = train_text - existing_vocab_tokens\n",
    "print(f\"OOV tokens in the training set: {len(train_oov_tokens)}\")\n",
    "print(f\"Some OOV tokens: {list(train_oov_tokens)[:50]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New vocabulary size: 400359\n"
     ]
    }
   ],
   "source": [
    "# Add training set OOV tokens to the GloVe embedder, sampling from a random uniform distribution for each feature in the respective range\n",
    "mins = torch.min(embedder.vectors, dim=0).values\n",
    "ranges = mins - torch.max(embedder.vectors, dim=0).values\n",
    "\n",
    "for token in train_oov_tokens:\n",
    "    embedder.itos.append(token)\n",
    "    embedder.stoi[token] = len(embedder.itos) - 1\n",
    "    embedder.vectors = torch.cat((embedder.vectors, (torch.rand(embedding_dim) * ranges + mins).unsqueeze(dim=0)), dim=0)\n",
    "\n",
    "# For the '[UNK]' token embedding, sample a vector from a normal distribution for each feature\n",
    "\n",
    "# Mean and std of the GloVe embeddings, for each feature\n",
    "means = torch.mean(embedder.vectors, dim=0)\n",
    "stds = torch.std(embedder.vectors, dim=0)\n",
    "unk_vector = torch.normal(means, stds)\n",
    "\n",
    "# The '[UNK]' token is not really added to the vocabulary (i.e. GloVe)\n",
    "# instead, we redefine the 'unk_init' function of the embedder to return the embedding vector corresponding to '[UNK]'\n",
    "embedder.unk_init = lambda x: unk_vector\n",
    "\n",
    "print(f\"New vocabulary size: {len(embedder.itos)}\")\n",
    "\n",
    "assert len(embedder.itos) == len(embedder.stoi) == embedder.vectors.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed words using GloVe embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the token to embedding mapping, we decided to use the following approach: the Dataset object takes care of calling the embedder every time it is queried to return a datapoint (\\_\\_getitem\\_\\_ method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = ([pos] for pos in corpus_df[\"POS\"].unique())\n",
    "pos_vocab = build_vocab_from_iterator(iterator)\n",
    "pos_vocab.append_token(\"<PAD>\")\n",
    "\n",
    "pos_padding_value = pos_vocab[\"<PAD>\"]\n",
    "punctuation_and_symbol_pos_indices = [pos_vocab[token] for token in punctuation_and_symbol_pos]\n",
    "\n",
    "\n",
    "class CorpusDataset(Dataset):\n",
    "    def __init__(self, dataframe: pd.DataFrame, embedder):\n",
    "        min_id = dataframe['id'].min()\n",
    "        dataframe['id'] = dataframe['id'] - min_id\n",
    "        self.dataframe = dataframe.groupby(\"id\")\n",
    "        self.embedder = embedder\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.dataframe.get_group(idx)\n",
    "        text = sentence['text'].to_list()\n",
    "        text = [token.lower() for token in text]        \n",
    "        \n",
    "        POS = sentence['POS'].to_list()\n",
    "        POS = torch.Tensor([pos_vocab[token] for token in POS])\n",
    "\n",
    "        embedded_text = self.embedder.get_vecs_by_tokens(text)\n",
    "\n",
    "        return embedded_text, POS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the dataset\n",
    "dataset_train = CorpusDataset(df_train, embedder)\n",
    "dataset_test = CorpusDataset(df_test, embedder)\n",
    "dataset_val = CorpusDataset(df_val, embedder)\n",
    "dataset_all = CorpusDataset(corpus_df, embedder)    # TODO: remove if not used\n",
    "\n",
    "\n",
    "# This collate function takes care of adding padding to the sequences\n",
    "# TODO - test if it works in the LSTM training\n",
    "def my_collate(batch):\n",
    "    sequences, labels = zip(*batch)\n",
    "\n",
    "    # max_len = max([len(seq) for seq in sequences])\n",
    "    # sequences_padded = [seq + [\"<PAD>\"] * (max_len - len(seq)) for seq in sequences]\n",
    "\n",
    "    sequences_padded = torch.nn.utils.rnn.pad_sequence(sequences, batch_first=True, padding_value=0)\n",
    "    labels_padded = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=pos_padding_value)\n",
    "\n",
    "    sequences_padded = sequences_padded.type(torch.float)\n",
    "    labels_padded = labels_padded.type(torch.long)\n",
    "\n",
    "    return [sequences_padded, labels_padded]\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset_train, batch_size=32, collate_fn=my_collate)\n",
    "val_loader = DataLoader(dataset_val, batch_size=32, collate_fn=my_collate)\n",
    "test_loader = DataLoader(dataset_test, batch_size=32, collate_fn=my_collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 4: Metrics\n",
    "\n",
    "* Evaluate models using macro F1-score, computed over **all** tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We defined our own macro F1-score metric in order to accumulate FP, TP, FN, TN iteratively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torchmetrics import Metric\n",
    "from torchmetrics import ConfusionMatrix\n",
    "\n",
    "\n",
    "class F1ScoreCustom(Metric):\n",
    "    def __init__(self, num_classes: int, pos_padding_value: int = pos_padding_value, punctuation_and_symbol_pos_indices: list = punctuation_and_symbol_pos_indices):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.mask = torch.ones([num_classes])\n",
    "        self.mask[[pos_padding_value] + punctuation_and_symbol_pos_indices] = 0\n",
    "        \n",
    "        self.add_state(\"true_positive\", default=torch.zeros([num_classes]), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"false_negative\", default=torch.zeros([num_classes]), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"false_positive\", default=torch.zeros([num_classes]), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, y_hat_class: torch.Tensor, y_class: torch.Tensor):\n",
    "        confusion_matrix_metric = ConfusionMatrix(num_classes=self.num_classes, task=\"multiclass\")\n",
    "        confusion_matrix = confusion_matrix_metric(y_hat_class, y_class)\n",
    "\n",
    "        # # Confusion matrix, TP, FN and FP for class 0 \n",
    "        # #   TRUE LABEL\n",
    "        # #   0               TP     FN     FN     FN     FN       \n",
    "        # #   1               FP       \n",
    "        # #   2               FP               \n",
    "        # #   3               FP                       \n",
    "        # #   4               FP                                \n",
    "        # # PREDICTED LABEL   0       1      2      3      4\n",
    "        # \n",
    "\n",
    "        true_positive = torch.Tensor([confusion_matrix[i][i] for i in range(self.num_classes)])\n",
    "        false_negative = torch.Tensor([sum(confusion_matrix[i, :]) - true_positive[i] for i in range(self.num_classes)])\n",
    "        false_positive = torch.Tensor([sum(confusion_matrix[:, i]) - true_positive[i] for i in range(self.num_classes)])\n",
    "\n",
    "        self.true_positive += true_positive\n",
    "        self.false_negative += false_negative\n",
    "        self.false_positive += false_positive\n",
    "\n",
    "    def compute(self):\n",
    "        precision = self.true_positive / (self.true_positive + self.false_positive)\n",
    "        recall = self.true_positive / (self.true_positive + self.false_negative)\n",
    "\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "        f1 = f1 * self.mask\n",
    "\n",
    "        return f1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 3: Model definition\n",
    "\n",
    "* **Baseline**: implement a Bidirectional LSTM with a Dense layer on top.\n",
    "\n",
    "* **Model 1**: add an additional LSTM layer to the Baseline model.\n",
    "* **Model 2**: add an additional Dense layer to the Baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model: Bidirectional LSTM + Dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMModel(LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, target_padding_value=pos_padding_value):\n",
    "        super(BiLSTMModel, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.target_padding_value = target_padding_value\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_dim,\n",
    "                            hidden_size=hidden_dim,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)  # Multiplied by 2 due to the bidirectionality\n",
    "\n",
    "        self._train_f1_metric = F1ScoreCustom(num_classes=output_dim, pos_padding_value=self.target_padding_value)\n",
    "        self._val_f1_metric = F1ScoreCustom(num_classes=output_dim, pos_padding_value=self.target_padding_value)\n",
    "        self._test_f1_metric = F1ScoreCustom(num_classes=output_dim, pos_padding_value=self.target_padding_value)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # embedding = self.embedding_layer(x)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        # lstm_out (batch_size, seq_length, hidden_size * 2)\n",
    "        out = self.fc(lstm_out)\n",
    "        # out (batch_size, seq_length, output_dim)\n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "\n",
    "        # Change shape from (batchsize, sequence_len, classes) to be (batchsize, classes, sequence_len) to compute loss function\n",
    "        y_hat = torch.movedim(y_hat, 1, 2)\n",
    "        loss = nn.functional.cross_entropy(y_hat, y, ignore_index=self.target_padding_value)\n",
    "\n",
    "        self.log_dict({'train_loss': loss, 'step': float(self.current_epoch)}, on_epoch=True, prog_bar=True, logger=True,\n",
    "                      on_step=False, reduce_fx=\"mean\")\n",
    "\n",
    "        y_hat_class = torch.argmax(y_hat, dim=1)\n",
    "        self._train_f1_metric.update(y_hat_class, y)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        y_hat = torch.movedim(y_hat, 1, 2)\n",
    "\n",
    "        loss = nn.functional.cross_entropy(y_hat, y, ignore_index=self.target_padding_value)\n",
    "        self.log_dict({'val_loss': loss, 'step': float(self.current_epoch)}, on_epoch=True, prog_bar=True, logger=True,\n",
    "                      reduce_fx=\"mean\")\n",
    "\n",
    "        y_hat_class = torch.argmax(y_hat, dim=1)\n",
    "        self._val_f1_metric.update(y_hat_class, y)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        y_hat = torch.movedim(y_hat, 1, 2)\n",
    "        loss = nn.functional.cross_entropy(y_hat, y, ignore_index=self.target_padding_value)\n",
    "\n",
    "        self.log_dict({'test_loss': loss, 'step': float(self.current_epoch)}, on_epoch=True, prog_bar=True, logger=True,\n",
    "                      reduce_fx=\"mean\")\n",
    "\n",
    "        y_hat_class = torch.argmax(y_hat, dim=1)\n",
    "        self._test_f1_metric.update(y_hat_class, y)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "    def _compute_f1(self, f1_metric):\n",
    "        mean_f1_score = f1_metric.compute()\n",
    "\n",
    "        # Create a mask that is False for NaNs\n",
    "        mask = torch.isnan(mean_f1_score)\n",
    "\n",
    "        # Invert the mask: True for valid entries, False for NaNs\n",
    "        valid_data = mean_f1_score[~mask]\n",
    "\n",
    "        # Compute the mean of the non-NaN values\n",
    "        mean_value = torch.mean(valid_data)\n",
    "\n",
    "        return mean_value\n",
    "\n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        mean_f1_score = self._compute_f1(self._train_f1_metric)\n",
    "        self.log_dict({\"train_f1\": mean_f1_score, 'step': float(self.current_epoch)}, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self._train_f1_metric.reset()\n",
    "\n",
    "    def on_validation_epoch_end(self) -> None:\n",
    "        mean_f1_score = self._compute_f1(self._val_f1_metric)\n",
    "        self.log_dict({\"val_f1\": mean_f1_score, 'step': float(self.current_epoch)}, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self._val_f1_metric.reset()\n",
    "\n",
    "    def on_test_epoch_end(self) -> None:\n",
    "        mean_f1_score = self._compute_f1(self._test_f1_metric)\n",
    "        self.log_dict({\"test_f1\": mean_f1_score, 'step': float(self.current_epoch)}, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self._test_f1_metric.reset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Bidirectional 2-layers LSTM + Dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model1(LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, target_padding_value=pos_padding_value):\n",
    "        super(Model1, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.target_padding_value = target_padding_value\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_dim,\n",
    "                            hidden_size=hidden_dim,\n",
    "                            num_layers=2,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)  # Multiplied by 2 due to the bidirectionality\n",
    "\n",
    "        self._train_f1_metric = F1ScoreCustom(num_classes=output_dim, pos_padding_value=self.target_padding_value)\n",
    "        self._val_f1_metric = F1ScoreCustom(num_classes=output_dim, pos_padding_value=self.target_padding_value)\n",
    "        self._test_f1_metric = F1ScoreCustom(num_classes=output_dim, pos_padding_value=self.target_padding_value)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # embedding = self.embedding_layer(x)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        # lstm_out (batch_size, seq_length, hidden_size * 2)\n",
    "        out = self.fc(lstm_out)\n",
    "        # out (batch_size, seq_length, output_dim)\n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "\n",
    "        # Change shape from (batchsize, sequence_len, classes) to be (batchsize, classes, sequence_len) to compute loss function\n",
    "        y_hat = torch.movedim(y_hat, 1, 2)\n",
    "        loss = nn.functional.cross_entropy(y_hat, y, ignore_index=self.target_padding_value)\n",
    "\n",
    "        self.log_dict({'train_loss': loss, 'step': float(self.current_epoch)}, on_epoch=True, prog_bar=True, logger=True,\n",
    "                      on_step=False, reduce_fx=\"mean\")\n",
    "\n",
    "        y_hat_class = torch.argmax(y_hat, dim=1)\n",
    "        self._train_f1_metric.update(y_hat_class, y)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        y_hat = torch.movedim(y_hat, 1, 2)\n",
    "\n",
    "        loss = nn.functional.cross_entropy(y_hat, y, ignore_index=self.target_padding_value)\n",
    "        self.log_dict({'val_loss': loss, 'step': float(self.current_epoch)}, on_epoch=True, prog_bar=True, logger=True,\n",
    "                      reduce_fx=\"mean\")\n",
    "\n",
    "        y_hat_class = torch.argmax(y_hat, dim=1)\n",
    "        self._val_f1_metric.update(y_hat_class, y)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        y_hat = torch.movedim(y_hat, 1, 2)\n",
    "        loss = nn.functional.cross_entropy(y_hat, y, ignore_index=self.target_padding_value)\n",
    "\n",
    "        self.log_dict({'test_loss': loss, 'step': float(self.current_epoch)}, on_epoch=True, prog_bar=True, logger=True,\n",
    "                      reduce_fx=\"mean\")\n",
    "\n",
    "        y_hat_class = torch.argmax(y_hat, dim=1)\n",
    "        self._test_f1_metric.update(y_hat_class, y)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "    def _compute_f1(self, f1_metric):\n",
    "        mean_f1_score = f1_metric.compute()\n",
    "\n",
    "        # Create a mask that is False for NaNs\n",
    "        mask = torch.isnan(mean_f1_score)\n",
    "\n",
    "        # Invert the mask: True for valid entries, False for NaNs\n",
    "        valid_data = mean_f1_score[~mask]\n",
    "\n",
    "        # Compute the mean of the non-NaN values\n",
    "        mean_value = torch.mean(valid_data)\n",
    "\n",
    "        return mean_value\n",
    "\n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        mean_f1_score = self._compute_f1(self._train_f1_metric)\n",
    "        self.log_dict({\"train_f1\": mean_f1_score, 'step': float(self.current_epoch)}, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self._train_f1_metric.reset()\n",
    "\n",
    "    def on_validation_epoch_end(self) -> None:\n",
    "        mean_f1_score = self._compute_f1(self._val_f1_metric)\n",
    "        self.log_dict({\"val_f1\": mean_f1_score, 'step': float(self.current_epoch)}, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self._val_f1_metric.reset()\n",
    "\n",
    "    def on_test_epoch_end(self) -> None:\n",
    "        mean_f1_score = self._compute_f1(self._test_f1_metric)\n",
    "        self.log_dict({\"test_f1\": mean_f1_score, 'step': float(self.current_epoch)}, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self._test_f1_metric.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Bidirectional LSTM + 2 Dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Model2(LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, fc_size,\n",
    "                 target_padding_value=pos_padding_value):\n",
    "        super(Model2, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.target_padding_value = target_padding_value\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_dim,\n",
    "                            hidden_size=hidden_dim,\n",
    "                            num_layers=2,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "        self.fc_1 = nn.Linear(hidden_dim * 2, fc_size)  # Multiplied by 2 due to bidirectionality\n",
    "        self.fc_2 = nn.Linear(fc_size, output_dim)\n",
    "\n",
    "        self._train_f1_metric = F1ScoreCustom(num_classes=output_dim, pos_padding_value=self.target_padding_value)\n",
    "        self._val_f1_metric = F1ScoreCustom(num_classes=output_dim, pos_padding_value=self.target_padding_value)\n",
    "        self._test_f1_metric = F1ScoreCustom(num_classes=output_dim, pos_padding_value=self.target_padding_value)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # embedding = self.embedding_layer(x)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        # lstm_out (batch_size, seq_length, hidden_size * 2)\n",
    "        out = self.fc_1(lstm_out)\n",
    "        out = self.fc_2(out)\n",
    "        # out (batch_size, seq_length, output_dim)\n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "\n",
    "        # Change shape from (batchsize, sequence_len, classes) to be (batchsize, classes, sequence_len) to compute loss function\n",
    "        y_hat = torch.movedim(y_hat, 1, 2)\n",
    "        loss = nn.functional.cross_entropy(y_hat, y, ignore_index=self.target_padding_value)\n",
    "\n",
    "        self.log_dict({'train_loss': loss, 'step': float(self.current_epoch)}, on_epoch=True, prog_bar=True, logger=True,\n",
    "                      on_step=False, reduce_fx=\"mean\")\n",
    "\n",
    "        y_hat_class = torch.argmax(y_hat, dim=1)\n",
    "        self._train_f1_metric.update(y_hat_class, y)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        y_hat = torch.movedim(y_hat, 1, 2)\n",
    "\n",
    "        loss = nn.functional.cross_entropy(y_hat, y, ignore_index=self.target_padding_value)\n",
    "        self.log_dict({'val_loss': loss, 'step': float(self.current_epoch)}, on_epoch=True, prog_bar=True, logger=True,\n",
    "                      reduce_fx=\"mean\")\n",
    "\n",
    "        y_hat_class = torch.argmax(y_hat, dim=1)\n",
    "        self._val_f1_metric.update(y_hat_class, y)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        y_hat = torch.movedim(y_hat, 1, 2)\n",
    "        loss = nn.functional.cross_entropy(y_hat, y, ignore_index=self.target_padding_value)\n",
    "\n",
    "        self.log_dict({'test_loss': loss, 'step': float(self.current_epoch)}, on_epoch=True, prog_bar=True, logger=True,\n",
    "                      reduce_fx=\"mean\")\n",
    "\n",
    "        y_hat_class = torch.argmax(y_hat, dim=1)\n",
    "        self._test_f1_metric.update(y_hat_class, y)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "    def _compute_f1(self, f1_metric):\n",
    "        mean_f1_score = f1_metric.compute()\n",
    "\n",
    "        # Create a mask that is False for NaNs\n",
    "        mask = torch.isnan(mean_f1_score)\n",
    "\n",
    "        # Invert the mask: True for valid entries, False for NaNs\n",
    "        valid_data = mean_f1_score[~mask]\n",
    "\n",
    "        # Compute the mean of the non-NaN values\n",
    "        mean_value = torch.mean(valid_data)\n",
    "\n",
    "        return mean_value\n",
    "\n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        mean_f1_score = self._compute_f1(self._train_f1_metric)\n",
    "        self.log_dict({\"train_f1\": mean_f1_score, 'step': float(self.current_epoch)}, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self._train_f1_metric.reset()\n",
    "\n",
    "    def on_validation_epoch_end(self) -> None:\n",
    "        mean_f1_score = self._compute_f1(self._val_f1_metric)\n",
    "        self.log_dict({\"val_f1\": mean_f1_score, 'step': float(self.current_epoch)}, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self._val_f1_metric.reset()\n",
    "\n",
    "    def on_test_epoch_end(self) -> None:\n",
    "        mean_f1_score = self._compute_f1(self._test_f1_metric)\n",
    "        self.log_dict({\"test_f1\": mean_f1_score, 'step': float(self.current_epoch)}, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self._test_f1_metric.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 5: Training and Evaluation\n",
    "\n",
    "* Train **all** models on the train set.\n",
    "* Evaluate **all** models on the validation set.\n",
    "* Compute metrics on the validation set.\n",
    "* Pick **at least** three seeds for robust estimation.\n",
    "* Pick the **best** performing model according to the observed validation set performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix all possible sources of randomness\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and evaluation\n",
    "\n",
    "#### Training all models on training set and evalutating on validation set at every epoch s.t. to keep the best model for each model/seed pair.\n",
    "#### Both cross entropy loss and F1-Score are computed at each evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model baseline with seed 6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: c:\\Users\\merli\\OneDrive\\Desktop\\Github repos\\NLP\\A1\\logs\\lightning_logs\\baseline_seed6\n",
      "\n",
      "  | Name             | Type          | Params\n",
      "---------------------------------------------------\n",
      "0 | lstm             | LSTM          | 184 K \n",
      "1 | fc               | Linear        | 11.8 K\n",
      "2 | _train_f1_metric | F1ScoreCustom | 0     \n",
      "3 | _val_f1_metric   | F1ScoreCustom | 0     \n",
      "4 | _test_f1_metric  | F1ScoreCustom | 0     \n",
      "---------------------------------------------------\n",
      "196 K     Trainable params\n",
      "0         Non-trainable params\n",
      "196 K     Total params\n",
      "0.785     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\edo\\envs\\nlp\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\edo\\envs\\nlp\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 59/59 [00:38<00:00,  1.54it/s, v_num=0, val_loss=2.390, step=0.000, val_f1=0.237, train_loss=2.940]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 2.393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 59/59 [00:36<00:00,  1.63it/s, v_num=0, val_loss=1.500, step=1.000, val_f1=0.293, train_loss=1.880, train_f1=0.0928]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.892 >= min_delta = 0.0. New best score: 1.501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 59/59 [00:35<00:00,  1.66it/s, v_num=0, val_loss=1.160, step=2.000, val_f1=0.410, train_loss=1.270, train_f1=0.241] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.343 >= min_delta = 0.0. New best score: 1.158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 59/59 [00:37<00:00,  1.58it/s, v_num=0, val_loss=0.985, step=3.000, val_f1=0.435, train_loss=1.010, train_f1=0.371]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.173 >= min_delta = 0.0. New best score: 0.985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 59/59 [00:33<00:00,  1.75it/s, v_num=0, val_loss=0.878, step=4.000, val_f1=0.451, train_loss=0.869, train_f1=0.438]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.107 >= min_delta = 0.0. New best score: 0.878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 59/59 [00:34<00:00,  1.72it/s, v_num=0, val_loss=0.806, step=5.000, val_f1=0.475, train_loss=0.775, train_f1=0.450]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.072 >= min_delta = 0.0. New best score: 0.806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 59/59 [00:33<00:00,  1.78it/s, v_num=0, val_loss=0.753, step=6.000, val_f1=0.516, train_loss=0.708, train_f1=0.482]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.053 >= min_delta = 0.0. New best score: 0.753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 59/59 [00:36<00:00,  1.60it/s, v_num=0, val_loss=0.713, step=7.000, val_f1=0.525, train_loss=0.656, train_f1=0.513]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.040 >= min_delta = 0.0. New best score: 0.713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 59/59 [00:31<00:00,  1.89it/s, v_num=0, val_loss=0.681, step=8.000, val_f1=0.538, train_loss=0.614, train_f1=0.514]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.032 >= min_delta = 0.0. New best score: 0.681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 59/59 [00:28<00:00,  2.08it/s, v_num=0, val_loss=0.654, step=9.000, val_f1=0.531, train_loss=0.578, train_f1=0.535]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.027 >= min_delta = 0.0. New best score: 0.654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 59/59 [00:24<00:00,  2.44it/s, v_num=0, val_loss=0.630, step=10.00, val_f1=0.540, train_loss=0.545, train_f1=0.549]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.023 >= min_delta = 0.0. New best score: 0.630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 59/59 [00:23<00:00,  2.52it/s, v_num=0, val_loss=0.610, step=11.00, val_f1=0.540, train_loss=0.517, train_f1=0.562]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.020 >= min_delta = 0.0. New best score: 0.610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 59/59 [00:25<00:00,  2.32it/s, v_num=0, val_loss=0.593, step=12.00, val_f1=0.536, train_loss=0.490, train_f1=0.559]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.017 >= min_delta = 0.0. New best score: 0.593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 59/59 [00:24<00:00,  2.40it/s, v_num=0, val_loss=0.578, step=13.00, val_f1=0.553, train_loss=0.466, train_f1=0.572]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.015 >= min_delta = 0.0. New best score: 0.578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 59/59 [00:25<00:00,  2.36it/s, v_num=0, val_loss=0.565, step=14.00, val_f1=0.563, train_loss=0.443, train_f1=0.570]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.013 >= min_delta = 0.0. New best score: 0.565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 59/59 [00:24<00:00,  2.44it/s, v_num=0, val_loss=0.554, step=15.00, val_f1=0.570, train_loss=0.422, train_f1=0.581]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.012 >= min_delta = 0.0. New best score: 0.554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 59/59 [00:26<00:00,  2.19it/s, v_num=0, val_loss=0.543, step=16.00, val_f1=0.570, train_loss=0.401, train_f1=0.590]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.010 >= min_delta = 0.0. New best score: 0.543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 59/59 [00:24<00:00,  2.40it/s, v_num=0, val_loss=0.534, step=17.00, val_f1=0.576, train_loss=0.382, train_f1=0.588]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.009 >= min_delta = 0.0. New best score: 0.534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 59/59 [00:26<00:00,  2.25it/s, v_num=0, val_loss=0.527, step=18.00, val_f1=0.588, train_loss=0.363, train_f1=0.600]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.008 >= min_delta = 0.0. New best score: 0.527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 59/59 [00:32<00:00,  1.80it/s, v_num=0, val_loss=0.520, step=19.00, val_f1=0.591, train_loss=0.345, train_f1=0.608]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 59/59 [00:35<00:00,  1.67it/s, v_num=0, val_loss=0.516, step=20.00, val_f1=0.579, train_loss=0.328, train_f1=0.606]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 59/59 [00:35<00:00,  1.67it/s, v_num=0, val_loss=0.511, step=21.00, val_f1=0.578, train_loss=0.312, train_f1=0.617]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 59/59 [00:33<00:00,  1.78it/s, v_num=0, val_loss=0.508, step=22.00, val_f1=0.579, train_loss=0.296, train_f1=0.625]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 59/59 [00:24<00:00,  2.37it/s, v_num=0, val_loss=0.505, step=23.00, val_f1=0.579, train_loss=0.281, train_f1=0.629]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 59/59 [00:27<00:00,  2.18it/s, v_num=0, val_loss=0.502, step=24.00, val_f1=0.580, train_loss=0.266, train_f1=0.635]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 59/59 [00:21<00:00,  2.69it/s, v_num=0, val_loss=0.501, step=25.00, val_f1=0.584, train_loss=0.253, train_f1=0.641]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 59/59 [00:23<00:00,  2.53it/s, v_num=0, val_loss=0.497, step=28.00, val_f1=0.574, train_loss=0.218, train_f1=0.655]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 59/59 [00:24<00:00,  2.41it/s, v_num=0, val_loss=0.502, step=31.00, val_f1=0.571, train_loss=0.179, train_f1=0.670]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 3 records. Best score: 0.497. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 59/59 [00:24<00:00,  2.41it/s, v_num=0, val_loss=0.502, step=31.00, val_f1=0.571, train_loss=0.179, train_f1=0.670]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 90\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model baseline with seed 90...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: c:\\Users\\merli\\OneDrive\\Desktop\\Github repos\\NLP\\A1\\logs\\lightning_logs\\baseline_seed90\n",
      "\n",
      "  | Name             | Type          | Params\n",
      "---------------------------------------------------\n",
      "0 | lstm             | LSTM          | 184 K \n",
      "1 | fc               | Linear        | 11.8 K\n",
      "2 | _train_f1_metric | F1ScoreCustom | 0     \n",
      "3 | _val_f1_metric   | F1ScoreCustom | 0     \n",
      "4 | _test_f1_metric  | F1ScoreCustom | 0     \n",
      "---------------------------------------------------\n",
      "196 K     Trainable params\n",
      "0         Non-trainable params\n",
      "196 K     Total params\n",
      "0.785     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 59/59 [00:26<00:00,  2.27it/s, v_num=0, val_loss=2.360, step=0.000, val_f1=0.299, train_loss=2.920]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 2.361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 59/59 [00:23<00:00,  2.48it/s, v_num=0, val_loss=1.500, step=1.000, val_f1=0.303, train_loss=1.870, train_f1=0.112]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.856 >= min_delta = 0.0. New best score: 1.505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 59/59 [01:08<00:00,  0.86it/s, v_num=0, val_loss=1.170, step=2.000, val_f1=0.397, train_loss=1.280, train_f1=0.238]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.337 >= min_delta = 0.0. New best score: 1.167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 59/59 [01:50<00:00,  0.54it/s, v_num=0, val_loss=0.995, step=3.000, val_f1=0.429, train_loss=1.020, train_f1=0.366]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.172 >= min_delta = 0.0. New best score: 0.995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 59/59 [01:19<00:00,  0.74it/s, v_num=0, val_loss=0.887, step=4.000, val_f1=0.456, train_loss=0.878, train_f1=0.415]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.108 >= min_delta = 0.0. New best score: 0.887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 59/59 [01:29<00:00,  0.66it/s, v_num=0, val_loss=0.812, step=5.000, val_f1=0.489, train_loss=0.784, train_f1=0.446]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.075 >= min_delta = 0.0. New best score: 0.812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 59/59 [00:43<00:00,  1.34it/s, v_num=0, val_loss=0.757, step=6.000, val_f1=0.525, train_loss=0.715, train_f1=0.485]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.055 >= min_delta = 0.0. New best score: 0.757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 59/59 [00:31<00:00,  1.90it/s, v_num=0, val_loss=0.716, step=7.000, val_f1=0.512, train_loss=0.663, train_f1=0.514]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.042 >= min_delta = 0.0. New best score: 0.716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 59/59 [00:34<00:00,  1.71it/s, v_num=0, val_loss=0.683, step=8.000, val_f1=0.521, train_loss=0.620, train_f1=0.527]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.033 >= min_delta = 0.0. New best score: 0.683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 59/59 [00:28<00:00,  2.06it/s, v_num=0, val_loss=0.656, step=9.000, val_f1=0.535, train_loss=0.583, train_f1=0.531]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.026 >= min_delta = 0.0. New best score: 0.656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 59/59 [00:29<00:00,  1.98it/s, v_num=0, val_loss=0.634, step=10.00, val_f1=0.529, train_loss=0.551, train_f1=0.547]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.022 >= min_delta = 0.0. New best score: 0.634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 59/59 [00:25<00:00,  2.35it/s, v_num=0, val_loss=0.615, step=11.00, val_f1=0.542, train_loss=0.522, train_f1=0.562]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.019 >= min_delta = 0.0. New best score: 0.615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 59/59 [00:26<00:00,  2.21it/s, v_num=0, val_loss=0.598, step=12.00, val_f1=0.553, train_loss=0.496, train_f1=0.549]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.017 >= min_delta = 0.0. New best score: 0.598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 59/59 [00:24<00:00,  2.45it/s, v_num=0, val_loss=0.583, step=13.00, val_f1=0.549, train_loss=0.472, train_f1=0.565]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.015 >= min_delta = 0.0. New best score: 0.583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 59/59 [00:26<00:00,  2.21it/s, v_num=0, val_loss=0.570, step=14.00, val_f1=0.555, train_loss=0.449, train_f1=0.578]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.013 >= min_delta = 0.0. New best score: 0.570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 59/59 [00:23<00:00,  2.46it/s, v_num=0, val_loss=0.559, step=15.00, val_f1=0.562, train_loss=0.428, train_f1=0.589]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.012 >= min_delta = 0.0. New best score: 0.559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 59/59 [00:27<00:00,  2.11it/s, v_num=0, val_loss=0.548, step=16.00, val_f1=0.567, train_loss=0.407, train_f1=0.602]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.010 >= min_delta = 0.0. New best score: 0.548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 59/59 [00:23<00:00,  2.54it/s, v_num=0, val_loss=0.539, step=17.00, val_f1=0.569, train_loss=0.388, train_f1=0.598]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.009 >= min_delta = 0.0. New best score: 0.539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 59/59 [00:24<00:00,  2.37it/s, v_num=0, val_loss=0.531, step=18.00, val_f1=0.567, train_loss=0.369, train_f1=0.597]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.008 >= min_delta = 0.0. New best score: 0.531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 59/59 [00:27<00:00,  2.16it/s, v_num=0, val_loss=0.524, step=19.00, val_f1=0.584, train_loss=0.351, train_f1=0.606]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.007 >= min_delta = 0.0. New best score: 0.524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 59/59 [00:24<00:00,  2.40it/s, v_num=0, val_loss=0.518, step=20.00, val_f1=0.585, train_loss=0.334, train_f1=0.612]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 59/59 [00:23<00:00,  2.48it/s, v_num=0, val_loss=0.514, step=21.00, val_f1=0.587, train_loss=0.317, train_f1=0.624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 59/59 [00:24<00:00,  2.42it/s, v_num=0, val_loss=0.510, step=22.00, val_f1=0.590, train_loss=0.301, train_f1=0.635]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 59/59 [00:24<00:00,  2.41it/s, v_num=0, val_loss=0.507, step=23.00, val_f1=0.590, train_loss=0.285, train_f1=0.641]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 59/59 [00:23<00:00,  2.53it/s, v_num=0, val_loss=0.505, step=24.00, val_f1=0.587, train_loss=0.270, train_f1=0.649]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 59/59 [00:25<00:00,  2.30it/s, v_num=0, val_loss=0.503, step=25.00, val_f1=0.576, train_loss=0.256, train_f1=0.657]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 59/59 [00:23<00:00,  2.51it/s, v_num=0, val_loss=0.503, step=26.00, val_f1=0.576, train_loss=0.242, train_f1=0.660]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 59/59 [00:25<00:00,  2.28it/s, v_num=0, val_loss=0.505, step=29.00, val_f1=0.560, train_loss=0.204, train_f1=0.663]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 3 records. Best score: 0.503. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 59/59 [00:25<00:00,  2.28it/s, v_num=0, val_loss=0.505, step=29.00, val_f1=0.560, train_loss=0.204, train_f1=0.663]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 157\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: c:\\Users\\merli\\OneDrive\\Desktop\\Github repos\\NLP\\A1\\logs\\lightning_logs\\baseline_seed157\n",
      "\n",
      "  | Name             | Type          | Params\n",
      "---------------------------------------------------\n",
      "0 | lstm             | LSTM          | 184 K \n",
      "1 | fc               | Linear        | 11.8 K\n",
      "2 | _train_f1_metric | F1ScoreCustom | 0     \n",
      "3 | _val_f1_metric   | F1ScoreCustom | 0     \n",
      "4 | _test_f1_metric  | F1ScoreCustom | 0     \n",
      "---------------------------------------------------\n",
      "196 K     Trainable params\n",
      "0         Non-trainable params\n",
      "196 K     Total params\n",
      "0.785     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model baseline with seed 157...\n",
      "Epoch 0: 100%|██████████| 59/59 [00:23<00:00,  2.53it/s, v_num=0, val_loss=2.320, step=0.000, val_f1=0.302, train_loss=2.920]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 2.322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 59/59 [00:24<00:00,  2.37it/s, v_num=0, val_loss=1.480, step=1.000, val_f1=0.304, train_loss=1.830, train_f1=0.104]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.842 >= min_delta = 0.0. New best score: 1.480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 59/59 [00:24<00:00,  2.39it/s, v_num=0, val_loss=1.150, step=2.000, val_f1=0.418, train_loss=1.260, train_f1=0.242]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.326 >= min_delta = 0.0. New best score: 1.154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 59/59 [00:29<00:00,  2.01it/s, v_num=0, val_loss=0.988, step=3.000, val_f1=0.425, train_loss=1.020, train_f1=0.380]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.166 >= min_delta = 0.0. New best score: 0.988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 59/59 [00:23<00:00,  2.52it/s, v_num=0, val_loss=0.886, step=4.000, val_f1=0.470, train_loss=0.878, train_f1=0.418]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.101 >= min_delta = 0.0. New best score: 0.886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 59/59 [00:17<00:00,  3.43it/s, v_num=0, val_loss=0.816, step=5.000, val_f1=0.485, train_loss=0.786, train_f1=0.446]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.070 >= min_delta = 0.0. New best score: 0.816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 59/59 [00:18<00:00,  3.19it/s, v_num=0, val_loss=0.764, step=6.000, val_f1=0.524, train_loss=0.718, train_f1=0.468]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.052 >= min_delta = 0.0. New best score: 0.764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 59/59 [00:19<00:00,  3.02it/s, v_num=0, val_loss=0.723, step=7.000, val_f1=0.542, train_loss=0.666, train_f1=0.512]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.041 >= min_delta = 0.0. New best score: 0.723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 59/59 [00:20<00:00,  2.86it/s, v_num=0, val_loss=0.690, step=8.000, val_f1=0.522, train_loss=0.623, train_f1=0.538]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.033 >= min_delta = 0.0. New best score: 0.690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 59/59 [00:19<00:00,  3.05it/s, v_num=0, val_loss=0.663, step=9.000, val_f1=0.519, train_loss=0.586, train_f1=0.529]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.028 >= min_delta = 0.0. New best score: 0.663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, v_num=0, val_loss=0.639, step=10.00, val_f1=0.528, train_loss=0.554, train_f1=0.544]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.023 >= min_delta = 0.0. New best score: 0.639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 59/59 [00:19<00:00,  3.10it/s, v_num=0, val_loss=0.619, step=11.00, val_f1=0.536, train_loss=0.526, train_f1=0.558]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.020 >= min_delta = 0.0. New best score: 0.619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 59/59 [00:19<00:00,  3.09it/s, v_num=0, val_loss=0.602, step=12.00, val_f1=0.543, train_loss=0.499, train_f1=0.568]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.017 >= min_delta = 0.0. New best score: 0.602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 59/59 [00:19<00:00,  3.04it/s, v_num=0, val_loss=0.586, step=13.00, val_f1=0.554, train_loss=0.475, train_f1=0.563]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.015 >= min_delta = 0.0. New best score: 0.586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 59/59 [00:18<00:00,  3.16it/s, v_num=0, val_loss=0.573, step=14.00, val_f1=0.548, train_loss=0.452, train_f1=0.560]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.013 >= min_delta = 0.0. New best score: 0.573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 59/59 [00:18<00:00,  3.11it/s, v_num=0, val_loss=0.561, step=15.00, val_f1=0.547, train_loss=0.431, train_f1=0.571]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.012 >= min_delta = 0.0. New best score: 0.561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 59/59 [00:19<00:00,  3.06it/s, v_num=0, val_loss=0.550, step=16.00, val_f1=0.554, train_loss=0.411, train_f1=0.571]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.010 >= min_delta = 0.0. New best score: 0.550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 59/59 [00:18<00:00,  3.22it/s, v_num=0, val_loss=0.541, step=17.00, val_f1=0.557, train_loss=0.391, train_f1=0.579]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.009 >= min_delta = 0.0. New best score: 0.541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 59/59 [00:18<00:00,  3.12it/s, v_num=0, val_loss=0.533, step=18.00, val_f1=0.561, train_loss=0.373, train_f1=0.591]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.008 >= min_delta = 0.0. New best score: 0.533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 59/59 [00:18<00:00,  3.19it/s, v_num=0, val_loss=0.527, step=19.00, val_f1=0.561, train_loss=0.355, train_f1=0.598]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.007 >= min_delta = 0.0. New best score: 0.527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 59/59 [00:20<00:00,  2.83it/s, v_num=0, val_loss=0.521, step=20.00, val_f1=0.547, train_loss=0.338, train_f1=0.590]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 59/59 [00:21<00:00,  2.73it/s, v_num=0, val_loss=0.516, step=21.00, val_f1=0.547, train_loss=0.322, train_f1=0.605]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 59/59 [00:18<00:00,  3.17it/s, v_num=0, val_loss=0.512, step=22.00, val_f1=0.554, train_loss=0.306, train_f1=0.610]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 59/59 [00:19<00:00,  3.08it/s, v_num=0, val_loss=0.510, step=23.00, val_f1=0.553, train_loss=0.291, train_f1=0.614]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 59/59 [00:18<00:00,  3.15it/s, v_num=0, val_loss=0.508, step=24.00, val_f1=0.560, train_loss=0.277, train_f1=0.620]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 59/59 [00:19<00:00,  3.04it/s, v_num=0, val_loss=0.508, step=25.00, val_f1=0.560, train_loss=0.263, train_f1=0.623]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 59/59 [00:20<00:00,  2.94it/s, v_num=0, val_loss=0.513, step=28.00, val_f1=0.558, train_loss=0.227, train_f1=0.637]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 3 records. Best score: 0.508. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 59/59 [00:20<00:00,  2.94it/s, v_num=0, val_loss=0.513, step=28.00, val_f1=0.558, train_loss=0.227, train_f1=0.637]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model model1 with seed 6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: c:\\Users\\merli\\OneDrive\\Desktop\\Github repos\\NLP\\A1\\logs\\lightning_logs\\model1_seed6\n",
      "\n",
      "  | Name             | Type          | Params\n",
      "---------------------------------------------------\n",
      "0 | lstm             | LSTM          | 579 K \n",
      "1 | fc               | Linear        | 11.8 K\n",
      "2 | _train_f1_metric | F1ScoreCustom | 0     \n",
      "3 | _val_f1_metric   | F1ScoreCustom | 0     \n",
      "4 | _test_f1_metric  | F1ScoreCustom | 0     \n",
      "---------------------------------------------------\n",
      "591 K     Trainable params\n",
      "0         Non-trainable params\n",
      "591 K     Total params\n",
      "2.366     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 59/59 [00:22<00:00,  2.63it/s, v_num=0, val_loss=2.490, step=0.000, val_f1=0.168, train_loss=2.960]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 2.493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 59/59 [00:22<00:00,  2.57it/s, v_num=0, val_loss=1.500, step=1.000, val_f1=0.346, train_loss=1.890, train_f1=0.0797]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.995 >= min_delta = 0.0. New best score: 1.497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 59/59 [00:24<00:00,  2.44it/s, v_num=0, val_loss=1.120, step=2.000, val_f1=0.406, train_loss=1.250, train_f1=0.238] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.379 >= min_delta = 0.0. New best score: 1.118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 59/59 [00:23<00:00,  2.49it/s, v_num=0, val_loss=0.932, step=3.000, val_f1=0.471, train_loss=0.973, train_f1=0.364]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.186 >= min_delta = 0.0. New best score: 0.932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 59/59 [00:23<00:00,  2.52it/s, v_num=0, val_loss=0.810, step=4.000, val_f1=0.458, train_loss=0.813, train_f1=0.448]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.122 >= min_delta = 0.0. New best score: 0.810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 59/59 [00:23<00:00,  2.52it/s, v_num=0, val_loss=0.721, step=5.000, val_f1=0.512, train_loss=0.703, train_f1=0.444]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.089 >= min_delta = 0.0. New best score: 0.721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 59/59 [00:23<00:00,  2.52it/s, v_num=0, val_loss=0.664, step=6.000, val_f1=0.538, train_loss=0.623, train_f1=0.484]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.058 >= min_delta = 0.0. New best score: 0.664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 59/59 [00:38<00:00,  1.53it/s, v_num=0, val_loss=0.625, step=7.000, val_f1=0.540, train_loss=0.560, train_f1=0.519]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.039 >= min_delta = 0.0. New best score: 0.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 59/59 [00:41<00:00,  1.41it/s, v_num=0, val_loss=0.589, step=8.000, val_f1=0.546, train_loss=0.510, train_f1=0.549]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.035 >= min_delta = 0.0. New best score: 0.589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 59/59 [00:43<00:00,  1.36it/s, v_num=0, val_loss=0.549, step=9.000, val_f1=0.567, train_loss=0.468, train_f1=0.569]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.041 >= min_delta = 0.0. New best score: 0.549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 59/59 [00:43<00:00,  1.37it/s, v_num=0, val_loss=0.518, step=10.00, val_f1=0.578, train_loss=0.429, train_f1=0.573]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.031 >= min_delta = 0.0. New best score: 0.518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 59/59 [00:41<00:00,  1.42it/s, v_num=0, val_loss=0.495, step=11.00, val_f1=0.589, train_loss=0.392, train_f1=0.589]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.023 >= min_delta = 0.0. New best score: 0.495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 59/59 [00:41<00:00,  1.41it/s, v_num=0, val_loss=0.476, step=12.00, val_f1=0.599, train_loss=0.360, train_f1=0.599]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.019 >= min_delta = 0.0. New best score: 0.476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 59/59 [00:42<00:00,  1.38it/s, v_num=0, val_loss=0.461, step=13.00, val_f1=0.592, train_loss=0.330, train_f1=0.612]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.016 >= min_delta = 0.0. New best score: 0.461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 59/59 [00:45<00:00,  1.29it/s, v_num=0, val_loss=0.449, step=14.00, val_f1=0.598, train_loss=0.303, train_f1=0.628]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.012 >= min_delta = 0.0. New best score: 0.449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 59/59 [00:43<00:00,  1.37it/s, v_num=0, val_loss=0.441, step=15.00, val_f1=0.610, train_loss=0.278, train_f1=0.638]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.008 >= min_delta = 0.0. New best score: 0.441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 59/59 [00:42<00:00,  1.39it/s, v_num=0, val_loss=0.437, step=16.00, val_f1=0.612, train_loss=0.255, train_f1=0.627]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 59/59 [00:41<00:00,  1.41it/s, v_num=0, val_loss=0.435, step=18.00, val_f1=0.603, train_loss=0.212, train_f1=0.632]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 59/59 [00:43<00:00,  1.37it/s, v_num=0, val_loss=0.429, step=19.00, val_f1=0.601, train_loss=0.193, train_f1=0.644]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 59/59 [00:41<00:00,  1.41it/s, v_num=0, val_loss=0.444, step=22.00, val_f1=0.594, train_loss=0.135, train_f1=0.668]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 3 records. Best score: 0.429. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 59/59 [00:41<00:00,  1.40it/s, v_num=0, val_loss=0.444, step=22.00, val_f1=0.594, train_loss=0.135, train_f1=0.668]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 90\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model model1 with seed 90...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: c:\\Users\\merli\\OneDrive\\Desktop\\Github repos\\NLP\\A1\\logs\\lightning_logs\\model1_seed90\n",
      "\n",
      "  | Name             | Type          | Params\n",
      "---------------------------------------------------\n",
      "0 | lstm             | LSTM          | 579 K \n",
      "1 | fc               | Linear        | 11.8 K\n",
      "2 | _train_f1_metric | F1ScoreCustom | 0     \n",
      "3 | _val_f1_metric   | F1ScoreCustom | 0     \n",
      "4 | _test_f1_metric  | F1ScoreCustom | 0     \n",
      "---------------------------------------------------\n",
      "591 K     Trainable params\n",
      "0         Non-trainable params\n",
      "591 K     Total params\n",
      "2.366     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 59/59 [00:37<00:00,  1.55it/s, v_num=0, val_loss=2.500, step=0.000, val_f1=0.191, train_loss=2.950]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 2.505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 59/59 [00:33<00:00,  1.76it/s, v_num=0, val_loss=1.510, step=1.000, val_f1=0.330, train_loss=1.930, train_f1=0.0848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.998 >= min_delta = 0.0. New best score: 1.507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 59/59 [00:29<00:00,  2.00it/s, v_num=0, val_loss=1.120, step=2.000, val_f1=0.411, train_loss=1.250, train_f1=0.249] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.384 >= min_delta = 0.0. New best score: 1.124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 59/59 [00:28<00:00,  2.07it/s, v_num=0, val_loss=0.930, step=3.000, val_f1=0.417, train_loss=0.970, train_f1=0.367]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.194 >= min_delta = 0.0. New best score: 0.930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 59/59 [00:29<00:00,  2.02it/s, v_num=0, val_loss=0.809, step=4.000, val_f1=0.464, train_loss=0.810, train_f1=0.420]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.121 >= min_delta = 0.0. New best score: 0.809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 59/59 [00:28<00:00,  2.09it/s, v_num=0, val_loss=0.725, step=5.000, val_f1=0.513, train_loss=0.704, train_f1=0.458]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.084 >= min_delta = 0.0. New best score: 0.725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 59/59 [00:29<00:00,  2.02it/s, v_num=0, val_loss=0.665, step=6.000, val_f1=0.544, train_loss=0.623, train_f1=0.479]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.060 >= min_delta = 0.0. New best score: 0.665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 59/59 [00:30<00:00,  1.96it/s, v_num=0, val_loss=0.622, step=7.000, val_f1=0.548, train_loss=0.560, train_f1=0.517]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.044 >= min_delta = 0.0. New best score: 0.622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 59/59 [00:30<00:00,  1.95it/s, v_num=0, val_loss=0.589, step=8.000, val_f1=0.561, train_loss=0.509, train_f1=0.548]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.032 >= min_delta = 0.0. New best score: 0.589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 59/59 [00:29<00:00,  2.00it/s, v_num=0, val_loss=0.560, step=9.000, val_f1=0.546, train_loss=0.466, train_f1=0.570]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.029 >= min_delta = 0.0. New best score: 0.560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 59/59 [00:29<00:00,  1.99it/s, v_num=0, val_loss=0.528, step=10.00, val_f1=0.557, train_loss=0.430, train_f1=0.571]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.032 >= min_delta = 0.0. New best score: 0.528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 59/59 [00:30<00:00,  1.93it/s, v_num=0, val_loss=0.508, step=11.00, val_f1=0.575, train_loss=0.396, train_f1=0.564]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.020 >= min_delta = 0.0. New best score: 0.508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 59/59 [00:28<00:00,  2.10it/s, v_num=0, val_loss=0.495, step=12.00, val_f1=0.586, train_loss=0.362, train_f1=0.592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.013 >= min_delta = 0.0. New best score: 0.495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 59/59 [00:28<00:00,  2.05it/s, v_num=0, val_loss=0.481, step=13.00, val_f1=0.595, train_loss=0.333, train_f1=0.611]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.014 >= min_delta = 0.0. New best score: 0.481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 59/59 [00:28<00:00,  2.05it/s, v_num=0, val_loss=0.465, step=14.00, val_f1=0.599, train_loss=0.308, train_f1=0.626]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.015 >= min_delta = 0.0. New best score: 0.465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 59/59 [00:28<00:00,  2.04it/s, v_num=0, val_loss=0.459, step=15.00, val_f1=0.607, train_loss=0.285, train_f1=0.626]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 59/59 [00:27<00:00,  2.12it/s, v_num=0, val_loss=0.453, step=16.00, val_f1=0.606, train_loss=0.261, train_f1=0.634]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 59/59 [00:31<00:00,  1.86it/s, v_num=0, val_loss=0.446, step=17.00, val_f1=0.594, train_loss=0.238, train_f1=0.629]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.007 >= min_delta = 0.0. New best score: 0.446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 59/59 [00:29<00:00,  1.99it/s, v_num=0, val_loss=0.437, step=18.00, val_f1=0.601, train_loss=0.215, train_f1=0.628]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.010 >= min_delta = 0.0. New best score: 0.437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 59/59 [00:30<00:00,  1.93it/s, v_num=0, val_loss=0.429, step=19.00, val_f1=0.619, train_loss=0.194, train_f1=0.640]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.008 >= min_delta = 0.0. New best score: 0.429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 59/59 [00:29<00:00,  1.97it/s, v_num=0, val_loss=0.429, step=22.00, val_f1=0.607, train_loss=0.144, train_f1=0.676]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 59/59 [00:29<00:00,  1.99it/s, v_num=0, val_loss=0.471, step=25.00, val_f1=0.613, train_loss=0.103, train_f1=0.698]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 3 records. Best score: 0.429. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 59/59 [00:29<00:00,  1.99it/s, v_num=0, val_loss=0.471, step=25.00, val_f1=0.613, train_loss=0.103, train_f1=0.698]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 157\n",
      "GPU available: False, used: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model model1 with seed 157...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: c:\\Users\\merli\\OneDrive\\Desktop\\Github repos\\NLP\\A1\\logs\\lightning_logs\\model1_seed157\n",
      "\n",
      "  | Name             | Type          | Params\n",
      "---------------------------------------------------\n",
      "0 | lstm             | LSTM          | 579 K \n",
      "1 | fc               | Linear        | 11.8 K\n",
      "2 | _train_f1_metric | F1ScoreCustom | 0     \n",
      "3 | _val_f1_metric   | F1ScoreCustom | 0     \n",
      "4 | _test_f1_metric  | F1ScoreCustom | 0     \n",
      "---------------------------------------------------\n",
      "591 K     Trainable params\n",
      "0         Non-trainable params\n",
      "591 K     Total params\n",
      "2.366     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 59/59 [00:32<00:00,  1.83it/s, v_num=0, val_loss=2.460, step=0.000, val_f1=0.192, train_loss=2.960]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 2.464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 59/59 [00:30<00:00,  1.94it/s, v_num=0, val_loss=1.490, step=1.000, val_f1=0.355, train_loss=1.860, train_f1=0.0825]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.975 >= min_delta = 0.0. New best score: 1.490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 59/59 [00:28<00:00,  2.10it/s, v_num=0, val_loss=1.120, step=2.000, val_f1=0.423, train_loss=1.240, train_f1=0.254] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.374 >= min_delta = 0.0. New best score: 1.116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 59/59 [00:28<00:00,  2.08it/s, v_num=0, val_loss=0.929, step=3.000, val_f1=0.455, train_loss=0.970, train_f1=0.388]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.186 >= min_delta = 0.0. New best score: 0.929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 59/59 [00:29<00:00,  1.98it/s, v_num=0, val_loss=0.819, step=4.000, val_f1=0.448, train_loss=0.817, train_f1=0.447]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.110 >= min_delta = 0.0. New best score: 0.819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 59/59 [00:28<00:00,  2.06it/s, v_num=0, val_loss=0.740, step=5.000, val_f1=0.496, train_loss=0.712, train_f1=0.449]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.080 >= min_delta = 0.0. New best score: 0.740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 59/59 [00:31<00:00,  1.86it/s, v_num=0, val_loss=0.677, step=6.000, val_f1=0.517, train_loss=0.631, train_f1=0.485]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.063 >= min_delta = 0.0. New best score: 0.677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 59/59 [00:28<00:00,  2.10it/s, v_num=0, val_loss=0.629, step=7.000, val_f1=0.545, train_loss=0.567, train_f1=0.504]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.048 >= min_delta = 0.0. New best score: 0.629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 59/59 [00:28<00:00,  2.07it/s, v_num=0, val_loss=0.590, step=8.000, val_f1=0.550, train_loss=0.515, train_f1=0.544]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.039 >= min_delta = 0.0. New best score: 0.590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 59/59 [00:29<00:00,  2.03it/s, v_num=0, val_loss=0.557, step=9.000, val_f1=0.555, train_loss=0.470, train_f1=0.568]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.032 >= min_delta = 0.0. New best score: 0.557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 59/59 [00:29<00:00,  2.00it/s, v_num=0, val_loss=0.533, step=10.00, val_f1=0.575, train_loss=0.430, train_f1=0.586]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.024 >= min_delta = 0.0. New best score: 0.533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 59/59 [00:40<00:00,  1.44it/s, v_num=0, val_loss=0.514, step=11.00, val_f1=0.571, train_loss=0.394, train_f1=0.576]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.019 >= min_delta = 0.0. New best score: 0.514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 59/59 [00:41<00:00,  1.43it/s, v_num=0, val_loss=0.499, step=12.00, val_f1=0.577, train_loss=0.362, train_f1=0.578]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.015 >= min_delta = 0.0. New best score: 0.499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 59/59 [00:42<00:00,  1.40it/s, v_num=0, val_loss=0.487, step=13.00, val_f1=0.584, train_loss=0.332, train_f1=0.602]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.012 >= min_delta = 0.0. New best score: 0.487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 59/59 [00:34<00:00,  1.70it/s, v_num=0, val_loss=0.476, step=14.00, val_f1=0.573, train_loss=0.306, train_f1=0.612]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.011 >= min_delta = 0.0. New best score: 0.476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 59/59 [00:31<00:00,  1.89it/s, v_num=0, val_loss=0.459, step=15.00, val_f1=0.574, train_loss=0.284, train_f1=0.624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.017 >= min_delta = 0.0. New best score: 0.459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 59/59 [00:31<00:00,  1.87it/s, v_num=0, val_loss=0.448, step=17.00, val_f1=0.585, train_loss=0.246, train_f1=0.628]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.011 >= min_delta = 0.0. New best score: 0.448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 59/59 [00:29<00:00,  2.01it/s, v_num=0, val_loss=0.439, step=18.00, val_f1=0.582, train_loss=0.217, train_f1=0.634]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.009 >= min_delta = 0.0. New best score: 0.439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 59/59 [00:30<00:00,  1.95it/s, v_num=0, val_loss=0.460, step=21.00, val_f1=0.591, train_loss=0.156, train_f1=0.655]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 3 records. Best score: 0.439. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 59/59 [00:30<00:00,  1.95it/s, v_num=0, val_loss=0.460, step=21.00, val_f1=0.591, train_loss=0.156, train_f1=0.655]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model model2 with seed 6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: c:\\Users\\merli\\OneDrive\\Desktop\\Github repos\\NLP\\A1\\logs\\lightning_logs\\model2_seed6\n",
      "\n",
      "  | Name             | Type          | Params\n",
      "---------------------------------------------------\n",
      "0 | lstm             | LSTM          | 579 K \n",
      "1 | fc_1             | Linear        | 16.4 K\n",
      "2 | fc_2             | Linear        | 3.0 K \n",
      "3 | _train_f1_metric | F1ScoreCustom | 0     \n",
      "4 | _val_f1_metric   | F1ScoreCustom | 0     \n",
      "5 | _test_f1_metric  | F1ScoreCustom | 0     \n",
      "---------------------------------------------------\n",
      "599 K     Trainable params\n",
      "0         Non-trainable params\n",
      "599 K     Total params\n",
      "2.396     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 59/59 [00:32<00:00,  1.82it/s, v_num=0, val_loss=2.630, step=0.000, val_f1=0.164, train_loss=3.040]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 2.628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 59/59 [00:32<00:00,  1.79it/s, v_num=0, val_loss=1.590, step=1.000, val_f1=0.304, train_loss=2.000, train_f1=0.079]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 1.040 >= min_delta = 0.0. New best score: 1.588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 59/59 [00:30<00:00,  1.95it/s, v_num=0, val_loss=1.170, step=2.000, val_f1=0.380, train_loss=1.300, train_f1=0.215]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.423 >= min_delta = 0.0. New best score: 1.165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 59/59 [00:32<00:00,  1.79it/s, v_num=0, val_loss=0.953, step=3.000, val_f1=0.433, train_loss=0.998, train_f1=0.336]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.212 >= min_delta = 0.0. New best score: 0.953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 59/59 [00:30<00:00,  1.96it/s, v_num=0, val_loss=0.819, step=4.000, val_f1=0.435, train_loss=0.827, train_f1=0.402]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.134 >= min_delta = 0.0. New best score: 0.819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 59/59 [00:31<00:00,  1.85it/s, v_num=0, val_loss=0.738, step=5.000, val_f1=0.458, train_loss=0.720, train_f1=0.434]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.081 >= min_delta = 0.0. New best score: 0.738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 59/59 [00:32<00:00,  1.81it/s, v_num=0, val_loss=0.687, step=6.000, val_f1=0.501, train_loss=0.638, train_f1=0.464]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.051 >= min_delta = 0.0. New best score: 0.687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 59/59 [00:31<00:00,  1.90it/s, v_num=0, val_loss=0.638, step=7.000, val_f1=0.532, train_loss=0.570, train_f1=0.483]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.049 >= min_delta = 0.0. New best score: 0.638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 59/59 [00:31<00:00,  1.89it/s, v_num=0, val_loss=0.590, step=8.000, val_f1=0.557, train_loss=0.515, train_f1=0.518]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.049 >= min_delta = 0.0. New best score: 0.590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 59/59 [00:30<00:00,  1.95it/s, v_num=0, val_loss=0.557, step=9.000, val_f1=0.558, train_loss=0.466, train_f1=0.550]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.033 >= min_delta = 0.0. New best score: 0.557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 59/59 [00:31<00:00,  1.88it/s, v_num=0, val_loss=0.533, step=10.00, val_f1=0.549, train_loss=0.423, train_f1=0.572]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.024 >= min_delta = 0.0. New best score: 0.533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 59/59 [00:31<00:00,  1.85it/s, v_num=0, val_loss=0.513, step=11.00, val_f1=0.558, train_loss=0.386, train_f1=0.580]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.020 >= min_delta = 0.0. New best score: 0.513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 59/59 [00:32<00:00,  1.82it/s, v_num=0, val_loss=0.494, step=12.00, val_f1=0.571, train_loss=0.354, train_f1=0.583]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.019 >= min_delta = 0.0. New best score: 0.494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 59/59 [00:31<00:00,  1.89it/s, v_num=0, val_loss=0.486, step=13.00, val_f1=0.583, train_loss=0.324, train_f1=0.588]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.008 >= min_delta = 0.0. New best score: 0.486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 59/59 [00:33<00:00,  1.77it/s, v_num=0, val_loss=0.478, step=14.00, val_f1=0.584, train_loss=0.300, train_f1=0.601]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.008 >= min_delta = 0.0. New best score: 0.478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 59/59 [00:30<00:00,  1.91it/s, v_num=0, val_loss=0.454, step=15.00, val_f1=0.589, train_loss=0.281, train_f1=0.614]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.024 >= min_delta = 0.0. New best score: 0.454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 59/59 [00:33<00:00,  1.75it/s, v_num=0, val_loss=0.459, step=18.00, val_f1=0.584, train_loss=0.195, train_f1=0.649]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 3 records. Best score: 0.454. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 59/59 [00:33<00:00,  1.75it/s, v_num=0, val_loss=0.459, step=18.00, val_f1=0.584, train_loss=0.195, train_f1=0.649]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 90\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: c:\\Users\\merli\\OneDrive\\Desktop\\Github repos\\NLP\\A1\\logs\\lightning_logs\\model2_seed90\n",
      "\n",
      "  | Name             | Type          | Params\n",
      "---------------------------------------------------\n",
      "0 | lstm             | LSTM          | 579 K \n",
      "1 | fc_1             | Linear        | 16.4 K\n",
      "2 | fc_2             | Linear        | 3.0 K \n",
      "3 | _train_f1_metric | F1ScoreCustom | 0     \n",
      "4 | _val_f1_metric   | F1ScoreCustom | 0     \n",
      "5 | _test_f1_metric  | F1ScoreCustom | 0     \n",
      "---------------------------------------------------\n",
      "599 K     Trainable params\n",
      "0         Non-trainable params\n",
      "599 K     Total params\n",
      "2.396     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model model2 with seed 90...\n",
      "Epoch 0: 100%|██████████| 59/59 [00:30<00:00,  1.90it/s, v_num=0, val_loss=2.550, step=0.000, val_f1=0.207, train_loss=3.010]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 2.548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 59/59 [00:32<00:00,  1.82it/s, v_num=0, val_loss=1.570, step=1.000, val_f1=0.306, train_loss=1.980, train_f1=0.0734]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.974 >= min_delta = 0.0. New best score: 1.574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 59/59 [00:31<00:00,  1.88it/s, v_num=0, val_loss=1.160, step=2.000, val_f1=0.381, train_loss=1.280, train_f1=0.223] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.416 >= min_delta = 0.0. New best score: 1.158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 59/59 [00:35<00:00,  1.67it/s, v_num=0, val_loss=0.950, step=3.000, val_f1=0.431, train_loss=0.977, train_f1=0.359]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.209 >= min_delta = 0.0. New best score: 0.950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 59/59 [00:32<00:00,  1.82it/s, v_num=0, val_loss=0.815, step=4.000, val_f1=0.471, train_loss=0.818, train_f1=0.432]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.135 >= min_delta = 0.0. New best score: 0.815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 59/59 [00:30<00:00,  1.94it/s, v_num=0, val_loss=0.740, step=5.000, val_f1=0.484, train_loss=0.709, train_f1=0.460]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.075 >= min_delta = 0.0. New best score: 0.740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 59/59 [00:34<00:00,  1.71it/s, v_num=0, val_loss=0.674, step=6.000, val_f1=0.518, train_loss=0.631, train_f1=0.494]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.065 >= min_delta = 0.0. New best score: 0.674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 59/59 [00:30<00:00,  1.91it/s, v_num=0, val_loss=0.621, step=7.000, val_f1=0.543, train_loss=0.570, train_f1=0.493]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.053 >= min_delta = 0.0. New best score: 0.621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 59/59 [00:32<00:00,  1.81it/s, v_num=0, val_loss=0.589, step=8.000, val_f1=0.553, train_loss=0.515, train_f1=0.522]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.031 >= min_delta = 0.0. New best score: 0.589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 59/59 [00:29<00:00,  1.98it/s, v_num=0, val_loss=0.561, step=9.000, val_f1=0.563, train_loss=0.466, train_f1=0.552]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.028 >= min_delta = 0.0. New best score: 0.561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 59/59 [00:33<00:00,  1.74it/s, v_num=0, val_loss=0.539, step=10.00, val_f1=0.559, train_loss=0.423, train_f1=0.556]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.023 >= min_delta = 0.0. New best score: 0.539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 59/59 [00:32<00:00,  1.81it/s, v_num=0, val_loss=0.523, step=11.00, val_f1=0.554, train_loss=0.384, train_f1=0.561]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.015 >= min_delta = 0.0. New best score: 0.523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 59/59 [00:32<00:00,  1.82it/s, v_num=0, val_loss=0.509, step=12.00, val_f1=0.557, train_loss=0.351, train_f1=0.579]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.015 >= min_delta = 0.0. New best score: 0.509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 59/59 [00:30<00:00,  1.91it/s, v_num=0, val_loss=0.492, step=13.00, val_f1=0.550, train_loss=0.321, train_f1=0.584]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.017 >= min_delta = 0.0. New best score: 0.492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 59/59 [00:37<00:00,  1.59it/s, v_num=0, val_loss=0.474, step=14.00, val_f1=0.579, train_loss=0.293, train_f1=0.601]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.019 >= min_delta = 0.0. New best score: 0.474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 59/59 [00:36<00:00,  1.62it/s, v_num=0, val_loss=0.462, step=15.00, val_f1=0.571, train_loss=0.267, train_f1=0.619]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.012 >= min_delta = 0.0. New best score: 0.462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 59/59 [00:32<00:00,  1.82it/s, v_num=0, val_loss=0.455, step=16.00, val_f1=0.562, train_loss=0.244, train_f1=0.634]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 59/59 [00:30<00:00,  1.91it/s, v_num=0, val_loss=0.447, step=18.00, val_f1=0.570, train_loss=0.192, train_f1=0.640]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.008 >= min_delta = 0.0. New best score: 0.447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 59/59 [00:33<00:00,  1.75it/s, v_num=0, val_loss=0.490, step=21.00, val_f1=0.581, train_loss=0.125, train_f1=0.675]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 3 records. Best score: 0.447. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 59/59 [00:33<00:00,  1.75it/s, v_num=0, val_loss=0.490, step=21.00, val_f1=0.581, train_loss=0.125, train_f1=0.675]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 157\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: c:\\Users\\merli\\OneDrive\\Desktop\\Github repos\\NLP\\A1\\logs\\lightning_logs\\model2_seed157\n",
      "\n",
      "  | Name             | Type          | Params\n",
      "---------------------------------------------------\n",
      "0 | lstm             | LSTM          | 579 K \n",
      "1 | fc_1             | Linear        | 16.4 K\n",
      "2 | fc_2             | Linear        | 3.0 K \n",
      "3 | _train_f1_metric | F1ScoreCustom | 0     \n",
      "4 | _val_f1_metric   | F1ScoreCustom | 0     \n",
      "5 | _test_f1_metric  | F1ScoreCustom | 0     \n",
      "---------------------------------------------------\n",
      "599 K     Trainable params\n",
      "0         Non-trainable params\n",
      "599 K     Total params\n",
      "2.396     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model model2 with seed 157...\n",
      "Epoch 0: 100%|██████████| 59/59 [00:32<00:00,  1.80it/s, v_num=0, val_loss=2.570, step=0.000, val_f1=0.169, train_loss=3.010]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 2.566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 59/59 [00:31<00:00,  1.86it/s, v_num=0, val_loss=1.450, step=1.000, val_f1=0.331, train_loss=1.920, train_f1=0.0795]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 1.118 >= min_delta = 0.0. New best score: 1.449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 59/59 [00:33<00:00,  1.78it/s, v_num=0, val_loss=1.120, step=2.000, val_f1=0.393, train_loss=1.220, train_f1=0.218] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.331 >= min_delta = 0.0. New best score: 1.117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 59/59 [00:36<00:00,  1.62it/s, v_num=0, val_loss=0.924, step=3.000, val_f1=0.426, train_loss=0.959, train_f1=0.363]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.193 >= min_delta = 0.0. New best score: 0.924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 59/59 [00:32<00:00,  1.79it/s, v_num=0, val_loss=0.805, step=4.000, val_f1=0.459, train_loss=0.797, train_f1=0.403]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.119 >= min_delta = 0.0. New best score: 0.805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 59/59 [00:33<00:00,  1.74it/s, v_num=0, val_loss=0.722, step=5.000, val_f1=0.496, train_loss=0.689, train_f1=0.433]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.084 >= min_delta = 0.0. New best score: 0.722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 59/59 [00:31<00:00,  1.90it/s, v_num=0, val_loss=0.657, step=6.000, val_f1=0.493, train_loss=0.609, train_f1=0.492]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.064 >= min_delta = 0.0. New best score: 0.657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 59/59 [00:38<00:00,  1.53it/s, v_num=0, val_loss=0.613, step=7.000, val_f1=0.530, train_loss=0.547, train_f1=0.497]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.044 >= min_delta = 0.0. New best score: 0.613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 59/59 [00:33<00:00,  1.77it/s, v_num=0, val_loss=0.582, step=8.000, val_f1=0.539, train_loss=0.490, train_f1=0.520]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.031 >= min_delta = 0.0. New best score: 0.582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 59/59 [00:36<00:00,  1.60it/s, v_num=0, val_loss=0.549, step=9.000, val_f1=0.550, train_loss=0.439, train_f1=0.557]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.033 >= min_delta = 0.0. New best score: 0.549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 59/59 [00:32<00:00,  1.81it/s, v_num=0, val_loss=0.512, step=10.00, val_f1=0.558, train_loss=0.399, train_f1=0.583]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.037 >= min_delta = 0.0. New best score: 0.512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 59/59 [00:32<00:00,  1.82it/s, v_num=0, val_loss=0.488, step=11.00, val_f1=0.559, train_loss=0.361, train_f1=0.568]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.024 >= min_delta = 0.0. New best score: 0.488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 59/59 [00:33<00:00,  1.77it/s, v_num=0, val_loss=0.472, step=12.00, val_f1=0.575, train_loss=0.323, train_f1=0.577]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.016 >= min_delta = 0.0. New best score: 0.472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 59/59 [00:32<00:00,  1.82it/s, v_num=0, val_loss=0.462, step=13.00, val_f1=0.567, train_loss=0.290, train_f1=0.600]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.009 >= min_delta = 0.0. New best score: 0.462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 59/59 [00:35<00:00,  1.65it/s, v_num=0, val_loss=0.460, step=14.00, val_f1=0.591, train_loss=0.260, train_f1=0.618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 59/59 [00:31<00:00,  1.85it/s, v_num=0, val_loss=0.455, step=16.00, val_f1=0.591, train_loss=0.208, train_f1=0.632]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 59/59 [00:35<00:00,  1.65it/s, v_num=0, val_loss=0.444, step=17.00, val_f1=0.593, train_loss=0.181, train_f1=0.645]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.012 >= min_delta = 0.0. New best score: 0.444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 59/59 [00:42<00:00,  1.38it/s, v_num=0, val_loss=0.504, step=20.00, val_f1=0.595, train_loss=0.127, train_f1=0.659]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 3 records. Best score: 0.444. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 59/59 [00:42<00:00,  1.38it/s, v_num=0, val_loss=0.504, step=20.00, val_f1=0.595, train_loss=0.127, train_f1=0.659]\n"
     ]
    }
   ],
   "source": [
    "logs_path = Path.cwd() / \"logs\" / \"lightning_logs\"\n",
    "\n",
    "\n",
    "seeds = [6, 90, 157]\n",
    "\n",
    "epochs = 100\n",
    "output_dim = len(df_train[\"POS\"].unique()) + 1  # +1 for padding\n",
    "hidden_dim = 128\n",
    "input_dim = embedding_dim\n",
    "\n",
    "model_classes = [BiLSTMModel, Model1, Model2]\n",
    "model_names = [\"baseline\", \"model1\", \"model2\"]\n",
    "hyperparameters = [\n",
    "    {'input_dim': input_dim, 'hidden_dim': hidden_dim, 'output_dim': output_dim},\n",
    "    {'input_dim': input_dim, 'hidden_dim': hidden_dim, 'output_dim': output_dim},\n",
    "    {'input_dim': input_dim, 'hidden_dim': hidden_dim, 'output_dim': output_dim, 'fc_size': 64} \n",
    "]\n",
    "\n",
    "for model_class, model_name, hyperparameter in zip(model_classes, model_names, hyperparameters):\n",
    "    for seed in seeds:\n",
    "        print(f\"Training model {model_name} with seed {seed}...\")\n",
    "        seed_everything(seed, workers=True)\n",
    "\n",
    "        model = model_class(**hyperparameter)\n",
    "\n",
    "        logger = TensorBoardLogger(logs_path, name=f\"{model_name}_seed{seed}\")\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            monitor='val_loss',\n",
    "            dirpath=None,\n",
    "            filename=f'{model_name}-seed={seed}' + '-{epoch:02d}-{val_loss:.2f}-{val_f1:.2f}',\n",
    "            save_top_k=1,\n",
    "        )\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=3,\n",
    "            verbose=True,\n",
    "            mode='min'\n",
    "        )\n",
    "\n",
    "\n",
    "        trainer = Trainer(\n",
    "            max_epochs=epochs,\n",
    "            logger=logger,\n",
    "            log_every_n_steps=1,\n",
    "            callbacks=[checkpoint_callback, early_stop_callback],\n",
    "            deterministic=True\n",
    "        )\n",
    "        \n",
    "        trainer.fit(model, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robust estimation across seeds and choice of best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model\n",
    "# validation_results_baseline_model = trainer.validate(model, dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 8392), started 3 days, 0:53:09 ago. (Use '!kill 8392' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6c7bd93fc6453f01\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6c7bd93fc6453f01\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 6: Error analysis\n",
    "\n",
    "* Compare the errors made on the validation and test sets.\n",
    "* Aggregate model errors into categories (if possible) \n",
    "* Comment about errors and propose possible solutions on how to address them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 7: Report\n",
    "\n",
    "Wrap up your experiment in a short report (up to 2 pages)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "* Use the NLP course report template.\n",
    "* Summarize each task in the report following the provided template."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendations\n",
    "\n",
    "The report is not a copy-paste of graphs, tables, and command outputs.\n",
    "\n",
    "* Summarize classification performance in Table format.\n",
    "* **Do not** report command outputs or screenshots.\n",
    "* Report learning curves in Figure format.\n",
    "* The error analysis section should summarize your findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "\n",
    "* **Submit** your report in PDF format.\n",
    "* **Submit** your python notebook.\n",
    "* Make sure your notebook is **well organized**, with no temporary code, commented sections, tests, etc...\n",
    "* You can upload **model weights** in a cloud repository and report the link in the report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
